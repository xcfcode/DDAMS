[{"edus": [{"text": "it 's not very significant .", "speaker": "A"}, {"text": "channel three . alright .", "speaker": "D"}, {"text": "did you solve speech recognition last week ?", "speaker": "B"}, {"text": "let 's do image processing .", "speaker": "B"}, {"text": "yes , again .", "speaker": "C"}, {"text": "we did it again , morgan .", "speaker": "C"}, {"text": "doo - doop , doo - doo .", "speaker": "E"}, {"text": "what 's wrong with ?", "speaker": "A"}, {"text": "it 's april fifth .", "speaker": "B"}, {"text": "actually , hynek should be getting back in town shortly if he isn't already .", "speaker": "B"}, {"text": "is he gonna come here ?", "speaker": "C"}, {"text": "we 'll drag him here .", "speaker": "B"}, {"text": "know where he is .", "speaker": "B"}, {"text": "so when you said \" in town \" , you mean oregon .", "speaker": "C"}, {"text": ", , this end of the world ,", "speaker": "B"}, {"text": "is really what ,", "speaker": "B"}, {"text": "doo , doo - doo .", "speaker": "E"}, {"text": "cuz he 's been in europe .", "speaker": "B"}, {"text": "doo - doo .", "speaker": "E"}, {"text": "have something just fairly brief to report on .", "speaker": "C"}, {"text": "did some experim , just few more experiments before had to , , go away for the , that week .", "speaker": "C"}, {"text": "was it last week or whenever ?", "speaker": "C"}, {"text": "so what was started playing with was the again , this is the htk back - end .", "speaker": "C"}, {"text": "was curious because the way that they train up the models , they go through about four rounds of training .", "speaker": "C"}, {"text": "and in the first round they do , it 's three iterations ,", "speaker": "C"}, {"text": "and for the last three rounds they do seven iterations of re - estimation in each of those three .", "speaker": "C"}, {"text": "that 's part of what takes so long to train the the back - end for this .", "speaker": "C"}, {"text": "didn't quite get that .", "speaker": "B"}, {"text": "there 's there 's four and there 's seven", "speaker": "B"}, {"text": "should write it on the board .", "speaker": "C"}, {"text": "so , there 's four rounds of training .", "speaker": "C"}, {"text": "you could say iterations .", "speaker": "C"}, {"text": "the first one is three , then seven , and seven .", "speaker": "C"}, {"text": "and what these numbers refer to is the number of times that the , , re - estimation is run .", "speaker": "C"}, {"text": "it 's this program called", "speaker": "C"}, {"text": "but in htk , what 's the difference between , , an inner loop and an outer loop in these iterations ?", "speaker": "B"}, {"text": "so what happens is , , at each one of these points , you increase the number of gaussians in the model .", "speaker": "C"}, {"text": "this was the mix up .", "speaker": "B"}, {"text": "the mix up .", "speaker": "C"}, {"text": "and so , in the final one here , you end up with , for all of the digit words , you end up with , , three mixtures per state ,", "speaker": "C"}, {"text": "in the final thing .", "speaker": "C"}, {"text": "so had done some experiments where was want to play with the number of mixtures .", "speaker": "C"}, {"text": "wanted to first test to see if we actually need to do this many iterations early on .", "speaker": "C"}, {"text": "one , two ,", "speaker": "E"}, {"text": "ran couple of experiments where reduced that to to be three , two , , five , ,", "speaker": "C"}, {"text": "and got almost the exact same results .", "speaker": "C"}, {"text": "and but it runs much faster .", "speaker": "C"}, {"text": "it only took something like , , three or four hours to do the full training ,", "speaker": "C"}, {"text": "as opposed to ?", "speaker": "B"}, {"text": "as opposed to wh what , sixteen hours like that ?", "speaker": "C"}, {"text": "it takes you have to do an overnight , the way it is set up now .", "speaker": "C"}, {"text": "even we don't do anything else , doing something like this could allow us to turn experiments around lot faster .", "speaker": "C"}, {"text": "and then when you have your final thing , do full one , so it 's", "speaker": "B"}, {"text": "and when you have your final thing , we go back to this .", "speaker": "C"}, {"text": "and it 's real simple change to make .", "speaker": "C"}, {"text": "it 's like one little text file you edit and change those numbers ,", "speaker": "C"}, {"text": "and you don't do anything else .", "speaker": "C"}, {"text": "and then you just run .", "speaker": "C"}, {"text": "so it 's very simple change to make", "speaker": "C"}, {"text": "and it doesn't seem to hurt all that much .", "speaker": "C"}, {"text": "so you run with three , two , five ? that 's", "speaker": "A"}, {"text": "have to look to see what the exact numbers were .", "speaker": "C"}, {"text": "was , like , three , two , five ,", "speaker": "C"}, {"text": "but 'll 'll double check .", "speaker": "C"}, {"text": "it was over week ago that did it ,", "speaker": "C"}, {"text": "so 't remember exactly .", "speaker": "C"}, {"text": "but it 's so much faster .", "speaker": "C"}, {"text": "it makes big difference .", "speaker": "C"}, {"text": "so we could do lot more experiments and throw lot more in there .", "speaker": "C"}, {"text": "the other thing that did was , , compiled the htk for the linux boxes .", "speaker": "C"}, {"text": "so we have this big thing that we got from ibm ,", "speaker": "C"}, {"text": "which is five - processor machine .", "speaker": "C"}, {"text": "but it 's running linux .", "speaker": "C"}, {"text": "so , you can now run your experiments on that machine", "speaker": "C"}, {"text": "and you can run five at time", "speaker": "C"}, {"text": "and it runs , , as fast as , , , five different machines .", "speaker": "C"}, {"text": "'ve forgotten now what the name of that machine is", "speaker": "C"}, {"text": "but send email around about it .", "speaker": "C"}, {"text": "and so we 've got it", "speaker": "C"}, {"text": "now htk 's compiled for both the linux and for , , the sparcs .", "speaker": "C"}, {"text": "you have to make you have to make that in your dot cshrc , , it detects whether you 're running on the linux or sparc and points to the executables .", "speaker": "C"}, {"text": "and you may not have had that in your dot cshrc before , if you were always just running the sparc .", "speaker": "C"}, {"text": "tell you exactly what you need to do to get all of that to work .", "speaker": "C"}, {"text": "but it 'll it really increases what we can run on .", "speaker": "C"}, {"text": "so , together with the fact that we 've got these faster linux boxes and that it takes less time to do these , , we should be able to crank through lot more experiments .", "speaker": "C"}, {"text": "so after did that , then what wanted to do was try increasing the number of mixtures ,", "speaker": "C"}, {"text": "just to see , see how that affects performance .", "speaker": "C"}, {"text": ", you could do something like keep exactly the same procedure and then add fifth thing onto it", "speaker": "B"}, {"text": "that had more .", "speaker": "B"}, {"text": "so at the middle where the arrows are showing , that 's you 're adding one more mixture per state ,", "speaker": "E"}, {"text": "let 's see ,", "speaker": "C"}, {"text": "this , try to go it backwards this at this point it 's two mixtures per state .", "speaker": "C"}, {"text": "so this just adds one .", "speaker": "C"}, {"text": "except that , , actually for the silence model , it 's six mixtures per state .", "speaker": "C"}, {"text": "so it goes to two .", "speaker": "C"}, {"text": "and what happens here is", "speaker": "C"}, {"text": "might be between , , shared , shared variances ,", "speaker": "B"}, {"text": "that 's what it is .", "speaker": "C"}, {"text": "'t remember now what happens at that first one .", "speaker": "C"}, {"text": "have to look it up and see .", "speaker": "C"}, {"text": "there because they start off with , , an initial model", "speaker": "C"}, {"text": "which is just this global model ,", "speaker": "C"}, {"text": "and then they split it to the individuals .", "speaker": "C"}, {"text": "and so , it may be that 's what 's happening here .", "speaker": "C"}, {"text": "have to look it up and see .", "speaker": "C"}, {"text": "don't exactly remember .", "speaker": "C"}, {"text": "so . that 's it .", "speaker": "C"}, {"text": "so what else ?", "speaker": "B"}, {"text": "there was conference call this tuesday .", "speaker": "A"}, {"text": "yet the what happened tuesday ,", "speaker": "A"}, {"text": "but the points that they were supposed to discuss is still , , things like the weights ,", "speaker": "A"}, {"text": "this is conference call for , , aurora participant thing .", "speaker": "B"}, {"text": "do who was since we weren't in on it , , do who was in from ogi ?", "speaker": "B"}, {"text": "was was hynek involved", "speaker": "B"}, {"text": "or was it sunil", "speaker": "B"}, {"text": "have no idea .", "speaker": "A"}, {"text": "so the points were the weights how to weight the different error rates that are obtained from different language and conditions .", "speaker": "A"}, {"text": "it 's not clear that they will keep the same weighting .", "speaker": "A"}, {"text": "now it 's weighting on improvement .", "speaker": "A"}, {"text": "some people are arguing that it would be better to have weights on", "speaker": "A"}, {"text": "to combine error rates before computing improvement .", "speaker": "A"}, {"text": "and the fact is that for now for the english , they have weights", "speaker": "A"}, {"text": "they combine error rates ,", "speaker": "A"}, {"text": "but for the other languages they combine improvement .", "speaker": "A"}, {"text": "so it 's not very consistent .", "speaker": "A"}, {"text": "this is point .", "speaker": "A"}, {"text": "and now actually there is thing also , , that happens with the current weight is that very non - significant improvement on the - matched case result in huge differences in the final number .", "speaker": "A"}, {"text": "and so , perhaps they will change the weights to", "speaker": "A"}, {"text": "how should that be done ?", "speaker": "C"}, {"text": "it seems like there 's simple way", "speaker": "C"}, {"text": "this seems like an obvious mistake .", "speaker": "C"}, {"text": ", the fact that it 's inconsistent is an obvious mistake .", "speaker": "B"}, {"text": "but the but , , the other thing", "speaker": "B"}, {"text": "haven't thought it through ,", "speaker": "B"}, {"text": "but one would think that each it", "speaker": "B"}, {"text": "it 's like if you say what 's the what 's the best way to do an average ,", "speaker": "B"}, {"text": "an arithmetic average or geometric average ?", "speaker": "B"}, {"text": "it depends what you wanna show .", "speaker": "B"}, {"text": "each each one is gonna have different characteristic .", "speaker": "B"}, {"text": "it seems like they should do , like , the percentage improvement ,", "speaker": "C"}, {"text": "rather than the absolute improvement .", "speaker": "C"}, {"text": "tha - that 's what they do .", "speaker": "A"}, {"text": "they are doing that .", "speaker": "B"}, {"text": "no , that is relative .", "speaker": "B"}, {"text": "but the question is , do you average the relative improvements or do you average the error rates and take the relative improvement of that ?", "speaker": "B"}, {"text": "and it 's not just pure average because there are these weightings .", "speaker": "B"}, {"text": "it 's weighted average .", "speaker": "B"}, {"text": "and so when you average the relative improvement it tends to give lot of , , importance to the - matched case", "speaker": "A"}, {"text": "because the baseline is already very good", "speaker": "A"}, {"text": "why don't they not look at improvements but just look at your av your scores ?", "speaker": "C"}, {"text": "figure out how to combine the scores", "speaker": "C"}, {"text": "with weight or whatever ,", "speaker": "C"}, {"text": "and then give you score", "speaker": "C"}, {"text": "here 's your score .", "speaker": "C"}, {"text": "and then they can do the same thing for the baseline system", "speaker": "C"}, {"text": "and here 's its score .", "speaker": "C"}, {"text": "and then you can look at", "speaker": "C"}, {"text": "that 's what he 's seeing as one of the things they could do .", "speaker": "B"}, {"text": "it 's just when you when you get all done , that they pro", "speaker": "B"}, {"text": "but they started off this process with the notion that you should be significantly better than the previous standard .", "speaker": "B"}, {"text": "so they said \" how much is significantly better ?", "speaker": "B"}, {"text": "what do you ? \"", "speaker": "B"}, {"text": "and and so they said \" , , you should have half the errors , \" , \" that you had before \" .", "speaker": "B"}, {"text": "so it 's ,", "speaker": "B"}, {"text": "but it does seem like", "speaker": "B"}, {"text": "it does seem like it 's more logical to combine them first", "speaker": "B"}, {"text": "and then do the", "speaker": "B"}, {"text": "but there is this is this still this problem of weights .", "speaker": "A"}, {"text": "when when you combine error rate it tends to give more importance to the difficult cases ,", "speaker": "A"}, {"text": "and some people think that", "speaker": "A"}, {"text": "they have different , , opinions about this .", "speaker": "A"}, {"text": "some people think that it 's more important to look at to have ten percent imp relative improvement on - matched case than to have fifty percent on the mismatched ,", "speaker": "A"}, {"text": "and other people think that it 's more important to improve lot on the mismatch", "speaker": "A"}, {"text": "it sounds like they don't really have good idea about what the final application is gonna be .", "speaker": "C"}, {"text": ", that if you look at the numbers on the on the more difficult cases , , if you really believe that was gonna be the predominant use , none of this would be good enough .", "speaker": "B"}, {"text": "whereas you with some reasonable error recovery could imagine in the better cases that these systems working .", "speaker": "B"}, {"text": "the hope would be that it would , it would work for the good cases", "speaker": "B"}, {"text": "and , , it would have reasonable reas soft degradation as you got to worse and worse conditions .", "speaker": "B"}, {"text": "was thinking about it in terms of , if were building the final product", "speaker": "C"}, {"text": "and was gonna test to see which front - end 'd wanted to use ,", "speaker": "C"}, {"text": "would try to weight things depending on the exact environment that was gonna be using the system in .", "speaker": "C"}, {"text": "but but no .", "speaker": "B"}, {"text": "it isn't the operating theater .", "speaker": "B"}, {"text": "they don they don't they don't really know , .", "speaker": "B"}, {"text": "so if they , doesn't that suggest the way for them to go ?", "speaker": "C"}, {"text": "you assume everything 's equal .", "speaker": "C"}, {"text": ", one thing to do is to just not rely on single number", "speaker": "B"}, {"text": "to have two or three numbers ,", "speaker": "B"}, {"text": "and and say here 's how much you , you improve the , the relatively clean case", "speaker": "B"}, {"text": "or - matched case ,", "speaker": "B"}, {"text": "and here 's how here 's how much you ,", "speaker": "B"}, {"text": "so not try to combine them .", "speaker": "C"}, {"text": "actually it 's true .", "speaker": "B"}, {"text": "had forgotten this ,", "speaker": "B"}, {"text": "but , , - matched is not actually clean .", "speaker": "B"}, {"text": "what it is just that ,", "speaker": "B"}, {"text": "the training and testing are similar .", "speaker": "B"}, {"text": "the training and testing .", "speaker": "C"}, {"text": "what you would do in practice is you 'd try to get as many , , examples of similar as you could ,", "speaker": "B"}, {"text": "so the argument for that being the the more important thing , is that you 're gonna try and do that , but you wanna see how badly it deviates from that when when the , it 's little different .", "speaker": "B"}, {"text": "so you should weight those other conditions very , really small .", "speaker": "C"}, {"text": "that 's that 's an arg", "speaker": "B"}, {"text": "that 's more of an information thing .", "speaker": "C"}, {"text": "that 's an ar", "speaker": "B"}, {"text": "that 's an argument for it ,", "speaker": "B"}, {"text": "but let me give you the opposite argument .", "speaker": "B"}, {"text": "the opposite argument is you 're never really gonna have good sample of all these different things .", "speaker": "B"}, {"text": "are you gonna have , examples with the windows open ,", "speaker": "B"}, {"text": "going seventy , sixty , fifty , forty miles an hour ?", "speaker": "B"}, {"text": "on what roads ?", "speaker": "B"}, {"text": "with what passing you ?", "speaker": "B"}, {"text": "that you could make the opposite argument that the - matched case is fantasy .", "speaker": "B"}, {"text": "that if you look at the - matched case versus the po , the medium and the and the fo and then the mismatched case , , we 're seeing really , really big differences in performance .", "speaker": "B"}, {"text": "and and you wouldn't like that to be the case .", "speaker": "B"}, {"text": "you wouldn't like that as soon as you step outside", "speaker": "B"}, {"text": "lot of the cases it 's is", "speaker": "B"}, {"text": "that 'll teach them to roll their window up .", "speaker": "C"}, {"text": "in these cases , if you go from the ,", "speaker": "B"}, {"text": "don't remember the numbers off ,", "speaker": "B"}, {"text": "but if you if you go from the - matched case to the medium , it 's not an enormous difference in the in the training - testing situation ,", "speaker": "B"}, {"text": "and and it 's really big performance drop .", "speaker": "B"}, {"text": "the reference one , this is back old on , on italian , was like six percent error for the - matched", "speaker": "B"}, {"text": "and eighteen for the medium - matched", "speaker": "B"}, {"text": "and sixty for the for highly - mismatched .", "speaker": "B"}, {"text": "and , , with these other systems we helped it out quite bit ,", "speaker": "B"}, {"text": "but still there 's there 's something like factor of two between - matched and medium - matched .", "speaker": "B"}, {"text": "and so that if what you 're if the goal of this is to come up with robust features , it does mean", "speaker": "B"}, {"text": "so you could argue , , that the - matched is something you shouldn't be looking ,", "speaker": "B"}, {"text": "that the goal is to come up with features that will still give you reasonable performance ,", "speaker": "B"}, {"text": "with again gentle degregra degradation ,", "speaker": "B"}, {"text": "even though the testing condition is not the same as the training .", "speaker": "B"}, {"text": "so , , could argue strongly that something like the medium mismatch , which is not compl pathological but", "speaker": "B"}, {"text": "what was the medium - mismatch condition again ?", "speaker": "B"}, {"text": "medium mismatch is everything with the far microphone ,", "speaker": "A"}, {"text": "but trained on , like , low noisy condition ,", "speaker": "A"}, {"text": "and or stopped car", "speaker": "A"}, {"text": "and tested on high - speed conditions , ,", "speaker": "A"}, {"text": "so it 's still the same microphone in both cases ,", "speaker": "B"}, {"text": "but , , it 's there 's mismatch between the car conditions .", "speaker": "B"}, {"text": "you could argue that 's pretty realistic situation", "speaker": "B"}, {"text": "and , , 'd almost argue for weighting that highest .", "speaker": "B"}, {"text": "but the way they have it now , it 's it 's it 's", "speaker": "B"}, {"text": "they they compute the relative improvement first", "speaker": "B"}, {"text": "and then average that with weighting ?", "speaker": "B"}, {"text": "and so then the that makes the highly - matched the really big thing .", "speaker": "B"}, {"text": "so , since they have these three categories , it seems like the reasonable thing to do is to go across the languages and to come up with an improvement for each of those .", "speaker": "B"}, {"text": "just say \" , in the in the highly - matched case this is what happens ,", "speaker": "B"}, {"text": "in the the , this other medium if this happens ,", "speaker": "B"}, {"text": "in the highly - mismatched that happens \" .", "speaker": "B"}, {"text": "you should see , , gentle degradation through that .", "speaker": "B"}, {"text": "gather that in these meetings it 's it 's really tricky to make anything ac make any policy change", "speaker": "B"}, {"text": "because everybody has , , their own opinion", "speaker": "B"}, {"text": "but there is probably big change that will be made", "speaker": "A"}, {"text": "is that the baseline they want to have new baseline , perhaps ,", "speaker": "A"}, {"text": "which is , , mfcc", "speaker": "A"}, {"text": "but with voice activity detector .", "speaker": "A"}, {"text": "and , , some people are pushing to still keep this fifty percent number .", "speaker": "A"}, {"text": "so they want to have at least fifty percent improvement on the baseline ,", "speaker": "A"}, {"text": "but which would be much better baseline .", "speaker": "A"}, {"text": "and if we look at the result that sunil sent , just putting the vad in the baseline improved , like , more than twenty percent ,", "speaker": "A"}, {"text": "which would mean then mean that fifty percent on this new baseline is like , , more than sixty percent improvement on", "speaker": "A"}, {"text": "so nobody would be there , probably . ?", "speaker": "B"}, {"text": "now , nobody would be there ,", "speaker": "A"}, {"text": "work to do .", "speaker": "B"}, {"text": "is is is this ?", "speaker": "B"}, {"text": "they didn't decide yet .", "speaker": "A"}, {"text": "this was one point of the conference call also ,", "speaker": "A"}, {"text": "that would be good .", "speaker": "B"}, {"text": "it 's not that the design of the vad isn't important ,", "speaker": "B"}, {"text": "but it 's just that it it does seem to be , lot of work to do good job on that", "speaker": "B"}, {"text": "and as as being lot of work to do good job on the feature design ,", "speaker": "B"}, {"text": "if we can cut down on that we can make some progress .", "speaker": "B"}, {"text": "per - someone told that perhaps it 's not fair to do that because the , to make good vad you don't have enough to with the features that are the baseline features .", "speaker": "A"}, {"text": "you need more features .", "speaker": "A"}, {"text": "so you really need to put more in the in the front - end .", "speaker": "A"}, {"text": "wha - what do you mean ?", "speaker": "C"}, {"text": "let 's say for ins", "speaker": "B"}, {"text": "see , mfcc doesn't have anything in it , , related to the pitch .", "speaker": "B"}, {"text": "so suppose you 've that what you really wanna do is put good pitch detector on there", "speaker": "B"}, {"text": "and if it gets an unambiguous", "speaker": "B"}, {"text": "if it gets an unambiguous result then you 're definitely in in voice in , , region with speech .", "speaker": "B"}, {"text": "so there 's this assumption that the the voice activity detector can only use the mfcc ?", "speaker": "C"}, {"text": "that 's not clear ,", "speaker": "A"}, {"text": "for the baseline .", "speaker": "B"}, {"text": "so so if you use other features then", "speaker": "B"}, {"text": "but it 's just question of what is your baseline .", "speaker": "B"}, {"text": "what is it that you 're supposed to do better than ?", "speaker": "B"}, {"text": "having the baseline be the mfcc 's means that people could choose to pour their ener their effort into trying to do really good vad", "speaker": "B"}, {"text": "but they seem like two separate issues .", "speaker": "C"}, {"text": "they 're separate .", "speaker": "B"}, {"text": "unfortunately there 's coupling between them ,", "speaker": "B"}, {"text": "which is part of what stephane is getting to , is that you can choose your features in such way as to improve the vad .", "speaker": "B"}, {"text": "and you also can choose your features in such way as to prove improve recognition .", "speaker": "B"}, {"text": "they may not be the same thing .", "speaker": "B"}, {"text": "but it seems like you should do both .", "speaker": "C"}, {"text": "you should do both", "speaker": "B"}, {"text": "and that this still makes still think this makes sense as baseline .", "speaker": "B"}, {"text": "it 's just saying , as baseline , we know", "speaker": "B"}, {"text": "we had the mfcc 's before ,", "speaker": "B"}, {"text": "lots of people have done voice activity detectors ,", "speaker": "B"}, {"text": "you might as pick some voice activity detector and make that the baseline ,", "speaker": "B"}, {"text": "just like you picked some version of htk and made that the baseline .", "speaker": "B"}, {"text": "and then let 's try and make everything better .", "speaker": "B"}, {"text": "and if one of the ways you make it better is by having your features be better features for the vad then that 's so be it .", "speaker": "B"}, {"text": ", at least you have starting point that 's", "speaker": "B"}, {"text": "cuz some of the some of the people didn't have vad , .", "speaker": "B"}, {"text": "then they looked pretty bad", "speaker": "B"}, {"text": "and what they were doing wasn't so bad .", "speaker": "B"}, {"text": "it seems like you should try to make your baseline as good as possible .", "speaker": "C"}, {"text": "and if it turns out that you can't improve on that , , , then , , nobody wins and you just use mfcc .", "speaker": "C"}, {"text": "it seems like ,", "speaker": "B"}, {"text": "it should include the current state of the art that you want are trying to improve ,", "speaker": "B"}, {"text": "and mfcc 's , , or plp it seems like reasonable baseline for the features ,", "speaker": "B"}, {"text": "and anybody doing this task , , is gonna have some voice activity detection at some level , in some way .", "speaker": "B"}, {"text": "they might use the whole recognizer to do it but rather than separate thing ,", "speaker": "B"}, {"text": "but they 'll have it on some level .", "speaker": "B"}, {"text": "it seems like whatever they choose they shouldn't , , purposefully brain - damage part of the system to make worse baseline ,", "speaker": "C"}, {"text": "it wasn't that they purposely brain - damaged it .", "speaker": "B"}, {"text": "people hadn't really thought through about the , the vad issue .", "speaker": "B"}, {"text": "and and then when the the proposals actually came in and half of them had ds and half of them didn't ,", "speaker": "B"}, {"text": "and the half that did", "speaker": "B"}, {"text": "and the half that didn't did poorly .", "speaker": "B"}, {"text": "we 'll see what happen with this .", "speaker": "A"}, {"text": "so what happened since , , last week is", "speaker": "A"}, {"text": "from ogi , these experiments on putting vad on the baseline .", "speaker": "A"}, {"text": "and these experiments also are using , , some noise compensation ,", "speaker": "A"}, {"text": "so spectral subtraction ,", "speaker": "A"}, {"text": "and putting on - line normalization , , just after this .", "speaker": "A"}, {"text": "so spectral subtraction , lda filtering , and on - line normalization ,", "speaker": "A"}, {"text": "so which is similar to the pro proposal - one , but with spectral subtraction in addition ,", "speaker": "A"}, {"text": "and it seems that on - line normalization doesn't help further when you have spectral subtraction .", "speaker": "A"}, {"text": "is this related to the issue that you brought up couple of meetings ago with the musical tones", "speaker": "C"}, {"text": "have no idea ,", "speaker": "A"}, {"text": "because the issue brought up was with very simple spectral subtraction approach ,", "speaker": "A"}, {"text": "and the one that they use at ogi is one from the proposed the aurora prop , proposals ,", "speaker": "A"}, {"text": "which might be much better .", "speaker": "A"}, {"text": "asked sunil for more information about that ,", "speaker": "A"}, {"text": "and what 's happened here is that we", "speaker": "A"}, {"text": "so we have this new , , reference system which use clean downsampling - upsampling ,", "speaker": "A"}, {"text": "which use new filter that 's much shorter", "speaker": "A"}, {"text": "and which also cuts the frequency below sixty - four hertz ,", "speaker": "A"}, {"text": "which was not done on our first proposal .", "speaker": "A"}, {"text": "when you say \" we have that \" , does sunil have it now , too ,", "speaker": "B"}, {"text": "because we 're still testing .", "speaker": "A"}, {"text": "so we have the result for , , just the features", "speaker": "A"}, {"text": "and we are currently testing with putting the neural network in the klt .", "speaker": "A"}, {"text": "it seems to improve on the - matched case ,", "speaker": "A"}, {"text": "but it 's little bit worse on the mismatch and highly - mismatched", "speaker": "A"}, {"text": "when we put the neural network .", "speaker": "A"}, {"text": "and with the current weighting it 's sh it will be better", "speaker": "A"}, {"text": "because the - matched case is better .", "speaker": "A"}, {"text": "but how much worse since the weighting might change", "speaker": "B"}, {"text": "how much worse is it on the other conditions ,", "speaker": "B"}, {"text": "when you say it 's little worse ?", "speaker": "B"}, {"text": "it 's like , , fff , ten percent relative .", "speaker": "A"}, {"text": "but it has the ,", "speaker": "B"}, {"text": "the latencies are much shorter .", "speaker": "B"}, {"text": "- when say it 's worse , it 's not it 's when , compare proposal - two to proposal - one ,", "speaker": "A"}, {"text": "putting neural network compared to not having any neural network .", "speaker": "A"}, {"text": "this new system is is better ,", "speaker": "A"}, {"text": "because it has , this sixty - four hertz cut - off ,", "speaker": "A"}, {"text": ", good vad .", "speaker": "A"}, {"text": "we put the good vad .", "speaker": "A"}, {"text": "but you 've got the latency shorter now .", "speaker": "B"}, {"text": "so it 's better than the system that we had before .", "speaker": "B"}, {"text": "mainly because of the sixty - four hertz and the good vad .", "speaker": "A"}, {"text": "and then took this system and , mmm , , we put the old filters also .", "speaker": "A"}, {"text": "so we have this good system , with good vad ,", "speaker": "A"}, {"text": "with the short filter and with the long filter ,", "speaker": "A"}, {"text": "with the short filter it 's not worse .", "speaker": "A"}, {"text": "so that 's that 's all fine .", "speaker": "B"}, {"text": "but what you 're saying is that when you do these", "speaker": "B"}, {"text": "so let me try to understand .", "speaker": "B"}, {"text": "when when you do these same improvements to proposal - one ,", "speaker": "B"}, {"text": "that , , on the", "speaker": "B"}, {"text": "things are somewhat better , , in proposal - two for the - matched case", "speaker": "B"}, {"text": "and somewhat worse for the other two cases .", "speaker": "B"}, {"text": "when you say ,", "speaker": "B"}, {"text": "the now that these other things are in there , is it the case that the additions of proposal - two over proposal - one are less im important ?", "speaker": "B"}, {"text": "but it 's good thing anyway to have shorter delay .", "speaker": "A"}, {"text": "then we tried , , to do something like proposal - two", "speaker": "A"}, {"text": "but having , , using also msg features .", "speaker": "A"}, {"text": "so there is this klt part , which use just the standard features ,", "speaker": "A"}, {"text": "and then two neura two neural networks .", "speaker": "A"}, {"text": "and it doesn't seem to help .", "speaker": "A"}, {"text": "however , we just have one result ,", "speaker": "A"}, {"text": "which is the italian mismatch ,", "speaker": "A"}, {"text": "we have to for that to fill the whole table ,", "speaker": "A"}, {"text": "there was start of some effort on something related to voicing .", "speaker": "B"}, {"text": "so we try to , , find good features that could be used for voicing detection ,", "speaker": "A"}, {"text": "but it 's still , on the ,", "speaker": "A"}, {"text": ", have the picture .", "speaker": "F"}, {"text": "we we are still playing with matlab to look at what happened ,", "speaker": "A"}, {"text": "what sorts of features are you looking at ?", "speaker": "C"}, {"text": "so we would be looking at , , the variance of the spectrum of the excitation ,", "speaker": "A"}, {"text": ", this , and this .", "speaker": "F"}, {"text": "something like this ,", "speaker": "A"}, {"text": "which is should be high for voiced sounds .", "speaker": "A"}, {"text": "what does that mean ?", "speaker": "C"}, {"text": "the variance of the spectrum of excitation .", "speaker": "C"}, {"text": "so the spectrum of the excitation for purely periodic sig signal shou sh", "speaker": "A"}, {"text": "what yo what you 're calling the excitation , as recall , is you 're subtracting the , the mel mel filter , , spectrum from the fft spectrum .", "speaker": "B"}, {"text": "so we have the mel filter bank ,", "speaker": "A"}, {"text": "we have the fft ,", "speaker": "A"}, {"text": "so it 's it 's not really an excitation ,", "speaker": "B"}, {"text": "but it 's something that hopefully tells you something about the excitation .", "speaker": "B"}, {"text": "we have here some histogram ,", "speaker": "F"}, {"text": "but they have lot of overlap .", "speaker": "F"}, {"text": "but it 's it 's still", "speaker": "A"}, {"text": "for unvoiced portion we have something tha that has mean around point three ,", "speaker": "A"}, {"text": "and for voiced portion the mean is point fifty - nine .", "speaker": "A"}, {"text": "but the variance seem quite high .", "speaker": "A"}, {"text": "how did you get your voiced and unvoiced truth data ?", "speaker": "C"}, {"text": "we used , , timit", "speaker": "A"}, {"text": "and we used canonical mappings between the phones", "speaker": "A"}, {"text": "we , , use timit on this ,", "speaker": "F"}, {"text": "but if we look at it in one sentence , it it 's good ,", "speaker": "F"}, {"text": "so it 's noisy timit .", "speaker": "A"}, {"text": "it 's noisy timit .", "speaker": "E"}, {"text": "it seems quite robust to noise ,", "speaker": "A"}, {"text": "so when we take we draw its parameters across time for clean sentence and then nois the same noisy sentence , it 's very close .", "speaker": "A"}, {"text": "so there are there is this .", "speaker": "A"}, {"text": "there could be also the , something like the maximum of the auto - correlation function", "speaker": "A"}, {"text": "is this trained system ?", "speaker": "C"}, {"text": "or is it system where you just pick some thresholds ?", "speaker": "C"}, {"text": "ho - how does it work ?", "speaker": "C"}, {"text": "now we just are trying to find some features .", "speaker": "A"}, {"text": "hopefully , what we want to have is to put these features in some ,", "speaker": "A"}, {"text": "to obtain statistical model on these features", "speaker": "A"}, {"text": "and to or just to use neural network", "speaker": "A"}, {"text": "and hopefully these features would help", "speaker": "A"}, {"text": "because it seems like what you said about the mean of the voiced and the unvoiced that seemed pretty encouraging .", "speaker": "C"}, {"text": ", except the variance was big .", "speaker": "B"}, {"text": "except the variance is quite high .", "speaker": "A"}, {"text": "that would trust that so much", "speaker": "C"}, {"text": "because you 're doing these canonical mappings from timit labellings .", "speaker": "C"}, {"text": "really that 's cartoon picture about what 's voiced and unvoiced .", "speaker": "C"}, {"text": "so that could be giving you lot of variance .", "speaker": "C"}, {"text": "it may be that you 're finding something good", "speaker": "C"}, {"text": "and that the variance is artificial because of how you 're getting your truth .", "speaker": "C"}, {"text": "but another way of looking at it might be that", "speaker": "B"}, {"text": "what we are coming up with feature sets after all .", "speaker": "B"}, {"text": "so another way of looking at it is that , the mel cepstru mel spectrum , mel cepstrum , any of these variants , , give you the smooth spectrum .", "speaker": "B"}, {"text": "it 's the spectral envelope .", "speaker": "B"}, {"text": "by going back to the fft , you 're getting something that is more like the raw data .", "speaker": "B"}, {"text": "so the question is , what characterization", "speaker": "B"}, {"text": "and you 're playing around with this", "speaker": "B"}, {"text": "another way of looking at it is what characterization of the difference between the raw data and this smooth version is something that you 're missing that could help ?", "speaker": "B"}, {"text": "so , , looking at different statistical measures of that difference ,", "speaker": "B"}, {"text": "coming up with some things and just trying them out", "speaker": "B"}, {"text": "and seeing if you add them onto the feature vector does that make things better or worse in noise ,", "speaker": "B"}, {"text": "where you 're really just", "speaker": "B"}, {"text": "the way 'm looking at it is not so much you 're trying to find the best the world 's best voiced - unvoiced , , classifier ,", "speaker": "B"}, {"text": "but it 's more that , , , try some different statistical characterizations of that difference back to the raw data", "speaker": "B"}, {"text": "there 's something there that the system can use .", "speaker": "B"}, {"text": "but ther more obvious is that", "speaker": "A"}, {"text": "the the more obvious is that", "speaker": "A"}, {"text": "using the the fft , , you just it gives you just information about if it 's voiced or not voiced , ma mainly , .", "speaker": "A"}, {"text": "this is why we started to look by having voiced phonemes", "speaker": "A"}, {"text": "that 's the rea", "speaker": "B"}, {"text": "what 'm arguing is that 's", "speaker": "B"}, {"text": ", what 'm arguing is that that 's givi you gives you your intuition .", "speaker": "B"}, {"text": "but in reality , it 's , there 's all of this overlap and ,", "speaker": "B"}, {"text": "and but what 'm saying is that may be ,", "speaker": "B"}, {"text": "because what you 're really getting is not actually voiced versus unvoiced ,", "speaker": "B"}, {"text": "both for the fac the reason of the overlap and then , , , structural reasons ,", "speaker": "B"}, {"text": "like the one that chuck said ,", "speaker": "B"}, {"text": "that , , the data itself is that you 're working with is not perfect .", "speaker": "B"}, {"text": "so , what 'm saying is that 's not killer", "speaker": "B"}, {"text": "because you 're just getting some characterization ,", "speaker": "B"}, {"text": "one that 's driven by your intuition about voiced - unvoiced certainly ,", "speaker": "B"}, {"text": "but it 's just some characterization of something back in the in the almost raw data , rather than the smooth version .", "speaker": "B"}, {"text": "and your intuition is driving you towards particular kinds of , , statistical characterizations of , , what 's missing from the spectral envelope .", "speaker": "B"}, {"text": "you have something about the excitation ,", "speaker": "B"}, {"text": "and what is it about the excitation ,", "speaker": "B"}, {"text": "and , and you 're not getting the excitation anyway , .", "speaker": "B"}, {"text": "so would almost take", "speaker": "B"}, {"text": "especially if these trainings and are faster , would almost just take , scattershot at few different ways of look of characterizing that difference", "speaker": "B"}, {"text": "and , , you could have one of them but and see , , which of them helps .", "speaker": "B"}, {"text": "so is the idea that you 're going to take whatever features you develop and just add them onto the future vector ?", "speaker": "C"}, {"text": "or , what 's the use of the voiced - unvoiced detector ?", "speaker": "C"}, {"text": "we exactly yet .", "speaker": "A"}, {"text": "it 's not part of vad system that you 're doing ?", "speaker": "C"}, {"text": "no , the idea was , , to use them as features .", "speaker": "A"}, {"text": "it could be , it could be neural network that does voiced and unvoiced detection ,", "speaker": "A"}, {"text": "but it could be in the also the big neural network that does phoneme classification .", "speaker": "A"}, {"text": "but each one of the mixture components", "speaker": "B"}, {"text": "you have , , variance only ,", "speaker": "B"}, {"text": "so it 's like you 're just multiplying together these , , probabilities from the individual features within each mixture .", "speaker": "B"}, {"text": "it 's neat thing .", "speaker": "C"}, {"text": "it seems like good idea .", "speaker": "C"}, {"text": "know that , , people doing some robustness things ways back were just doing just being gross and just throwing in the fft", "speaker": "B"}, {"text": "and actually it wasn't wasn't so bad .", "speaker": "B"}, {"text": "and that it 's gotta hurt you little bit to not have spectral , smooth spectral envelope ,", "speaker": "B"}, {"text": "so there must be something else that you get in return for that", "speaker": "B"}, {"text": "'m going in too much detail ,", "speaker": "C"}, {"text": "but how exactly do you make the difference between the fft and the smoothed spectral envelope ?", "speaker": "C"}, {"text": "wha - wh , how is that , ?", "speaker": "C"}, {"text": "how did we do it up again ?", "speaker": "A"}, {"text": "we distend the we have the twenty - three coefficient af after the mel filter ,", "speaker": "F"}, {"text": "and we extend these coefficient between the all the frequency range .", "speaker": "F"}, {"text": "and the interpolation between give for the triang triangular filter , the value of the triangular filter", "speaker": "F"}, {"text": "and of this way we obtained this mode this model speech .", "speaker": "F"}, {"text": "so you essentially take the values that that you get from the triangular filter and extend them", "speaker": "B"}, {"text": "to sor like rectangle , that 's at that value .", "speaker": "B"}, {"text": "we have linear interpolation .", "speaker": "A"}, {"text": "so we have we have one point for one energy for each filter bank ,", "speaker": "A"}, {"text": "mmm , it 's linear .", "speaker": "F"}, {"text": "which is the energy that 's centered on on the triangle", "speaker": "A"}, {"text": "at the center of the filter", "speaker": "F"}, {"text": "so you end up with vector that 's the same length as the fft vector ?", "speaker": "C"}, {"text": "and then you just , , compute differences", "speaker": "C"}, {"text": "have here one example if you if you want see something like that .", "speaker": "F"}, {"text": "then we compute the difference .", "speaker": "A"}, {"text": "sum the differences ?", "speaker": "C"}, {"text": "and the variance is computed only from , like , two hundred hertz to one to fifteen hundred .", "speaker": "A"}, {"text": "two thou two fifteen hundred ?", "speaker": "F"}, {"text": "two hundred and fifty thousand .", "speaker": "F"}, {"text": "two thousand and fifteen hundred .", "speaker": "F"}, {"text": "above , it seems that", "speaker": "A"}, {"text": "some voiced sound can have also , like , noisy part on high frequencies ,", "speaker": "A"}, {"text": "no , it 's makes sense to look at low frequencies .", "speaker": "B"}, {"text": "so this is , this is comparing an original version of the signal to smoothed version of the same signal ?", "speaker": "C"}, {"text": "so so this is", "speaker": "B"}, {"text": "you could argue about whether it should be linear interpolation or or zeroeth order ,", "speaker": "B"}, {"text": "at any rate something like this is what you 're feeding your recognizer , typically .", "speaker": "B"}, {"text": "like which of the ?", "speaker": "C"}, {"text": "so the mel cepstrum is the is the cepstrum of this , , spectrum or log spectrum ,", "speaker": "B"}, {"text": "you - you 're subtracting in power domain or log domain ?", "speaker": "B"}, {"text": "in log domain .", "speaker": "A"}, {"text": "so it 's like division , when you do the , the spectra .", "speaker": "B"}, {"text": "it 's the ratio .", "speaker": "C"}, {"text": "but , anyway ,", "speaker": "B"}, {"text": "so what 's , what 's the intuition behind this thing ?", "speaker": "C"}, {"text": "really know the signal - processing enough to understand what is that doing .", "speaker": "C"}, {"text": "what happen if what we have what we would like to have is some spectrum of the excitation signal ,", "speaker": "A"}, {"text": "that makes sense .", "speaker": "B"}, {"text": "which is for voiced sound ideally", "speaker": "A"}, {"text": "and for unvoiced it 's something that 's more flat .", "speaker": "A"}, {"text": "and the way to do this is that", "speaker": "A"}, {"text": "we have the we have the fft because it 's computed in the in the system ,", "speaker": "A"}, {"text": "and we have the mel filter banks ,", "speaker": "A"}, {"text": "and so if we if we , like , remove the mel filter bank from the fft , we have something that 's close to the excitation signal .", "speaker": "A"}, {"text": "it 's something that 's like train of pulse train for voiced sound", "speaker": "A"}, {"text": "and that 's that should be flat for", "speaker": "A"}, {"text": "so do you have picture that sh ?", "speaker": "C"}, {"text": "so - it 's", "speaker": "A"}, {"text": "is this for voiced segment ,", "speaker": "C"}, {"text": "what does it look like for unvoiced ?", "speaker": "C"}, {"text": "you have several some unvoiced ?", "speaker": "A"}, {"text": "no . unvoiced , don't have", "speaker": "F"}, {"text": "so , , all", "speaker": "B"}, {"text": "this is the between", "speaker": "F"}, {"text": "this is another voiced example .", "speaker": "A"}, {"text": "but it 's this ,", "speaker": "F"}, {"text": "but between the frequency that we are considered for the excitation", "speaker": "F"}, {"text": "and this is the difference .", "speaker": "F"}, {"text": "this is the difference .", "speaker": "C"}, {"text": "so , , it 's around zero ,", "speaker": "A"}, {"text": "because we begin , , in fifteen point the fifteen point .", "speaker": "F"}, {"text": "does the periodicity of this signal say something about the", "speaker": "C"}, {"text": "it 's the pitch .", "speaker": "A"}, {"text": "that 's like fundamental frequency .", "speaker": "B"}, {"text": "to first order what you 'd what you 're doing", "speaker": "B"}, {"text": "ignore all the details and all the ways which is that these are complete lies .", "speaker": "B"}, {"text": "the , what you 're doing in feature extraction for speech recognition is you have , , in your head simplified production model for speech ,", "speaker": "B"}, {"text": "in which you have periodic or aperiodic source that 's driving some filters .", "speaker": "B"}, {"text": "this is the auto - correlation the - zero energy .", "speaker": "F"}, {"text": "do you have the mean", "speaker": "A"}, {"text": "do you have the mean for the auto - correlation ?", "speaker": "A"}, {"text": "first order for speech recognition , you say \" don't care about the source \" .", "speaker": "B"}, {"text": "for the energy .", "speaker": "A"}, {"text": "have the mean .", "speaker": "F"}, {"text": "and so you just want to find out what the filters are .", "speaker": "B"}, {"text": "the filters roughly act like , , an overall resonant , some resonances and that that 's processing excitation .", "speaker": "B"}, {"text": "they should be more close .", "speaker": "A"}, {"text": "this is this ?", "speaker": "F"}, {"text": "more close . is this ?", "speaker": "F"}, {"text": "this is there is less difference .", "speaker": "A"}, {"text": "so if you look at the spectral envelope , just the very smooth properties of it , you get something closer to that .", "speaker": "B"}, {"text": "this is less it 's less robust .", "speaker": "A"}, {"text": "and the notion is if you have the full spectrum , with all the little nitty - gritty details , that has the effect of both ,", "speaker": "B"}, {"text": "and it would be multiplication in frequency domain", "speaker": "B"}, {"text": "so that would be like an addition in log power spectrum domain .", "speaker": "B"}, {"text": "and so this is saying , , if you really do have that vocal tract envelope , and you subtract that off , what you get is the excitation .", "speaker": "B"}, {"text": "and call that lies because you don't really have that ,", "speaker": "B"}, {"text": "you just have some signal - processing trickery to get something that 's smooth .", "speaker": "B"}, {"text": "it 's not really what 's happening in the vocal tract", "speaker": "B"}, {"text": "so you 're not really getting the vocal excitation .", "speaker": "B"}, {"text": "that 's why was going to the why was referring to it in more more , , conservative way ,", "speaker": "B"}, {"text": "when was saying \" , it 's", "speaker": "B"}, {"text": "it 's the excitation \" .", "speaker": "B"}, {"text": "but it 's not really the excitation .", "speaker": "B"}, {"text": "it 's whatever it is that 's different between", "speaker": "B"}, {"text": "this moved in the", "speaker": "C"}, {"text": "so so , stand standing back from that , you say there 's this very detailed representation .", "speaker": "B"}, {"text": "you go to smooth representation .", "speaker": "B"}, {"text": "you go to smooth representation cuz this typically generalizes better .", "speaker": "B"}, {"text": "but whenever you smooth you lose something ,", "speaker": "B"}, {"text": "so the question is have you lost something you can you use ?", "speaker": "B"}, {"text": "probably you wouldn't want to go to the extreme of just ta saying \" , our feature set will be the fft \" ,", "speaker": "B"}, {"text": "cuz we really think we do gain something in robustness from going to something smoother ,", "speaker": "B"}, {"text": "but there 's something that we missed .", "speaker": "B"}, {"text": "so what is it ?", "speaker": "B"}, {"text": "and then you go back to the intuition that ,", "speaker": "B"}, {"text": "you don't really get the excitation ,", "speaker": "B"}, {"text": "but you get something related to it .", "speaker": "B"}, {"text": "and it and as you can see from those pictures , you do get something that shows some periodicity , , in frequency ,", "speaker": "B"}, {"text": "and and also in time .", "speaker": "B"}, {"text": "that 's that 's really neat .", "speaker": "C"}, {"text": "so you don't have one for unvoiced picture ?", "speaker": "C"}, {"text": "but not here .", "speaker": "F"}, {"text": "but presumably you 'll see something that won't have this , , , regularity in frequency , , in the", "speaker": "B"}, {"text": "would li would like to see those pictures .", "speaker": "C"}, {"text": "'t see you now .", "speaker": "F"}, {"text": "and so you said this is pretty", "speaker": "C"}, {"text": "doing this thing is pretty robust to noise ?", "speaker": "C"}, {"text": "the mean is different with it ,", "speaker": "F"}, {"text": "because the histogram for the classifica", "speaker": "F"}, {"text": "no , no .", "speaker": "A"}, {"text": "but the robustness to noise", "speaker": "A"}, {"text": "so if you take this frame , , from the noisy utterance and the same frame from the clean utterance", "speaker": "A"}, {"text": "you end up with similar difference", "speaker": "C"}, {"text": "we end up with", "speaker": "A"}, {"text": "have here the same frame for the clean speech", "speaker": "F"}, {"text": "that 's clean .", "speaker": "C"}, {"text": "but they are difference .", "speaker": "F"}, {"text": "because here the fft is only with two hundred fifty - six point", "speaker": "F"}, {"text": "and this is with five hundred twelve .", "speaker": "F"}, {"text": "this is inter interesting also", "speaker": "A"}, {"text": "because if we use the standard , , frame length of , like , twenty - five milliseconds , , what happens is that for low - pitched voiced , because of the frame length , you don't really have you don't clearly see this periodic structure ,", "speaker": "A"}, {"text": "because of the first lobe of each of the harmonics .", "speaker": "A"}, {"text": "so this one inclu is longer .", "speaker": "C"}, {"text": "so , this is like , fifty milliseconds like that .", "speaker": "A"}, {"text": "but it 's the same frame", "speaker": "A"}, {"text": "it 's that time - frequency trade - off thing .", "speaker": "C"}, {"text": ", so this is this the difference here ,", "speaker": "C"}, {"text": "this is the signal .", "speaker": "F"}, {"text": "this is the signal .", "speaker": "F"}, {"text": "that 's the the original .", "speaker": "C"}, {"text": "this is the fra the original frame .", "speaker": "F"}, {"text": "so with short frame you have only two periods", "speaker": "A"}, {"text": "and it 's not enough to have this neat things .", "speaker": "A"}, {"text": "so probably we 'll have to use , like , long long frames .", "speaker": "A"}, {"text": "that 's interesting .", "speaker": "C"}, {"text": "it looks better ,", "speaker": "B"}, {"text": "but , , if , if you 're actually asking , if you actually , need to do place along an fft , it may be it may be pushing things .", "speaker": "B"}, {"text": "would you would you wanna do this , , difference thing after you do spectral subtraction ?", "speaker": "C"}, {"text": "we can do that .", "speaker": "F"}, {"text": "the spectral subtraction is being done", "speaker": "B"}, {"text": "at what level ? is it being done", "speaker": "B"}, {"text": "at the level of fft bins", "speaker": "B"}, {"text": "or at the level of , , mel spectrum ?", "speaker": "B"}, {"text": "how are they doing it ?", "speaker": "B"}, {"text": "how they 're doing it ?", "speaker": "A"}, {"text": "ericsson is on the , , filter bank ,", "speaker": "A"}, {"text": "fft . filter bank ,", "speaker": "F"}, {"text": "it 's on the filter bank ,", "speaker": "A"}, {"text": "so in that case , it might not make much difference .", "speaker": "B"}, {"text": "seems like you 'd wanna do it on the fft bins .", "speaker": "C"}, {"text": "certainly it 'd be better .", "speaker": "B"}, {"text": "if you were gonna", "speaker": "C"}, {"text": "for this purpose , that is .", "speaker": "C"}, {"text": "that 's all .", "speaker": "A"}, {"text": "so we 'll perhaps try to convince ogi people to use the new the new filters", "speaker": "A"}, {"text": "has anything happened yet on this business of having some standard , , source ,", "speaker": "B"}, {"text": "but wi will call them", "speaker": "A"}, {"text": "now they are they have more time", "speaker": "A"}, {"text": "because they have this", "speaker": "A"}, {"text": "eurospeech deadline is over", "speaker": "A"}, {"text": "when is the next , , aurora deadline ?", "speaker": "C"}, {"text": "it 's , , in june .", "speaker": "A"}, {"text": "and he 's been doing all the talking", "speaker": "B"}, {"text": "but these he 's he 's ,", "speaker": "B"}, {"text": "this is this bad thing .", "speaker": "B"}, {"text": "we 're trying to get , , more female voices in this record as .", "speaker": "B"}, {"text": "make sur make carmen talks as .", "speaker": "B"}, {"text": "but has he been talking about what you 're doing also ,", "speaker": "B"}, {"text": "am doing this .", "speaker": "F"}, {"text": "that for the recognizer for the meeting recorder that it 's better that don't speak .", "speaker": "F"}, {"text": ", we 'll get we 'll get to , , spanish voices sometime ,", "speaker": "B"}, {"text": "and we do we want to recognize , , you too .", "speaker": "B"}, {"text": "after the after , , the result for the ti - digits on the meeting record there will be foreigns people .", "speaker": "F"}, {"text": "we like we 're", "speaker": "B"}, {"text": "we are we 're in the , , bourlard - hermansky - morgan , , frame of mind .", "speaker": "B"}, {"text": "we like high error rates .", "speaker": "B"}, {"text": "that way there 's lots of work to do .", "speaker": "B"}, {"text": "not much is new .", "speaker": "D"}, {"text": "so when talked about what 'm planning to do last time , said was , , going to use avendano 's method of , , using transformation , , to map from long analysis frames which are used for removing reverberation to short analysis frames for feature calculation .", "speaker": "D"}, {"text": "he has trick for doing that involving viewing the dft as matrix .", "speaker": "D"}, {"text": "but , , , decided not to do that after all", "speaker": "D"}, {"text": "because realized to use it 'd need to have these short analysis frames get plugged directly into the feature computation somehow", "speaker": "D"}, {"text": "and now our feature computation is set to up to , , take , , audio as input , in general .", "speaker": "D"}, {"text": "so decided that 'll do the reverberation removal on the long analysis windows", "speaker": "D"}, {"text": "and then just re - synthesize audio", "speaker": "D"}, {"text": "and then send that .", "speaker": "D"}, {"text": "this is in order to use the sri system .", "speaker": "B"}, {"text": "or even if 'm using our system , was thinking it might be easier to just re - synthesize the audio ,", "speaker": "D"}, {"text": "because then could just feacalc as is", "speaker": "D"}, {"text": "and wouldn't have to change the code .", "speaker": "D"}, {"text": "certainly in short - term this just sounds easier .", "speaker": "B"}, {"text": "longer - term if it 's if it turns out to be useful , one might want to do something else ,", "speaker": "B"}, {"text": "that 's true .", "speaker": "D"}, {"text": ", , in other words , you may be putting other kinds of errors in from the re - synthesis process .", "speaker": "B"}, {"text": "from the re - synthesis ?", "speaker": "D"}, {"text": "anything about re - synthesis .", "speaker": "D"}, {"text": "how likely do you think that is ?", "speaker": "D"}, {"text": "it depends what you what you do .", "speaker": "B"}, {"text": "it 's it 's , ,", "speaker": "B"}, {"text": "but anyway it sounds like reasonable way to go for for an initial thing ,", "speaker": "B"}, {"text": "and we can look at exactly what you end up doing", "speaker": "B"}, {"text": "and then figure out if there 's some something that could be hurt by the end part of the process .", "speaker": "B"}, {"text": "that was it , ?", "speaker": "B"}, {"text": "that , that 's it , that 's it .", "speaker": "D"}, {"text": "anything to add ?", "speaker": "B"}, {"text": "'ve been continuing reading .", "speaker": "E"}, {"text": "went off on little tangent this past week ,", "speaker": "E"}, {"text": "looking at , , , modulation spectrum ,", "speaker": "E"}, {"text": "and learning bit about what , what it is ,", "speaker": "E"}, {"text": "and , , the importance of it in speech recognition .", "speaker": "E"}, {"text": "and found some , , neat papers , , historical papers from , , kanedera , hermansky , and arai .", "speaker": "E"}, {"text": "and they did lot of experiments where where , , they take speech and , , they modify the ,", "speaker": "E"}, {"text": "they they measure the relative importance of having different , , portions of the modulation spectrum intact .", "speaker": "E"}, {"text": "and they find that the spectrum between one and sixteen hertz in the modulation is , is im important for speech recognition .", "speaker": "E"}, {"text": "this goes back to earlier by drullman .", "speaker": "B"}, {"text": "and and , , the msg features were built up with this notion", "speaker": "B"}, {"text": "but , , you had brought this up in the context of , , targets somehow .", "speaker": "B"}, {"text": "it 's not , they 're not in the same category as , say , phonetic target or syllabic target", "speaker": "B"}, {"text": "was thinking more like using them as the inputs to the detectors .", "speaker": "E"}, {"text": "that 's what msg does .", "speaker": "B"}, {"text": "anyway , we 'll talk more about it later .", "speaker": "B"}, {"text": "we can talk more about it later .", "speaker": "E"}, {"text": "should we do digits ?", "speaker": "C"}, {"text": "let 's do digits .", "speaker": "B"}, {"text": "let you start .", "speaker": "B"}], "id": "xxxxx", "relations": [{"y": 1, "x": 0, "type": "Explanation"}]}]