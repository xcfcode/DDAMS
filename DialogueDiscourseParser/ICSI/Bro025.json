[{"edus": [{"text": "alright . we 're on .", "speaker": "A"}, {"text": "test , . test , test .", "speaker": "B"}, {"text": "that 's me .", "speaker": "B"}, {"text": "there 's two sheets of paper in front of us .", "speaker": "B"}, {"text": "what are these ?", "speaker": "A"}, {"text": "this is the arm wrestling ?", "speaker": "B"}, {"text": ", we formed coalition actually .", "speaker": "C"}, {"text": "we already made it into one .", "speaker": "C"}, {"text": "that 's the best thing .", "speaker": "B"}, {"text": "so , tell me about it .", "speaker": "B"}, {"text": "so it 's , it 's spectral subtraction or wiener filtering ,", "speaker": "E"}, {"text": "depending on if we put if we square the transfer function or not .", "speaker": "E"}, {"text": "and then with over - estimation of the noise , depending on the , the snr , with smoothing along time ,", "speaker": "E"}, {"text": "smoothing along frequency .", "speaker": "E"}, {"text": "it 's very simple , smoothing things .", "speaker": "E"}, {"text": "and , , the best result is when we apply this procedure on fft bins , , with wiener filter .", "speaker": "E"}, {"text": "and there is no noise addition after that .", "speaker": "E"}, {"text": "so it 's good", "speaker": "E"}, {"text": "because it 's difficult when we have to add noise to to find the level .", "speaker": "E"}, {"text": "are you looking at one in particular of these two ?", "speaker": "A"}, {"text": "so the sh it 's the sheet that gives fifty - three point sixty - six .", "speaker": "E"}, {"text": "the second sheet is abo , about the same .", "speaker": "E"}, {"text": "it 's the same , , idea but it 's working on mel bands , and it 's spectral subtraction instead of wiener filter ,", "speaker": "E"}, {"text": "and there is also noise addition after , , cleaning up the mel bins .", "speaker": "E"}, {"text": "the results are similar .", "speaker": "E"}, {"text": ", it 's it 's actually , , very similar .", "speaker": "B"}, {"text": "if you look at databases ,", "speaker": "B"}, {"text": "the , , one that has the smallest smaller overall number is actually better on the finnish and spanish ,", "speaker": "B"}, {"text": "but it is , , worse on the , , aurora", "speaker": "B"}, {"text": "it 's worse on", "speaker": "E"}, {"text": "on the , , ti - digits ,", "speaker": "B"}, {"text": "on the multi - condition in ti - digits . .", "speaker": "E"}, {"text": "so , it probably doesn't matter that much either way .", "speaker": "B"}, {"text": "but , , when you say , unified do you mean , , it 's one piece of software now ,", "speaker": "B"}, {"text": "so now we are , , setting up the software .", "speaker": "E"}, {"text": "it should be ready , , very soon .", "speaker": "E"}, {"text": "so what 's what 's happened ?", "speaker": "A"}, {"text": "'ve missed something .", "speaker": "A"}, {"text": "you weren't around when when hynek and guenther and ?", "speaker": "B"}, {"text": "hynek was here .", "speaker": "C"}, {"text": ". so , let 's summarize .", "speaker": "B"}, {"text": "and then if summarize somebody can tell me if 'm wrong ,", "speaker": "B"}, {"text": "which will also be possibly helpful .", "speaker": "B"}, {"text": "what did press here ?", "speaker": "B"}, {"text": "hope this is still working .", "speaker": "B"}, {"text": "we , we looked at , {nonvocalsound}", "speaker": "B"}, {"text": "anyway we after coming back from qualcomm we had , , very strong feedback", "speaker": "B"}, {"text": "and , , it was hynek and guenter 's and my opinion also that , , , we spread out to look at number of different ways of doing noise suppression .", "speaker": "B"}, {"text": "but given the limited time , , it was time to choose one .", "speaker": "B"}, {"text": "and so , , the vector taylor series hadn't really worked out that much .", "speaker": "B"}, {"text": "the subspace , , had not been worked with so much .", "speaker": "B"}, {"text": "so it came down to spectral subtraction versus wiener filtering .", "speaker": "B"}, {"text": "we had long discussion about how they were the same and how they were , completely different .", "speaker": "B"}, {"text": "and , , , fundamentally they 're the same thing", "speaker": "B"}, {"text": "but the math is little different", "speaker": "B"}, {"text": "so that there 's there 's an exponent difference in the index", "speaker": "B"}, {"text": "what 's the ideal filtering ,", "speaker": "B"}, {"text": "and depending on how you construct the problem .", "speaker": "B"}, {"text": "and , , it 's sort , after that meeting it made more sense to me", "speaker": "B"}, {"text": "because , if you 're dealing with power spectra then how are you gonna choose your error ?", "speaker": "B"}, {"text": "and typically you 'll do choose something like variance .", "speaker": "B"}, {"text": "and so that means it 'll be something like the square of the power spectra .", "speaker": "B"}, {"text": "whereas when you 're when you 're doing the , , , looking at it the other way , you 're gonna be dealing with signals", "speaker": "B"}, {"text": "and you 're gonna end up looking at power , noise power that you 're trying to reduce .", "speaker": "B"}, {"text": "and so , so there should be difference of , conceptually of , , factor of two in the exponent .", "speaker": "B"}, {"text": "but there 're so many different little factors that you adjust in terms of , , , over - subtraction and and ,", "speaker": "B"}, {"text": "that arguably , you 're", "speaker": "B"}, {"text": "and and the choice of do you do you operate on the mel bands or do you operate on the fft beforehand .", "speaker": "B"}, {"text": "there 're so many other choices to make that are almost , if not independent , certainly in addition to the choice of whether you , , do spectral subtraction or wiener filtering ,", "speaker": "B"}, {"text": "that , , @ @ again we felt the gang should just figure out which it is they wanna do", "speaker": "B"}, {"text": "and then let 's pick it ,", "speaker": "B"}, {"text": "go forward with it .", "speaker": "B"}, {"text": "so that 's that was last week .", "speaker": "B"}, {"text": "and and , , we said , , take week , go arm wrestle ,", "speaker": "B"}, {"text": "figure it out .", "speaker": "B"}, {"text": "and the joke there was that each of them had specialized in one of them .", "speaker": "B"}, {"text": "and and so they", "speaker": "B"}, {"text": "so instead they went to yosemite and bonded , and they came out with single piece of software .", "speaker": "B"}, {"text": "so it 's another victory for international collaboration .", "speaker": "B"}, {"text": "so so you have combined or you 're going to be combining the software ?", "speaker": "A"}, {"text": "the piece of software has , like , plenty of options ,", "speaker": "C"}, {"text": "like you can parse command - line arguments .", "speaker": "C"}, {"text": "so depending on that , it becomes either spectral subtraction or wiener filtering .", "speaker": "C"}, {"text": "they 're close enough .", "speaker": "A"}, {"text": "that 's fine ,", "speaker": "B"}, {"text": "but the important thing is that there is piece of software that you that we all will be using now .", "speaker": "B"}, {"text": "there 's just one piece of software .", "speaker": "C"}, {"text": "need to allow it to do everything and even more than this .", "speaker": "E"}, {"text": "if we want to , like , optimize different parameters of", "speaker": "E"}, {"text": "we can do it later .", "speaker": "E"}, {"text": "but , still so , there will be piece of software with , , will give this system , the fifty - three point sixty - six , by default", "speaker": "E"}, {"text": "how how is how good is that ?", "speaker": "A"}, {"text": "don't have sense of", "speaker": "A"}, {"text": "it 's just one percent off of the best proposal .", "speaker": "E"}, {"text": "it 's between we are second actually if we take this system .", "speaker": "E"}, {"text": "compared to the last evaluation numbers ? .", "speaker": "A"}, {"text": "which we were before", "speaker": "B"}, {"text": "but we were considerably far behind .", "speaker": "B"}, {"text": "and , this doesn't have neural net in yet .", "speaker": "B"}, {"text": "so it so , , it 's it 's not using our full bal bag of tricks , if you will .", "speaker": "B"}, {"text": "and , , and it is , , very close in performance to the best thing that was there before .", "speaker": "B"}, {"text": "but , , looking at it another way , more importantly , , we didn't have any explicit noise , , handling", "speaker": "B"}, {"text": "we didn't explicitly have anything to deal with stationary noise .", "speaker": "B"}, {"text": "and now we do .", "speaker": "B"}, {"text": "so will the neural net operate on the output from either the wiener filtering or the spectral subtraction ?", "speaker": "A"}, {"text": "or will it operate on the original ?", "speaker": "A"}, {"text": "so so argu arguably , , what we should do", "speaker": "B"}, {"text": "gather you have it sounds like you have few more days of nailing things down with the software and so on .", "speaker": "B"}, {"text": "but and then but , , arguably what we should do is , even though the software can do many things , we should for now pick set of things ,", "speaker": "B"}, {"text": "these things would ,", "speaker": "B"}, {"text": "and not change that .", "speaker": "B"}, {"text": "and then focus on everything that 's left .", "speaker": "B"}, {"text": "and , , that our goal should be by next week , when hynek comes back , , to , really just to have firm path , , for the , for the time he 's gone ,", "speaker": "B"}, {"text": "of , , what things will be attacked .", "speaker": "B"}, {"text": "but would would thought think that what we would wanna do is not futz with this for while", "speaker": "B"}, {"text": "because what 'll happen is we 'll change many other things in the system ,", "speaker": "B"}, {"text": "and then we 'll probably wanna come back to this and possibly make some other choices .", "speaker": "B"}, {"text": "but just conceptually , where does the neural net go ?", "speaker": "A"}, {"text": "do do you wanna run it on the output of the spectrally subtracted ?", "speaker": "A"}, {"text": "depending on its size", "speaker": "B"}, {"text": "one question is , is it on the , , server side or is it on the terminal side ?", "speaker": "B"}, {"text": "if it 's on the server side , it you probably don't have to worry too much about size .", "speaker": "B"}, {"text": "so that 's an argument for that .", "speaker": "B"}, {"text": "we do still , however , have to consider its latency .", "speaker": "B"}, {"text": "so the issue is , , , could we have neural net that only looked at the past ?", "speaker": "B"}, {"text": "what we 've done in in the past is to use the neural net , , to transform , , all of the features that we use .", "speaker": "B"}, {"text": "so this is done early on .", "speaker": "B"}, {"text": "this is essentially , , it 's it 's more or less like spee speech enhancement technique here", "speaker": "B"}, {"text": "where we 're just creating new if not new speech at least new fft 's", "speaker": "B"}, {"text": "that have , which could be turned into speech", "speaker": "B"}, {"text": "that have some of the noise removed .", "speaker": "B"}, {"text": "after that we still do mess of other things to produce bunch of features .", "speaker": "B"}, {"text": "and then those features are not now currently transformed by the neural net .", "speaker": "B"}, {"text": "and then the way that we had it in our proposal - two before , we had the neural net transformed features and we had the untransformed features ,", "speaker": "B"}, {"text": "which you actually did linearly transform with the klt ,", "speaker": "B"}, {"text": "but , to orthogonalize them", "speaker": "B"}, {"text": "but they were not , , processed through neural net .", "speaker": "B"}, {"text": "and stephane 's idea with that , as recall , was that you 'd have one part of the feature vector that was very discriminant and another part that wasn't ,", "speaker": "B"}, {"text": "which would smooth things bit for those occasions when , , the testing set was quite different than what you 'd trained your discriminant features for .", "speaker": "B"}, {"text": "so , , all of that is , still seems like good idea .", "speaker": "B"}, {"text": "now we know some other constraints .", "speaker": "B"}, {"text": "we can't have unlimited amounts of latency .", "speaker": "B"}, {"text": ", that 's still being debated by the by people in europe", "speaker": "B"}, {"text": "but , , no matter how they end up there , it 's not going to be unlimited amounts ,", "speaker": "B"}, {"text": "so we have to be little conscious of that .", "speaker": "B"}, {"text": "so there 's the neural net issue .", "speaker": "B"}, {"text": "there 's the vad issue .", "speaker": "B"}, {"text": "and , , there 's the second stream thing .", "speaker": "B"}, {"text": "and those that we last time we that those are the three things that have to get , , focused on .", "speaker": "B"}, {"text": "what was the issue with the vad ?", "speaker": "A"}, {"text": "better ones are good .", "speaker": "B"}, {"text": "and so the the default , , boundaries that they provide are they 're , but they 're not all that ?", "speaker": "A"}, {"text": "they still allow two hundred milliseconds on either side or some ?", "speaker": "B"}, {"text": "is that what the deal is ?", "speaker": "B"}, {"text": "so , they keep two hundred milliseconds at the beginning and end of speech . and they keep all the", "speaker": "E"}, {"text": "outside the beginnings and end .", "speaker": "A"}, {"text": "and all the speech pauses ,", "speaker": "E"}, {"text": "which is sometimes on the speechdat - car you have pauses that are more than one or two seconds .", "speaker": "E"}, {"text": "more than one second for .", "speaker": "E"}, {"text": "and , , it seems to us that this way of just dropping the beginning and end is not", "speaker": "E"}, {"text": "we cou we can do better , ,", "speaker": "E"}, {"text": "because , , with this way of dropping the frames they improve over the baseline by fourteen percent", "speaker": "E"}, {"text": "and sunil already showed that with our current vad we can improve by more than twenty percent .", "speaker": "E"}, {"text": "on top of the vad that they provide ?", "speaker": "A"}, {"text": "just using either their vad or our current vad .", "speaker": "E"}, {"text": "so , our current vad is more than twenty percent ,", "speaker": "E"}, {"text": "while their is fourteen .", "speaker": "E"}, {"text": "theirs is fourteen ?", "speaker": "A"}, {"text": "and another thing that we did also is that we have all this training data for let 's say , for speechdat - car .", "speaker": "E"}, {"text": "we have channel zero which is clean ,", "speaker": "E"}, {"text": "channel one which is far - field microphone .", "speaker": "E"}, {"text": "if we just take only the , , vad probabilities computed on the clean signal and apply them on the far - field , , test utterances , then results are much better .", "speaker": "E"}, {"text": "in some cases it divides the error rate by two .", "speaker": "E"}, {"text": "so it means that there are stim still", "speaker": "E"}, {"text": "how how much latency does the , does our vad add ?", "speaker": "A"}, {"text": "if if we can have good vad , , it would be .", "speaker": "E"}, {"text": "is it significant ,", "speaker": "A"}, {"text": "now it 's , , neural net with nine frames .", "speaker": "E"}, {"text": "so it 's forty milliseconds plus , , the rank ordering ,", "speaker": "E"}, {"text": "which , , should be", "speaker": "E"}, {"text": "like another ten frames .", "speaker": "C"}, {"text": "so , now it 's one hundred and forty milliseconds .", "speaker": "E"}, {"text": "with the rank ordering ?", "speaker": "B"}, {"text": "the the smoothing the the filtering of the probabilities .", "speaker": "C"}, {"text": "it 's not median filtering .", "speaker": "E"}, {"text": "it 's just we don't take the median value . we take something", "speaker": "E"}, {"text": "so we have eleven , , frames .", "speaker": "E"}, {"text": "this is for the vad .", "speaker": "B"}, {"text": "for the vad ,", "speaker": "E"}, {"text": "and we take the third .", "speaker": "E"}, {"text": "so , was just noticing on this that it makes reference to delay .", "speaker": "B"}, {"text": "so what 's the ? if you ignore", "speaker": "B"}, {"text": "the vad is in parallel ,", "speaker": "B"}, {"text": "isn't isn't it ,", "speaker": "B"}, {"text": "with the ? , it isn't additive with the , , lda and the wiener filtering , and .", "speaker": "B"}, {"text": "so so what happened now , we removed the delay of the lda .", "speaker": "C"}, {"text": "so we , if so if we if so which is like if we reduce the delay of va", "speaker": "C"}, {"text": "so , the the final delay 's now ba is determined by the delay of the vad ,", "speaker": "C"}, {"text": "because the lda doesn't have any delay .", "speaker": "C"}, {"text": "so if we re if we reduce the delay of the vad , , it 's like effectively reducing the delay .", "speaker": "C"}, {"text": "how how much , , delay was there on the lda ?", "speaker": "A"}, {"text": "so the lda and the vad both had hundred millisecond delay .", "speaker": "C"}, {"text": "so and they were in parallel ,", "speaker": "C"}, {"text": "so which means you pick either one of them", "speaker": "C"}, {"text": "the biggest , whatever .", "speaker": "C"}, {"text": "so , now the lda delays are more .", "speaker": "C"}, {"text": "and there didn't seem to be any , , penalty for that ?", "speaker": "B"}, {"text": "there didn't seem to be any penalty for making it causal ?", "speaker": "B"}, {"text": "no . it actually made it , like , point one percent better , actually .", "speaker": "C"}, {"text": "may as , then .", "speaker": "B"}, {"text": "and he says wiener filter is forty milliseconds delay .", "speaker": "B"}, {"text": "so is it ?", "speaker": "B"}, {"text": "so that 's the one which stephane was discussing , like", "speaker": "C"}, {"text": "the you smooth it and then delay the decision by", "speaker": "C"}, {"text": "so that 's that 's really not bad .", "speaker": "B"}, {"text": "so we may we 'll see what they decide . we may have , , the , , latency time available for to have neural net .", "speaker": "B"}, {"text": "sounds like we probably will .", "speaker": "B"}, {"text": "that 'd be good .", "speaker": "B"}, {"text": "cuz cuz it certainly always helped us before .", "speaker": "B"}, {"text": "what amount of latency are you thinking about when you say that ?", "speaker": "A"}, {"text": "they 're , they 're disputing it .", "speaker": "B"}, {"text": "they 're saying , one group is saying hundred and thirty milliseconds and another group is saying two hundred and fifty milliseconds .", "speaker": "B"}, {"text": "two hundred and fifty is what it was before actually .", "speaker": "B"}, {"text": "some people are lobbying to make it shorter .", "speaker": "B"}, {"text": "were you thinking of the two - fifty or the one - thirty when you said we should have enough for the neural net ?", "speaker": "A"}, {"text": "it just it when we find that out it might change exactly how we do it , is all .", "speaker": "B"}, {"text": "how much effort do we put into making it causal ?", "speaker": "B"}, {"text": "the neural net will probably do better if it looks at little bit of the future .", "speaker": "B"}, {"text": "but , , it will probably work to some extent to look only at the past .", "speaker": "B"}, {"text": "and we ha , limited machine and human time , and effort .", "speaker": "B"}, {"text": "and , , how much time should we put into that ?", "speaker": "B"}, {"text": "so it 'd be helpful if we find out from the standards folks whether , , they 're gonna restrict that or not .", "speaker": "B"}, {"text": "but , , at this point our major concern is making the performance better", "speaker": "B"}, {"text": "and , , if , , something has to take little longer in latency in order to do it that 's , secondary issue .", "speaker": "B"}, {"text": "but if we get told otherwise then , , we may have to clamp down bit more .", "speaker": "B"}, {"text": "so , the one one difference is that was there is like we tried computing the delta and then doing the frame - dropping .", "speaker": "C"}, {"text": "the earlier system was do the frame - dropping and then compute the delta on the", "speaker": "C"}, {"text": "which could be funny delta .", "speaker": "A"}, {"text": "so that 's fixed in this .", "speaker": "B"}, {"text": "we talked about that .", "speaker": "B"}, {"text": "so we have no delta . and then", "speaker": "C"}, {"text": "so the frame - dropping is the last thing that we do .", "speaker": "C"}, {"text": "so , , what we do is we compute the silence probability ,", "speaker": "C"}, {"text": "convert it to that binary flag ,", "speaker": "C"}, {"text": "and then in the end you up upsample it to match the final features number of", "speaker": "C"}, {"text": "did that help then ?", "speaker": "A"}, {"text": "it seems to be helping on the - matched condition .", "speaker": "C"}, {"text": "so that 's why this improvement got from the last result .", "speaker": "C"}, {"text": "so . and it actually reduced little bit on the high mismatch ,", "speaker": "C"}, {"text": "so in the final weightage it 's better", "speaker": "C"}, {"text": "because the - matched is still weighted more than", "speaker": "C"}, {"text": "so , @ @ , you were doing lot of changes .", "speaker": "B"}, {"text": "did you happen to notice how much , , the change was due to just this frame - dropping problem ?", "speaker": "B"}, {"text": "what about this ?", "speaker": "B"}, {"text": "you had something on it .", "speaker": "C"}, {"text": "just the frame - dropping problem .", "speaker": "E"}, {"text": "but it 's it 's difficult .", "speaker": "E"}, {"text": "sometime we change two things together", "speaker": "E"}, {"text": "and but it 's around it 's less than one percent .", "speaker": "E"}, {"text": "but like we 're saying , if there 's four or five things like that then pretty sho soon you 're talking real improvement .", "speaker": "B"}, {"text": "and then we have to be careful with that also with the neural net", "speaker": "E"}, {"text": "because in the proposal the neural net was also , , working on after frame - dropping .", "speaker": "E"}, {"text": "that 's real good point .", "speaker": "B"}, {"text": "so . , we 'll have to be", "speaker": "E"}, {"text": "to do the same correction .", "speaker": "E"}, {"text": "it might be hard if it 's at the server side .", "speaker": "B"}, {"text": "mmm . , we can do the frame - dropping on the server side", "speaker": "E"}, {"text": "or we can just be careful at the terminal side to send couple of more frames before and after ,", "speaker": "E"}, {"text": "don't quite understand how this works ,", "speaker": "A"}, {"text": "but , , couldn't you just send all of the frames , but mark the ones that are supposed to be dropped ?", "speaker": "A"}, {"text": "cuz you have bunch more bandwidth .", "speaker": "A"}, {"text": ", it always seemed to us that it would be to in addition to , , reducing insertions , actually use up less bandwidth .", "speaker": "B"}, {"text": "but nobody seems to have cared about that in this evaluation .", "speaker": "B"}, {"text": "and that way the net could use", "speaker": "A"}, {"text": "if the net 's on the server side then it could use all of the frames .", "speaker": "A"}, {"text": "yes , it could be .", "speaker": "C"}, {"text": "it 's , like , you mean you just transferred everything", "speaker": "C"}, {"text": "and then finally drop the frames after the neural net .", "speaker": "C"}, {"text": "that 's that 's one thing which", "speaker": "C"}, {"text": "but you could even mark them , before they get to the server .", "speaker": "A"}, {"text": "now what wha what we did is , like , we just mark we just have this additional bit which goes around the features , saying it 's currently it 's speech or nonspeech .", "speaker": "C"}, {"text": "so there is no frame - dropping till the final features , like , including the deltas are computed .", "speaker": "C"}, {"text": "and after the deltas are computed , you just pick up the ones that are marked silence and then drop them .", "speaker": "C"}, {"text": "so it would be more or less the same thing with the neural net , , actually .", "speaker": "B"}, {"text": "so . , that 's what that 's what , , this is doing now .", "speaker": "C"}, {"text": "what 's , ?", "speaker": "B"}, {"text": "that 's that 's good set of work that ,", "speaker": "B"}, {"text": "just one more thing .", "speaker": "C"}, {"text": "like , should we do something more for the noise estimation ,", "speaker": "C"}, {"text": "because we still ?", "speaker": "C"}, {"text": "was wondering about that .", "speaker": "B"}, {"text": "that was had written that down there .", "speaker": "B"}, {"text": "so , we , actually did the first experiment .", "speaker": "E"}, {"text": "this is with just fifteen frames .", "speaker": "E"}, {"text": "we take the first fifteen frame of each utterance to it ,", "speaker": "E"}, {"text": "and average their power spectra .", "speaker": "E"}, {"text": "tried just plugging the , , , guenter noise estimation on this system ,", "speaker": "E"}, {"text": "and it , it got worse .", "speaker": "E"}, {"text": "but didn't play with it .", "speaker": "E"}, {"text": "didn't do much more for noise estimation . tried this ,", "speaker": "E"}, {"text": ". , it 's not surprising it 'd be worse the first time .", "speaker": "B"}, {"text": "it does seem like , , some compromise between always depending on the first fifteen frames and always depending on pause is is good idea .", "speaker": "B"}, {"text": "you have to weight the estimate from the first - teen fifteen frames more heavily than was done in your first attempt .", "speaker": "B"}, {"text": "do you have any way of assessing how or how poorly the noise estimation is currently doing ?", "speaker": "B"}, {"text": "mmm . no , we don't .", "speaker": "E"}, {"text": "we don't have nothing that", "speaker": "E"}, {"text": "is there was there any experiment with ?", "speaker": "C"}, {"text": "did the only experiment where tried was used the channel zero vad for the noise estimation", "speaker": "C"}, {"text": "and frame - dropping .", "speaker": "C"}, {"text": "so don't have don't have split , like which one helped more .", "speaker": "C"}, {"text": "so . it it was the best result could get .", "speaker": "C"}, {"text": "so , that 's the", "speaker": "C"}, {"text": "so that 's something you could do with , , this final system .", "speaker": "B"}, {"text": "just do this everything that is in this final system except , , use the channel zero .", "speaker": "B"}, {"text": "for the noise estimation .", "speaker": "C"}, {"text": "we can try something .", "speaker": "C"}, {"text": "and then see how much better it gets .", "speaker": "B"}, {"text": "if it 's , , essentially not better , then it 's probably not worth", "speaker": "B"}, {"text": "but the guenter 's argument is slightly different .", "speaker": "C"}, {"text": "it 's , like , ev even if use channel zero vad , 'm just averaging the power spectrum .", "speaker": "C"}, {"text": "but the guenter 's argument is , like , if it is non - stationary segment , then he doesn't update the noise spectrum .", "speaker": "C"}, {"text": "so he 's , like he tries to capture only the stationary part in it .", "speaker": "C"}, {"text": "so the averaging is , like , different from updating the noise spectrum only during stationary segments .", "speaker": "C"}, {"text": "so , the guenter was arguing that , , even if you have very good vad , averaging it , like , over the whole thing is not good idea .", "speaker": "C"}, {"text": "because you 're averaging the stationary and the non - stationary , and finally you end up getting something", "speaker": "C"}, {"text": "which is not really the because , you anyway , you can't remove the stationary part fr , non - stationary part from the signal .", "speaker": "C"}, {"text": "not using these methods anyway . .", "speaker": "B"}, {"text": "so you just update only doing or update only the stationary components .", "speaker": "C"}, {"text": "so , that 's so that 's still slight difference from what guenter is trying", "speaker": "C"}, {"text": ". and and also there 's just the fact that , ,", "speaker": "B"}, {"text": ", although we 're trying to do very on this evaluation , , we actually would like to have something that worked in general .", "speaker": "B"}, {"text": "and , , relying on having fifteen frames at the front is pretty", "speaker": "B"}, {"text": "you might not .", "speaker": "B"}, {"text": "it 'd certainly be more robust to different kinds of input if you had at least some updates .", "speaker": "B"}, {"text": "what what do you , what do you see as being what you would be doing in the next week , given wha what 's happened ?", "speaker": "B"}, {"text": "cure the vad ?", "speaker": "C"}, {"text": "what was that ?", "speaker": "A"}, {"text": "so , should we keep the same ? we might try to keep the same idea", "speaker": "E"}, {"text": "of having neural network ,", "speaker": "E"}, {"text": "but training it on more data", "speaker": "E"}, {"text": "and adding better features , ,", "speaker": "E"}, {"text": "but because the current network is just plp features .", "speaker": "E"}, {"text": "it 's trained on noisy plp", "speaker": "E"}, {"text": "just the cepstra .", "speaker": "C"}, {"text": "plp features computed on noisy speech .", "speaker": "E"}, {"text": "but there is no nothing particularly robust in these features .", "speaker": "E"}, {"text": "there 's no rasta , no", "speaker": "E"}, {"text": "so , , don't remember what you said the answer to my , , question earlier .", "speaker": "A"}, {"text": "will you will you train the net on after you 've done the spectral subtraction or the wiener filtering ?", "speaker": "A"}, {"text": "this is different net .", "speaker": "B"}, {"text": "so we have vad which is like neur that 's neural net .", "speaker": "C"}, {"text": "you 're talking about the vad net .", "speaker": "A"}, {"text": "so that vad was trained on the noisy features .", "speaker": "C"}, {"text": "so , now we have , like , we have the cleaned - up features ,", "speaker": "C"}, {"text": "so we can have better vad by training the net on the cleaned - up speech .", "speaker": "C"}, {"text": "see . see .", "speaker": "A"}, {"text": "but we need vad for noise estimation also .", "speaker": "C"}, {"text": "so it 's , like , where do we want to put the vad ?", "speaker": "C"}, {"text": "can you use the same net to do both ,", "speaker": "A"}, {"text": "can you use the same net that you that was talking about to do the vad ?", "speaker": "A"}, {"text": "it actually comes at at the very end .", "speaker": "C"}, {"text": "so the net the final net , which is the feature net", "speaker": "C"}, {"text": "so that actually comes after chain of , like , lda plus everything .", "speaker": "C"}, {"text": "so it 's , like , it takes long time to get decision out of it .", "speaker": "C"}, {"text": "and and you can actually do it for final frame - dropping ,", "speaker": "C"}, {"text": "but not for the va - noise estimation .", "speaker": "C"}, {"text": "you see , the idea is that the , , initial decision to that you 're in silence or speech happens pretty quickly .", "speaker": "B"}, {"text": "cuz that 's used by some of these other ?", "speaker": "A"}, {"text": "and that 's fed forward , and you say \" , flush everything , it 's not speech anymore \" .", "speaker": "B"}, {"text": "that was only used for doing frame - dropping later on .", "speaker": "A"}, {"text": "it is used ,", "speaker": "B"}, {"text": "it 's only used , it 's used for frame - dropping .", "speaker": "B"}, {"text": "it 's used for end of utterance", "speaker": "B"}, {"text": "because , , there 's if you have more than five hundred milliseconds of of nonspeech then you figure it 's end of utterance like that .", "speaker": "B"}, {"text": "and it seems important for , like , the on - line normalization .", "speaker": "E"}, {"text": "we don't want to update the mean and variance during silen long silence portions .", "speaker": "E"}, {"text": "so it has to be done before", "speaker": "E"}, {"text": "this mean and variance normalization .", "speaker": "E"}, {"text": "so probably the vad and testing out the noise estimation little bit .", "speaker": "B"}, {"text": "keeping the same method", "speaker": "B"}, {"text": "but , , seeing if you cou but , noise estimation could be improved .", "speaker": "B"}, {"text": "those are related issues .", "speaker": "B"}, {"text": "it probably makes sense to move from there .", "speaker": "B"}, {"text": "and then , , later on in the month we wanna start including the neural net at the end .", "speaker": "B"}, {"text": "the half dome was .", "speaker": "E"}, {"text": "you didn't didn't fall .", "speaker": "B"}, {"text": "that 's good .", "speaker": "B"}, {"text": "our our effort would have been devastated", "speaker": "B"}, {"text": "if you had run into problems .", "speaker": "B"}, {"text": "so , hynek is coming back next week , you said ?", "speaker": "A"}, {"text": "that 's the plan .", "speaker": "B"}, {"text": "the week after he 'll be , , going back to europe ,", "speaker": "B"}, {"text": "and so we wanna", "speaker": "B"}, {"text": "is he in europe now or is he up at ?", "speaker": "A"}, {"text": "no , no . he 's he 's dropped into the us . .", "speaker": "B"}, {"text": "the idea was that , , we 'd we 'd sort out where we were going next with this with this work before he , , left on this next trip .", "speaker": "B"}, {"text": "good . , barry , you just got through your quals , so if you have much to say .", "speaker": "B"}, {"text": "no , just , , looking into some of the things that , , , john ohala and hynek , , gave as feedback ,", "speaker": "D"}, {"text": "as starting point for the project .", "speaker": "D"}, {"text": "in in my proposal , was thinking about starting from set of , , phonological features , or subset of them .", "speaker": "D"}, {"text": "but that might not be necessarily good idea according to , , john .", "speaker": "D"}, {"text": "he said , , , these phonological features are figments of imagination also .", "speaker": "D"}, {"text": "in conversational speech in particular .", "speaker": "B"}, {"text": "you can you can put them in pretty reliably in synthetic speech .", "speaker": "B"}, {"text": "but we don't have too much trouble recognizing synthetic speech since we create it in the first place .", "speaker": "B"}, {"text": "so , it 's", "speaker": "B"}, {"text": "so , , better way would be something more data - driven ,", "speaker": "D"}, {"text": "just looking at the data and seeing what 's similar and what 's not similar .", "speaker": "D"}, {"text": "so , 'm 'm , , taking look at some of , , sangita 's work on traps .", "speaker": "D"}, {"text": "she did something where , where the traps learn", "speaker": "D"}, {"text": "she clustered the temporal patterns of , , certain phonemes in averaged over many , many contexts .", "speaker": "D"}, {"text": "and , , some things tended to cluster .", "speaker": "D"}, {"text": "? , like stop consonants clustered really .", "speaker": "D"}, {"text": "silence was by its own self .", "speaker": "D"}, {"text": "and , , , vocalic was clustered .", "speaker": "D"}, {"text": "and , , so , those are interesting things to", "speaker": "D"}, {"text": "so you 're now you 're looking to try to gather set of these types of features ?", "speaker": "A"}, {"text": "just to see where could start off from ,", "speaker": "D"}, {"text": "set of small features and continue to iterate and find , , better set .", "speaker": "D"}, {"text": ", short meeting .", "speaker": "B"}, {"text": "so next week hopefully we 'll can get hynek here to join us", "speaker": "B"}, {"text": "should we do digits ?", "speaker": "A"}, {"text": "digits , digits .", "speaker": "B"}, {"text": "go ahead , morgan .", "speaker": "A"}, {"text": "you can start .", "speaker": "A"}, {"text": "alright . let me get my glasses on so see them .", "speaker": "B"}, {"text": "and we 're off .", "speaker": "A"}], "id": "xxxxx", "relations": [{"y": 1, "x": 0, "type": "Explanation"}]}]