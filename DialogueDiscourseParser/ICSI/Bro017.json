[{"edus": [{"text": "is it starting now ?", "speaker": "B"}, {"text": "so what from what", "speaker": "B"}, {"text": "whatever we say from now on , it can be held against us ,", "speaker": "B"}, {"text": "it 's your to remain silent .", "speaker": "A"}, {"text": "so the problem is that actually how these held meetings are held ,", "speaker": "B"}, {"text": "if they are very informal and just people are say what 's going on", "speaker": "B"}, {"text": "that 's usually what we do .", "speaker": "E"}, {"text": "we just sorta go around and people say what 's going on , what 's the latest", "speaker": "E"}, {"text": "so that what may be reasonable is if first make report on what 's happening in aurora in general , at least what from my perspective .", "speaker": "B"}, {"text": "that would be .", "speaker": "E"}, {"text": "and and so , that carmen and stephane reported on amsterdam meeting ,", "speaker": "B"}, {"text": "because it was for the first time we realized we are not friends really , but we are competitors .", "speaker": "B"}, {"text": "cuz until then it was like everything was like wonderful", "speaker": "B"}, {"text": "it seemed like there were still some issues ,", "speaker": "E"}, {"text": "that they were trying to decide ?", "speaker": "E"}, {"text": "there is plenty of there 're plenty of issues .", "speaker": "B"}, {"text": "like the voice activity detector ,", "speaker": "E"}, {"text": "and what happened was that they realized that if two leading proposals , which was french telecom alcatel , and us both had voice activity detector .", "speaker": "B"}, {"text": "and said \" big surprise , we could have told you that four months ago , except we didn't because nobody else was bringing it up \" .", "speaker": "B"}, {"text": "french telecom didn't volunteer this information either ,", "speaker": "B"}, {"text": "cuz we were working on mainly on voice activity detector for past several months", "speaker": "B"}, {"text": "because that 's buying us the most thing .", "speaker": "B"}, {"text": "and everybody said \" but this is not fair . we didn't know that . \"", "speaker": "B"}, {"text": "and the it 's not working on features really .", "speaker": "B"}, {"text": "if wish that you provided better end point at speech because", "speaker": "B"}, {"text": "or at least that if we could modify the recognizer , to account for these long silences ,", "speaker": "B"}, {"text": "because otherwise that that wasn't correct thing . \"", "speaker": "B"}, {"text": "and so then ev everybody else says \" we should we need to do new eval evaluation without voice activity detector ,", "speaker": "B"}, {"text": "or we have to do something about it \" .", "speaker": "B"}, {"text": "and in principle we .", "speaker": "B"}, {"text": "we said \" \" .", "speaker": "B"}, {"text": "but in that case , we would like to change the the algorithm", "speaker": "B"}, {"text": "because if we are working on different data , we probably will use different set of tricks .", "speaker": "B"}, {"text": "but unfortunately nobody ever officially can somehow acknowledge that this can be done ,", "speaker": "B"}, {"text": "because french telecom was saying \" no , no , now everybody has access to our code ,", "speaker": "B"}, {"text": "so everybody is going to copy what we did . \"", "speaker": "B"}, {"text": "our argument was everybody ha has access to our code , and everybody always had access to our code .", "speaker": "B"}, {"text": "we never denied that .", "speaker": "B"}, {"text": "we thought that people are honest , that if you copy something and if it is protected by patent then you negotiate , ,", "speaker": "B"}, {"text": "if you find our technique useful , we are very happy .", "speaker": "B"}, {"text": "but and french telecom was saying \" no , no ,", "speaker": "B"}, {"text": "there is lot of little tricks which cannot be protected and you will take them , \" which probably is also true .", "speaker": "B"}, {"text": ", it might be that people will take the algorithms apart and use the blocks from that .", "speaker": "B"}, {"text": "but somehow think that it wouldn't be so bad , as long as people are happy abou honest about it .", "speaker": "B"}, {"text": "and they have to be honest in the long run , because winning proposal again what will be available is will be code .", "speaker": "B"}, {"text": "so the the people can go to code and say \" listen this is what you stole from me \"", "speaker": "B"}, {"text": "\" so let 's deal with that \" .", "speaker": "B"}, {"text": "so don't see the problem .", "speaker": "B"}, {"text": "the biggest problem is that that alcatel french telecom cl claims \" we fulfilled the conditions .", "speaker": "B"}, {"text": "we are the best .", "speaker": "B"}, {"text": "we are the standard . \"", "speaker": "B"}, {"text": "and and other people don't feel that ,", "speaker": "B"}, {"text": "because they so they now decided that is the whole thing will be done on - endpointed data ,", "speaker": "B"}, {"text": "essentially that somebody will endpoint the data based on clean speech ,", "speaker": "B"}, {"text": "because most of this the speechdat - car has the also close speaking mike and endpoints will be provided .", "speaker": "B"}, {"text": "and we will run again", "speaker": "B"}, {"text": "still not clear if we are going to run the if we are allowed to run new algorithms ,", "speaker": "B"}, {"text": "but assume so .", "speaker": "B"}, {"text": "because we would fight for that , really .", "speaker": "B"}, {"text": "at least our experience is that only endpointing mel cepstrum gets gets you twenty - one percent improvement overall and twenty - seven improvement on speechdat - car", "speaker": "B"}, {"text": "then obvious the database the the baseline will go up .", "speaker": "B"}, {"text": "and nobody can then achieve fifty percent improvement .", "speaker": "B"}, {"text": "so they that there will be twenty - five percent improvement required on bad mis badly mismatched", "speaker": "B"}, {"text": "the endpointing really only helped in the noisy cases .", "speaker": "E"}, {"text": "but you still have that with the mfcc .", "speaker": "E"}, {"text": "but you have the same prob mfcc has an enormous number of insertions .", "speaker": "B"}, {"text": "and so , so now they want to say \" we will require fifty percent improvement only for matched condition , and only twenty - five percent for the serial cases . \"", "speaker": "B"}, {"text": "and and they almost on that except that it wasn't hundred percent .", "speaker": "B"}, {"text": "and so last time during the meeting , brought up the issue ,", "speaker": "B"}, {"text": "said \" quite frankly 'm surprised how lightly you are making these decisions", "speaker": "B"}, {"text": "because this is major decision .", "speaker": "B"}, {"text": "for two years we are fighting for fifty percent improvement", "speaker": "B"}, {"text": "and suddenly you are saying \" no we will do something less \" ,", "speaker": "B"}, {"text": "but we should discuss that .", "speaker": "B"}, {"text": "and everybody said \" we discussed that and you were not mee there \"", "speaker": "B"}, {"text": "and said \" lot of other people were not there because not everybody participates at these teleconferencing things . \"", "speaker": "B"}, {"text": "then they said \" no because everybody is invited . \"", "speaker": "B"}, {"text": "however , there is only ten or fifteen lines , so people can't even con participate .", "speaker": "B"}, {"text": "so they , and so they said \" , we will discuss that . \"", "speaker": "B"}, {"text": "immediately nokia raised the question", "speaker": "B"}, {"text": "and they said \" we agree this is not good to dissolve the the criterion . \"", "speaker": "B"}, {"text": "so now officially , nokia is complaining and said they are looking for support ,", "speaker": "B"}, {"text": "qualcomm is saying , too \" we shouldn't abandon the fifty percent yet .", "speaker": "B"}, {"text": "we should at least try once again , one more round . \"", "speaker": "B"}, {"text": "so this is where we are .", "speaker": "B"}, {"text": "hope that hope that this is going to be adopted .", "speaker": "B"}, {"text": "next wednesday we are going to have another teleconferencing call , so we 'll see what where it goes .", "speaker": "B"}, {"text": "so what about the issue of the weights on the for the different systems ,", "speaker": "E"}, {"text": "the - matched , and medium - mismatched and", "speaker": "E"}, {"text": "that 's what that 's very good point ,", "speaker": "B"}, {"text": "because david says \" we ca we can manipulate this number by choosing the weights anyways . \"", "speaker": "B"}, {"text": "so while you are but but", "speaker": "B"}, {"text": "if if you put zero weight zero on mismatched condition , or highly mismatched then you are done .", "speaker": "B"}, {"text": "but weights were also deter already decided half year ago .", "speaker": "B"}, {"text": "and they 're the staying the same ?", "speaker": "E"}, {"text": "people will not like it .", "speaker": "B"}, {"text": "now what is happening now is that that people try to match the criterion to solution .", "speaker": "B"}, {"text": "they have solution .", "speaker": "B"}, {"text": "now they want to make their criterion is", "speaker": "B"}, {"text": "and that this is not the way .", "speaker": "B"}, {"text": "it may be that", "speaker": "B"}, {"text": "eventually it may ha it may have to happen .", "speaker": "B"}, {"text": "but it 's should happen at point where everybody feels comfortable that we did all what we could .", "speaker": "B"}, {"text": "and don't think we did .", "speaker": "B"}, {"text": "that this test was little bit bogus because of the data", "speaker": "B"}, {"text": "and essentially there were these arbitrary decisions made , and everything .", "speaker": "B"}, {"text": "so , so this is so this is where it is .", "speaker": "B"}, {"text": "so what we are doing at ogi now is working on our parts which we little bit neglected ,", "speaker": "B"}, {"text": "like noise separation .", "speaker": "B"}, {"text": "so we are looking in ways is in which with which we can provide better initial estimate of the mel spectrum ,", "speaker": "B"}, {"text": "which would be , more robust to noise ,", "speaker": "B"}, {"text": "and so far not much success .", "speaker": "B"}, {"text": "we tried things which long time ago bill byrne suggested ,", "speaker": "B"}, {"text": "instead of using fourier spectrum , from fourier transform , use the spectrum from lpc model .", "speaker": "B"}, {"text": "their argument there was the lpc model fits the peaks of the spectrum , so it may be naturally more robust in noise .", "speaker": "B"}, {"text": "and \" , that makes sense , \" but so far we can't get much out of it .", "speaker": "B"}, {"text": "we may try some standard techniques like spectral subtraction and", "speaker": "B"}, {"text": "you haven't tried that yet ?", "speaker": "E"}, {"text": "not not much .", "speaker": "B"}, {"text": "or even was thinking about looking back into these ad - hoc techniques", "speaker": "B"}, {"text": "like dennis klatt was suggesting the one way to deal with noisy speech is to add noise to everything .", "speaker": "B"}, {"text": "so . , add moderate amount of noise to all data .", "speaker": "B"}, {"text": "so that makes any additive noise less addi less effective ,", "speaker": "B"}, {"text": "because you already had the noise in", "speaker": "B"}, {"text": "and it was working at the time .", "speaker": "B"}, {"text": "it was like one of these things , , but", "speaker": "B"}, {"text": "if you think about it , it 's actually pretty ingenious .", "speaker": "B"}, {"text": "so , , just take take spectrum and and add of the constant , , to every value .", "speaker": "B"}, {"text": "you 're you 're", "speaker": "E"}, {"text": "so you 're making all your training data more uniform .", "speaker": "E"}, {"text": "and if then if this data becomes noisy , it it becomes eff effectively becomes less noisy .", "speaker": "B"}, {"text": "but you cannot add too much noise because then you 'll then you 're clean recognition goes down ,", "speaker": "B"}, {"text": "but it 's yet to be seen how much ,", "speaker": "B"}, {"text": "it 's very simple technique .", "speaker": "B"}, {"text": "yes it 's very simple technique ,", "speaker": "B"}, {"text": "you just take your spectrum and use whatever is coming from fft , add constant ,", "speaker": "B"}, {"text": "on onto power spectrum .", "speaker": "B"}, {"text": "or the other thing is if you have spectrum , what you can start doing , you can leave start leaving out the the parts which are low in energy", "speaker": "B"}, {"text": "and then perhaps one could try to find all - pole model to such spectrum .", "speaker": "B"}, {"text": "because all - pole model will still try to to put the continuation of the of the model into these parts where the issue set to zero .", "speaker": "B"}, {"text": "that 's what we want to try .", "speaker": "B"}, {"text": "have visitor from brno .", "speaker": "B"}, {"text": "he 's like young faculty .", "speaker": "B"}, {"text": "pretty hard - working so he so he 's looking into that .", "speaker": "B"}, {"text": "and then most of the effort is now also aimed at this trap recognition .", "speaker": "B"}, {"text": "this this is this recognition from temporal patterns .", "speaker": "B"}, {"text": "what is that ?", "speaker": "E"}, {"text": "you about traps !", "speaker": "B"}, {"text": "the traps sound familiar , but don't", "speaker": "E"}, {"text": "this is familiar like because we gave you the name ,", "speaker": "B"}, {"text": "but , what it is , is that normally what you do is that you recognize speech based on shortened spectrum .", "speaker": "B"}, {"text": "essentially - lpc , mel cepstrum , , everything starts with spectral slice .", "speaker": "B"}, {"text": "so if you so , given the spectrogram you essentially are sliding the spectrogram along the frequency axis", "speaker": "B"}, {"text": "and you keep shifting this thing , and you have spectrogram .", "speaker": "B"}, {"text": "so you can say \" you can also take the time trajectory of the energy at given frequency \" ,", "speaker": "B"}, {"text": "and what you get is then , that you get vector .", "speaker": "B"}, {"text": "and this vector can be assigned to some phoneme .", "speaker": "B"}, {"text": "namely you can say it will say that this vector will will describe the phoneme which is in the center of the vector .", "speaker": "B"}, {"text": "and you can try to classify based on that .", "speaker": "B"}, {"text": "and you so you classi", "speaker": "B"}, {"text": "so it 's very different vector , very different properties ,", "speaker": "B"}, {"text": "we much about it ,", "speaker": "B"}, {"text": "but the truth is", "speaker": "B"}, {"text": "but you have many of those vectors per phoneme ,", "speaker": "E"}, {"text": "so you get many decisions .", "speaker": "B"}, {"text": "and then you can start dec thinking about how to combine these decisions .", "speaker": "B"}, {"text": "exactly , that 's what , that 's what it is .", "speaker": "B"}, {"text": "because if you run this recognition , you get you still get about twenty percent error", "speaker": "B"}, {"text": "twenty percent correct .", "speaker": "B"}, {"text": "on like for the frame by frame basis ,", "speaker": "B"}, {"text": "so so it 's much better than chance .", "speaker": "B"}, {"text": "how wide are the frequency bands ?", "speaker": "E"}, {"text": "that 's another thing .", "speaker": "B"}, {"text": "currently we start we start always with critical band spectrum .", "speaker": "B"}, {"text": "for various reasons .", "speaker": "B"}, {"text": "but the latest observation is that you you are you can get quite big advantage of using two critical bands at the same time .", "speaker": "B"}, {"text": "are they adjacent ,", "speaker": "A"}, {"text": "adjacent , adjacent .", "speaker": "B"}, {"text": "and the reasons there are some reasons for that .", "speaker": "B"}, {"text": "because there are some reasons could talk about , will have to tell you about things like masking experiments which yield critical bands ,", "speaker": "B"}, {"text": "and also experiments with release of masking , which actually tell you that something is happening across critical bands , across bands .", "speaker": "B"}, {"text": "how do you how do you convert this energy over time in particular frequency band into vector of numbers ?", "speaker": "E"}, {"text": "it 's time - zero is one number , time", "speaker": "B"}, {"text": "but what 's the number ?", "speaker": "E"}, {"text": "is it just the", "speaker": "E"}, {"text": "it 's spectral energy , logarithmic spectral energy ,", "speaker": "B"}, {"text": "it 's just the amount of energy in that band from in that time interval .", "speaker": "E"}, {"text": "yes , yes .", "speaker": "B"}, {"text": "yes , yes .", "speaker": "B"}, {"text": "and that 's what that 's what 'm saying then ,", "speaker": "B"}, {"text": "so this is this is starting vector .", "speaker": "B"}, {"text": "it 's just like shortened spectrum , .", "speaker": "B"}, {"text": "but now we are trying to understand what this vector actually represents ,", "speaker": "B"}, {"text": "question is like \" how correlated are the elements of this vector ? \"", "speaker": "B"}, {"text": "turns out they are quite correlated , because , especially the neighboring ones ,", "speaker": "B"}, {"text": "they they represent the same almost the same configuration of the vocal tract .", "speaker": "B"}, {"text": "so there 's very high correlation .", "speaker": "B"}, {"text": "so the classifiers which use the diagonal covariance matrix don't like it .", "speaker": "B"}, {"text": "so we 're thinking about de - correlating them .", "speaker": "B"}, {"text": "then the question is \" can you describe elements of this vector by gaussian distributions \" , or to what extent ?", "speaker": "B"}, {"text": "and and so on and so on .", "speaker": "B"}, {"text": "so we are learning quite lot about that .", "speaker": "B"}, {"text": "and then another issue is how many vectors we should be using ,", "speaker": "B"}, {"text": "the so the minimum is one .", "speaker": "B"}, {"text": "but is the is the critical band the dimension ?", "speaker": "B"}, {"text": "so we somehow made arbitrary decision , \" yes \" .", "speaker": "B"}, {"text": "then but then now we are thinking lot how to how to use at least the neighboring band because that seems to be happening", "speaker": "B"}, {"text": "this somehow start to believe that 's what 's happening in recognition .", "speaker": "B"}, {"text": "cuz lot of experiments point to the fact that people can split the signal into critical bands ,", "speaker": "B"}, {"text": "so you can you are quite capable of processing signal in independently in individual critical bands .", "speaker": "B"}, {"text": "that 's what masking experiments tell you .", "speaker": "B"}, {"text": "but at the same time you most likely pay attention to at least neighboring bands", "speaker": "B"}, {"text": "when you are making any decisions , you compare what 's happening in this band to what 's happening to the band to the to the neighboring bands .", "speaker": "B"}, {"text": "and that 's how you make decisions .", "speaker": "B"}, {"text": "that 's why the articulatory events , which fletcher talks about , they are about two critical bands .", "speaker": "B"}, {"text": "you need at least two , .", "speaker": "B"}, {"text": "you need some relative , relative relation .", "speaker": "B"}, {"text": "absolute number doesn't tell you the thing .", "speaker": "B"}, {"text": "you need to you need to compare it to something else , what 's happening", "speaker": "B"}, {"text": "but it 's what 's happening in the in the close neighborhood .", "speaker": "B"}, {"text": "so if you are making decision what 's happening at one kilohertz , you want to 's happening at nine hundred hertz and it and at eleven hundred hertz ,", "speaker": "B"}, {"text": "but you don't much care what 's happening at three kilohertz .", "speaker": "B"}, {"text": "so it 's really", "speaker": "E"}, {"text": "it 's like saying that what 's happening at one kilohertz depends on what 's happening around it .", "speaker": "E"}, {"text": "it 's relative to it .", "speaker": "E"}, {"text": "to some extent , it that is also true .", "speaker": "B"}, {"text": "but it 's but , what humans are very much capable of doing is that if if they are exactly the same thing happening in two neighboring critical bands , recognition can discard it .", "speaker": "B"}, {"text": "is what 's happening", "speaker": "B"}, {"text": "we need us another voice here .", "speaker": "B"}, {"text": "and so so if you if you if you add the noise that normally masks the the signal", "speaker": "B"}, {"text": "and you can show that in that if the if you add the noise outside the critical band , that doesn't affect the decisions you 're making about signal within critical band .", "speaker": "B"}, {"text": "unless this noise is modulated .", "speaker": "B"}, {"text": "if the noise is modulated , with the same modulation frequency as the noise in critical band , the amount of masking is less .", "speaker": "B"}, {"text": "the moment you moment you provide the noise in neighboring critical bands .", "speaker": "B"}, {"text": "so the masking curve , normally it looks like", "speaker": "B"}, {"text": "start from here ,", "speaker": "B"}, {"text": "so you have no noise then you you are expanding the critical band , so the amount of maching is increasing .", "speaker": "B"}, {"text": "and when you hit certain point , which is critical band , then the amount of masking is the same .", "speaker": "B"}, {"text": "so that 's the famous experiment of fletcher , long time ago .", "speaker": "B"}, {"text": "like that 's where people started thinking \" this is interesting ! \"", "speaker": "B"}, {"text": "but , if you if you modulate the noise , the masking goes up and the moment you start hitting the another critical band , the masking goes down .", "speaker": "B"}, {"text": "so essentially that 's very clear indication that cognition can take into consideration what 's happening in the neighboring bands .", "speaker": "B"}, {"text": "but if you go too far in if you if the noise is very broad , you are not increasing much more ,", "speaker": "B"}, {"text": "so if you if you are far away from the signal from the signal the frequency at which the signal is , then the even the when the noise is co - modulated it 's not helping you much .", "speaker": "B"}, {"text": "so things like this we are playing with with the hope that perhaps we could eventually use this in in real recognizer .", "speaker": "B"}, {"text": "like partially we promised to do this under the the aurora program .", "speaker": "B"}, {"text": "but you probably won't have anything before the next time we have to evaluate ,", "speaker": "E"}, {"text": ", most likely we will not have anything which would comply with the rules .", "speaker": "B"}, {"text": "latency and things .", "speaker": "E"}, {"text": "latency currently chops the require significant latency amount of processing ,", "speaker": "B"}, {"text": "because we any better , yet , than to use the neural net classifiers , and and traps .", "speaker": "B"}, {"text": "though the work which everybody is looking at now aims at trying to find out what to do with these vectors , so that simple gaussian classifier would be happier with it .", "speaker": "B"}, {"text": "or to what extent gaussian classifier should be unhappy", "speaker": "B"}, {"text": "that , and how to gaussian - ize the vectors ,", "speaker": "B"}, {"text": "so this is what 's happening .", "speaker": "B"}, {"text": "then sunil is asked me for one month 's vacation", "speaker": "B"}, {"text": "and since he did not take any vacation for two years , had no didn't have heart to tell him no .", "speaker": "B"}, {"text": "so he 's in india .", "speaker": "B"}, {"text": "is he getting married ?", "speaker": "E"}, {"text": "he may be looking for girl , for don't don't ask .", "speaker": "B"}, {"text": "know that naran - when last time narayanan did that he came back engaged .", "speaker": "B"}, {"text": ", 've known other friends who they go to ind - they go back home to india for month , they come back married ,", "speaker": "E"}, {"text": "know , know ,", "speaker": "B"}, {"text": "and then then what happened with narayanan was that he start pushing me that he needs to get phd because they wouldn't give him his wife .", "speaker": "B"}, {"text": "and she 's very pretty and he loves her", "speaker": "B"}, {"text": "and so we had to really", "speaker": "B"}, {"text": "so he finally had some incentive to finish ,", "speaker": "E"}, {"text": "we had had incentive because he always had this plan except he never told me .", "speaker": "B"}, {"text": "figured that that was that he he told me the day when we did very at our nist evaluations of speaker recognition , the technology , and he was involved there .", "speaker": "B"}, {"text": "we were after presentation we were driving home and he told me .", "speaker": "B"}, {"text": "when he knew you were happy ,", "speaker": "E"}, {"text": "so said \" , , \" so he took another three quarter of the year but he was out .", "speaker": "B"}, {"text": "so wouldn't surprise me if he has plan like that , though pratibha still needs to get out first .", "speaker": "B"}, {"text": "cuz pratibha is there year earlier .", "speaker": "B"}, {"text": "and and satya needs to get out very first because he 's he already has four years served ,", "speaker": "B"}, {"text": "though one year he was getting masters .", "speaker": "B"}, {"text": "when is the next evaluation ?", "speaker": "E"}, {"text": "no , for aurora ?", "speaker": "E"}, {"text": "there , we about evaluation ,", "speaker": "B"}, {"text": "next meeting is in june .", "speaker": "B"}, {"text": "and but like getting get together .", "speaker": "B"}, {"text": "are people supposed to rerun their systems ,", "speaker": "E"}, {"text": "nobody said that yet .", "speaker": "B"}, {"text": "yes , , but nobody even set up yet the date for delivering endpointed data .", "speaker": "B"}, {"text": "and this that .", "speaker": "B"}, {"text": "what would be extremely useful , if we can come to our next meeting and say \" we did get fifty percent improvement .", "speaker": "B"}, {"text": "if if you are interested we eventually can tell you how \" , but we can get fifty percent improvement .", "speaker": "B"}, {"text": "because people will will be saying it 's impossible .", "speaker": "B"}, {"text": "do what the new baseline is ?", "speaker": "E"}, {"text": "if you don't have", "speaker": "E"}, {"text": "twenty - two twenty - two percent better than the old baseline .", "speaker": "B"}, {"text": "using your voice activity detector ?", "speaker": "E"}, {"text": "but assume that it will be similar , don't don't see the reason why it shouldn't be .", "speaker": "B"}, {"text": "don't see reason why it should be worse .", "speaker": "B"}, {"text": "cuz if it is worse , then we will raise the objection ,", "speaker": "B"}, {"text": "we say \" how come ? \"", "speaker": "B"}, {"text": "because if we just use our voice activity detector , which we don't claim even that it 's wonderful , it 's just like one of them .", "speaker": "B"}, {"text": "we get this improvement ,", "speaker": "B"}, {"text": "how come that we don't see it on on your endpointed data ?", "speaker": "B"}, {"text": "it could be even better ,", "speaker": "C"}, {"text": "because the voice activity detector that choosed is something that cheating , it 's using the alignment of the speech recognition system ,", "speaker": "C"}, {"text": "and only the alignment on the clean channel , and then mapped this alignment to the noisy channel .", "speaker": "C"}, {"text": "and on clean speech data .", "speaker": "B"}, {"text": "david told me yesterday or harry actually he told harry from qualcomm", "speaker": "B"}, {"text": "and harry brought up the suggestion we should still go for fifty percent", "speaker": "B"}, {"text": "he says are you aware that your system does only thirty percent comparing to endpointed baselines ?", "speaker": "B"}, {"text": "so they must have run already something .", "speaker": "B"}, {"text": "and harry said \" .", "speaker": "B"}, {"text": "but we think that we didn't say the last word yet , that we have other things which we can try . \"", "speaker": "B"}, {"text": "so . so there 's lot of discussion now about this new criterion .", "speaker": "B"}, {"text": "because nokia was objecting , with qualcomm 's we supported that , we said \" yes \" .", "speaker": "B"}, {"text": "now everybody else is saying \" you might must be out of your mind . \"", "speaker": "B"}, {"text": "the guenter hirsch who doesn't speak for ericsson anymore because he is not with ericsson", "speaker": "B"}, {"text": "and ericsson may not may withdraw from the whole aurora activity because they have so many troubles now .", "speaker": "B"}, {"text": "ericsson 's laying off twenty percent of people .", "speaker": "B"}, {"text": "where 's guenter going ?", "speaker": "E"}, {"text": "guenter is already he got the job already was working on it for past two years or three years", "speaker": "B"}, {"text": "he got job at some fachschule , the technical college not too far from aachen .", "speaker": "B"}, {"text": "so it 's like professor university professor", "speaker": "B"}, {"text": "not quite university , not quite it 's not aachen university , but it 's good school and he 's happy .", "speaker": "B"}, {"text": "and he , he was hoping to work with ericsson like on like consulting basis ,", "speaker": "B"}, {"text": "but now he says it doesn't look like that anybody is even thinking about speech recognition .", "speaker": "B"}, {"text": "they think about survival .", "speaker": "B"}, {"text": "so . but this is being now discussed now ,", "speaker": "B"}, {"text": "and it 's possible that that it may get through , that we will still stick to fifty percent .", "speaker": "B"}, {"text": "but that means that nobody will probably get this im this improvement .", "speaker": "B"}, {"text": "yet , wi with the current system .", "speaker": "B"}, {"text": "which event es essentially that we should be happy with", "speaker": "B"}, {"text": "because that would mean that at least people may be forced to look into alternative solutions", "speaker": "B"}, {"text": "but we are not too far from fifty percent , from the new baseline .", "speaker": "C"}, {"text": "which would mean like sixty percent over the current baseline , which is", "speaker": "C"}, {"text": "yes . yes .", "speaker": "B"}, {"text": "we we getting there , .", "speaker": "B"}, {"text": "we are around fifty , fifty - five .", "speaker": "C"}, {"text": "is it like is", "speaker": "B"}, {"text": "how did you come up with this number ?", "speaker": "B"}, {"text": "if you improve twenty by twenty percent the the the all baselines , it 's just quick comp co computation ?", "speaker": "B"}, {"text": "exactly if it 's", "speaker": "C"}, {"text": "it 's about .", "speaker": "B"}, {"text": "because it de it depends on the weightings", "speaker": "C"}, {"text": "how 's your documentation or whatever", "speaker": "E"}, {"text": "it what was it you were working on last week ?", "speaker": "E"}, {"text": "finally we 've not finished with this .", "speaker": "C"}, {"text": "more or less it 's finished .", "speaker": "D"}, {"text": "ma - nec to need little more time to improve the english , and to fill in something some small detail , something like that ,", "speaker": "D"}, {"text": "but it 's more or less ready .", "speaker": "D"}, {"text": "we have document that explain big part of the experiments ,", "speaker": "C"}, {"text": "necessary to include the bi the bibliography .", "speaker": "D"}, {"text": "it 's not , , finished yet .", "speaker": "C"}, {"text": "so have you been running some new experiments ?", "speaker": "E"}, {"text": "saw some jobs of yours running on some of the machine", "speaker": "E"}, {"text": "we 've fff done some strange things like removing - zero or - one from the vector of parameters ,", "speaker": "C"}, {"text": "and we noticed that - one is almost not useful .", "speaker": "C"}, {"text": "you can remove it from the vector , it doesn't hurt .", "speaker": "C"}, {"text": "that has no effect ?", "speaker": "E"}, {"text": "is this in the baseline ?", "speaker": "E"}, {"text": "in the proposal .", "speaker": "C"}, {"text": "- , - .", "speaker": "E"}, {"text": "so we were just discussing , since you mentioned that , in it", "speaker": "B"}, {"text": "driving in the car with morgan this morning , we were discussing good experiment for for beginning graduate student who wants to run lot of who wants to get lot of numbers on something", "speaker": "B"}, {"text": "which is , like , \" imagine that you will you will start putting every co any coefficient , which you are using in your vector , in some general power .", "speaker": "B"}, {"text": "in some what ?", "speaker": "E"}, {"text": "general pow power .", "speaker": "B"}, {"text": "like you take power of two , or take square root , .", "speaker": "B"}, {"text": "so suppose that you are working with - zer - one .", "speaker": "B"}, {"text": "so if you put it in square root , that effectively makes your model half as efficient .", "speaker": "B"}, {"text": "because your gaussian mixture model ,", "speaker": "B"}, {"text": "computes the mean .", "speaker": "B"}, {"text": "but it 's the mean is an exponent of the whatever , the this gaussian function .", "speaker": "B"}, {"text": "you 're compressing the range ,", "speaker": "E"}, {"text": "so you 're compressing the range of this coefficient , so it 's becoming less efficient .", "speaker": "B"}, {"text": "morgan was @ @ and he was he was saying this might be the alternative way how to play with with fudge factor ,", "speaker": "B"}, {"text": "just compress the whole vector .", "speaker": "B"}, {"text": "and said \" in that case why don't we just start compressing individual elements , like when", "speaker": "B"}, {"text": "because in old days we were doing when people still were doing template matching and euclidean distances , we were doing this liftering of parameters ,", "speaker": "B"}, {"text": "because we observed that higher parameters were more important than lower for recognition .", "speaker": "B"}, {"text": "and the - ze - one contributes mainly slope ,", "speaker": "B"}, {"text": "and it 's highly affected by frequency response of the of the recording equipment and that thing ,", "speaker": "B"}, {"text": "so we were coming with all these various lifters .", "speaker": "B"}, {"text": "bell labs had he this raised cosine lifter which still is built into htk for reasons unknown to anybody ,", "speaker": "B"}, {"text": "but we had exponential lifter , or triangle lifter , basic number of lifters .", "speaker": "B"}, {"text": "and . but so they may be way to fiddle with the", "speaker": "B"}, {"text": "insertions , deletions , or the giving relative modifying relative importance of the various parameters .", "speaker": "B"}, {"text": "the only problem is that there 's an infinite number of combinations", "speaker": "B"}, {"text": "and if the if you if", "speaker": "B"}, {"text": "you need like some", "speaker": "E"}, {"text": "you need lot of graduate students , and lot of computing power .", "speaker": "B"}, {"text": "you need to have genetic algorithm , that tries random permutations of these things .", "speaker": "E"}, {"text": "if you were at bell labs or", "speaker": "B"}, {"text": "shouldn't be saying this in on mike ,", "speaker": "B"}, {"text": "that 's what that 's what somebody would be doing .", "speaker": "B"}, {"text": "the places which have lot of computing power ,", "speaker": "B"}, {"text": "so because it is really it 's it 's it 's it will be reasonable search", "speaker": "B"}, {"text": "but wonder if there isn't some way of doing this search like when we are searching say for best discriminants .", "speaker": "B"}, {"text": "actually , that this wouldn't be all that bad .", "speaker": "E"}, {"text": "you compute the features once ,", "speaker": "E"}, {"text": "and then these exponents are just applied to that", "speaker": "E"}, {"text": "and hev everything is fixed .", "speaker": "B"}, {"text": "everything is fixed .", "speaker": "B"}, {"text": "and is this something that you would adjust for training ?", "speaker": "E"}, {"text": "or only recognition ?", "speaker": "E"}, {"text": "for both , you would have to do .", "speaker": "B"}, {"text": "you would do it on both .", "speaker": "E"}, {"text": "you have to do bo both .", "speaker": "B"}, {"text": "so you 'd actually", "speaker": "E"}, {"text": "because essentially you are saying \" this feature is not important \" .", "speaker": "B"}, {"text": "or less important ,", "speaker": "B"}, {"text": "so that 's that 's that 's painful one ,", "speaker": "B"}, {"text": "so for each set of exponents that you would try , it would require training and recognition ?", "speaker": "E"}, {"text": "but but minute .", "speaker": "B"}, {"text": "you may not need to re retrain the model .", "speaker": "B"}, {"text": "you just may may need to give less weight to mod component of the model which represents this particular feature .", "speaker": "B"}, {"text": "you don't have to retrain it .", "speaker": "B"}, {"text": "instead of altering the feature vectors themselves , you modify the the gaussians in the models .", "speaker": "E"}, {"text": "you just multiply .", "speaker": "B"}, {"text": "you modify the gaussian in the model ,", "speaker": "B"}, {"text": "but in the in the test data you would have to put it in the power ,", "speaker": "B"}, {"text": "but in training what you in training in trained model , all you would have to do is to multiply model by appropriate constant .", "speaker": "B"}, {"text": "but why if you 're multi if you 're altering the model , why in the test data , why would you have to muck with the cepstral coefficients ?", "speaker": "E"}, {"text": "because in test in test data you ca don't have model .", "speaker": "B"}, {"text": "you have only data .", "speaker": "B"}, {"text": "but in in tr", "speaker": "B"}, {"text": "no . but you 're running your data through that same model .", "speaker": "E"}, {"text": "that is true ,", "speaker": "B"}, {"text": "but , so what you want to do you want to say if obs you if you observe something like stephane observes , that - one is not important , you can do two things .", "speaker": "B"}, {"text": "if you have trained recognizer , in the model , the the component which di dimension wh", "speaker": "B"}, {"text": "all of the all of the mean and variances that correspond to - one , you put them to zero .", "speaker": "E"}, {"text": "to the it .", "speaker": "B"}, {"text": "but what 'm proposing now , if it is important but not as important , you multiply it by point one in model .", "speaker": "B"}, {"text": "but what are you multiplying ?", "speaker": "E"}, {"text": "cuz those are means ,", "speaker": "E"}, {"text": "you 're multiplying the standard deviation ?", "speaker": "A"}, {"text": "that you multiply the", "speaker": "B"}, {"text": "would would have to look in the in the math ,", "speaker": "B"}, {"text": "how does the model", "speaker": "B"}, {"text": "you 'd have to modify the standard deviation , so that you make it wider or narrower .", "speaker": "E"}, {"text": "effectively , that 's", "speaker": "B"}, {"text": "that 's what you do .", "speaker": "B"}, {"text": "that 's what you do , you you modify the standard deviation as it was trained .", "speaker": "B"}, {"text": "effectively you , in in front of the of the model , you put constant .", "speaker": "B"}, {"text": "effectively what you 're doing is you is you are modifying the the deviation .", "speaker": "B"}, {"text": "it 's the same mean ,", "speaker": "A"}, {"text": "so by making the standard deviation narrower , your scores get worse for", "speaker": "E"}, {"text": "unless it 's exactly on the mean .", "speaker": "E"}, {"text": "by making it narrower ,", "speaker": "B"}, {"text": "there 's you 're allowing for less variance .", "speaker": "E"}, {"text": "so you making this particular dimension less important .", "speaker": "B"}, {"text": "because see what you are fitting is the multidimensional gaussian ,", "speaker": "B"}, {"text": "it 's it has thirty - nine dimensions , or thirteen dimensions if you ignore deltas and double - deltas .", "speaker": "B"}, {"text": "so in order if you in order to make dimension which stephane sees less important , not useful , less important , what you do is that this particular component in the model you can multiply by you can you can de - weight it in the model .", "speaker": "B"}, {"text": "but you can't do it in in test data", "speaker": "B"}, {"text": "because you don't have model for when the test comes ,", "speaker": "B"}, {"text": "but what you can do is that you put this particular component in and you compress it .", "speaker": "B"}, {"text": "that becomes gets less variance , subsequently becomes less important .", "speaker": "B"}, {"text": "couldn't you just do that to the test data and not do anything with your training data ?", "speaker": "E"}, {"text": "that would be very bad ,", "speaker": "B"}, {"text": "because your your model was trained expecting ,", "speaker": "B"}, {"text": "that wouldn't work .", "speaker": "B"}, {"text": "because your model was trained expecting certain var variance on - one .", "speaker": "B"}, {"text": "and because the model thinks - one is important .", "speaker": "B"}, {"text": "after you train the model , you you could do you could do still what was proposing initially ,", "speaker": "B"}, {"text": "that during the training you compress - one that becomes then it becomes less important in training .", "speaker": "B"}, {"text": "but if you have if you want to run ex extensive experiment without retraining the model , you don't have to retrain the model .", "speaker": "B"}, {"text": "you train it on the original vector .", "speaker": "B"}, {"text": "but after , you wh when you are doing this parametric study of importance of - one you will de - weight the - one component in the model ,", "speaker": "B"}, {"text": "and you will put in the you will compress the this component in in the test data . by the same amount .", "speaker": "B"}, {"text": "could you also if you wanted to", "speaker": "E"}, {"text": "if you wanted to try an experiment by leaving out say , - one , couldn't you , in your test data , modify the all of the - one values to be way outside of the normal range of the gaussian for - one that was trained in the model ?", "speaker": "E"}, {"text": "so that effectively , the - one never really contributes to the score ?", "speaker": "E"}, {"text": "that would be severe mismatch ,", "speaker": "B"}, {"text": "do what 'm say", "speaker": "E"}, {"text": "what you are proposing ?", "speaker": "B"}, {"text": "no you don't want that .", "speaker": "B"}, {"text": "because that would then your model would be unlikely .", "speaker": "B"}, {"text": "your likelihood would be low ,", "speaker": "B"}, {"text": "because you would be providing severe mismatch .", "speaker": "B"}, {"text": "but what if you set if to the mean of the model , then ?", "speaker": "E"}, {"text": "and it was cons you set all - ones coming in through your test data , you change whatever value that was there to the mean that your model had .", "speaker": "E"}, {"text": "no that would be very good match ,", "speaker": "B"}, {"text": ", but we have several means .", "speaker": "C"}, {"text": "see what you are sa saying ,", "speaker": "B"}, {"text": "no , no don't think that it would be the same .", "speaker": "B"}, {"text": "no , the if you set it to mean , that would", "speaker": "B"}, {"text": "no , you can't do that .", "speaker": "B"}, {"text": "you ca ch - chuck , you can't do that .", "speaker": "B"}, {"text": "that 's true ,", "speaker": "E"}, {"text": "because that would be really fiddling with the data ,", "speaker": "B"}, {"text": "you can't do that .", "speaker": "B"}, {"text": "- . - .", "speaker": "E"}, {"text": "but what you can do , 'm confident you ca", "speaker": "B"}, {"text": "'m reasonably confident and putting it on the record ,", "speaker": "B"}, {"text": "people will listen to it for centuries now ,", "speaker": "B"}, {"text": "is what you can do , is you train the model with the with the original data .", "speaker": "B"}, {"text": "then you decide that you want to see how important - one is .", "speaker": "B"}, {"text": "so what you will do is that component in the model for - one , you will divide it by two .", "speaker": "B"}, {"text": "and you will compress your test data by square root .", "speaker": "B"}, {"text": "then you will still have perfect match .", "speaker": "B"}, {"text": "except that this component of - one will be half as important in in overall score .", "speaker": "B"}, {"text": "then you divide it by four and you take square , fourth root .", "speaker": "B"}, {"text": "then if you think that some component is more is more important then it then it is , based on training , then you multiply this particular component in the model by by", "speaker": "B"}, {"text": "you 're talking about the standard deviation ?", "speaker": "E"}, {"text": "multiply this component it by number larger than one ,", "speaker": "B"}, {"text": "and you put your data in power higher than one .", "speaker": "B"}, {"text": "then it becomes more important . in the overall score , believe .", "speaker": "B"}, {"text": "but , at the", "speaker": "C"}, {"text": "but don't you have to do something to the mean , also ?", "speaker": "E"}, {"text": "but it 's the the variance is on the denominator in the in the gaussian equation .", "speaker": "C"}, {"text": "so . it 's it 's the contrary .", "speaker": "C"}, {"text": "if you want to decrease the importance of parameter , you have to increase it 's variance .", "speaker": "C"}, {"text": "so you so you may want to do it other way around ,", "speaker": "B"}, {"text": "if your original data for - one had mean of two .", "speaker": "E"}, {"text": "and now you 're you 're changing that by squaring it .", "speaker": "E"}, {"text": "now your mean of your - one original data has is four .", "speaker": "E"}, {"text": "but your model still has mean of two .", "speaker": "E"}, {"text": "so even though you 've expended the range , your mean doesn't match anymore .", "speaker": "E"}, {"text": "let 's see .", "speaker": "B"}, {"text": "do you see what ?", "speaker": "E"}, {"text": "what see what could be done is you don't change your features , which are computed once for all ,", "speaker": "C"}, {"text": "but you just tune the model .", "speaker": "C"}, {"text": "so . you have your features .", "speaker": "C"}, {"text": "you train your model on these features .", "speaker": "C"}, {"text": "and then if you want to decrease the importance of - one you just take the variance of the - one component in the in the model and increase it if you want to decrease the importance of - one or decrease it", "speaker": "C"}, {"text": "you would have to modify the mean in the model .", "speaker": "B"}, {"text": "you agree with you .", "speaker": "B"}, {"text": "but , but it 's it 's it 's do - able ,", "speaker": "B"}, {"text": "it 's predictable .", "speaker": "B"}, {"text": "it 's predictable , .", "speaker": "E"}, {"text": "it 's predictable .", "speaker": "B"}, {"text": "but as simple thing , you could just muck with the variance .", "speaker": "E"}, {"text": "just adjust the model ,", "speaker": "C"}, {"text": "to get this the effect that you 're talking about ,", "speaker": "E"}, {"text": "it might be .", "speaker": "B"}, {"text": "could increase the variance to decrease the importance .", "speaker": "E"}, {"text": "because if you had huge variance , you 're dividing by large number , you get very small contribution .", "speaker": "E"}, {"text": "it becomes more flat", "speaker": "C"}, {"text": "the sharper the variance , the more important to get that one .", "speaker": "A"}, {"text": "actually , this reminds me of something that happened when was at bbn .", "speaker": "E"}, {"text": "we were playing with putting pitch into the mandarin recognizer .", "speaker": "E"}, {"text": "and this particular pitch algorithm when it didn't think there was any voicing , was spitting out zeros .", "speaker": "E"}, {"text": "so we were getting when we did clustering , we were getting groups of features", "speaker": "E"}, {"text": "pretty new outliers , interesting outliers ,", "speaker": "B"}, {"text": "with mean of zero and zero variance .", "speaker": "E"}, {"text": "so , when ener when anytime any one of those vectors came in that had zero in it , we got score .", "speaker": "E"}, {"text": "it was just , {nonvocalsound} , incredibly {nonvocalsound} high score , and so that was throwing everything off .", "speaker": "E"}, {"text": "so if you have very small variance you get really good scores when you get something that matches .", "speaker": "E"}, {"text": "so . so that 's way ,", "speaker": "E"}, {"text": "that 's way to increase the ,", "speaker": "E"}, {"text": "that 's interesting .", "speaker": "E"}, {"text": "so , that would be", "speaker": "E"}, {"text": "that doesn't require any retraining .", "speaker": "E"}, {"text": "no . no .", "speaker": "B"}, {"text": "so that means it 's just", "speaker": "E"}, {"text": "just tuning the models and testing , actually .", "speaker": "C"}, {"text": "it would be quick .", "speaker": "C"}, {"text": "you you have step where you modify the models , make copy of your models with whatever variance modifications you make , and rerun recognition .", "speaker": "E"}, {"text": "and then do whole bunch of those .", "speaker": "E"}, {"text": "that could be set up fairly easily ,", "speaker": "E"}, {"text": "and you have whole bunch of", "speaker": "E"}, {"text": "chuck is getting himself in trouble .", "speaker": "B"}, {"text": "that 's an interesting idea , actually .", "speaker": "E"}, {"text": "didn't you say you got these htk 's set up on the new linux boxes ?", "speaker": "A"}, {"text": "and they 're just now they 're installing increasing the memory on that the linux box .", "speaker": "E"}, {"text": "and chuck is really fishing for how to keep his computer busy ,", "speaker": "B"}, {"text": "we 've got five processors on that .", "speaker": "E"}, {"text": "that 's , that 's good thing", "speaker": "B"}, {"text": "because then you just write the \" do \" - loops and then you pretend that you are working while you are you you can go fishing .", "speaker": "B"}, {"text": "and two gigs of memory .", "speaker": "E"}, {"text": "see how many cycles we used ?", "speaker": "E"}, {"text": "then you are in this mode like all of those arpa people are ,", "speaker": "B"}, {"text": "since it is on the record , 't say which company it was ,", "speaker": "B"}, {"text": "but it was reported to me that somebody visited company", "speaker": "B"}, {"text": "and during during discussion , there was this guy who was always hitting the carriage returns on computer .", "speaker": "B"}, {"text": "so after two hours the visitor said \" wh why are you hitting this carriage return ? \"", "speaker": "B"}, {"text": "and he said \" , we are being paid by computer ty we are we have government contract .", "speaker": "B"}, {"text": "and they pay us by amount of computer time we use . \"", "speaker": "B"}, {"text": "it was in old days when there were of pdp - eights and that thing .", "speaker": "B"}, {"text": "so he had to make it look like", "speaker": "E"}, {"text": "because so they had they literally had to monitor at the time at the time on computer how much time is being spent or on this particular project .", "speaker": "B"}, {"text": "nobody was looking even at what was coming out .", "speaker": "B"}, {"text": "have you ever seen those little", "speaker": "E"}, {"text": "it 's it 's this thing that 's the shape of bird and it has red ball and its beak dips into the water ?", "speaker": "E"}, {"text": "so if you could hook that up so it hit the keyboard", "speaker": "E"}, {"text": "that 's an interesting experiment .", "speaker": "E"}, {"text": "it would be similar to", "speaker": "B"}, {"text": "knew some people who were that was in old communist czechoslovakia ,", "speaker": "B"}, {"text": "so we were watching for american airplanes , coming to spy on on us at the time ,", "speaker": "B"}, {"text": "so there were three stationed in the middle of the woods on one lonely watching tower , spending year and half there because there was this service", "speaker": "B"}, {"text": "and so they very quickly they made friends with local girls and local people in the village", "speaker": "B"}, {"text": "and so but they there was one plane flying over always above ,", "speaker": "B"}, {"text": "and so that was the only work which they had .", "speaker": "B"}, {"text": "they like four in the afternoon they had to report there was plane from prague to brno flying there ,", "speaker": "B"}, {"text": "so they very first thing was that they would always run back and at four ' clock and quickly make call , \" this plane is passing \"", "speaker": "B"}, {"text": "then second thing was that they took the line from this post to local pub .", "speaker": "B"}, {"text": "and they were calling from the pub .", "speaker": "B"}, {"text": "and they but third thing which they made , and when they screwed up , they finally they had to the pub owner to make these phone calls because they didn't even bother to be there anymore .", "speaker": "B"}, {"text": "and one day there was there was no plane .", "speaker": "B"}, {"text": "at least they were smart enough that they looked if the plane is flying there ,", "speaker": "B"}, {"text": "and the pub owner says \" my four ' clock , , quickly pick up the phone , call that there 's plane flying . \"", "speaker": "B"}, {"text": "there was no plane for some reason ,", "speaker": "B"}, {"text": "and there wasn't ?", "speaker": "E"}, {"text": "it was downed ,", "speaker": "B"}, {"text": "so they got in trouble .", "speaker": "B"}, {"text": "but . but .", "speaker": "B"}, {"text": "that 's that 's really", "speaker": "E"}, {"text": "that wouldn't be too difficult to try .", "speaker": "E"}, {"text": "could set that up .", "speaker": "E"}, {"text": "and we 'll just", "speaker": "E"}, {"text": "at least go test the test the assumption about - one to begin with .", "speaker": "B"}, {"text": "but then one can then think about some predictable result to change all of them .", "speaker": "B"}, {"text": "it 's just like we used to do these the distance measures .", "speaker": "B"}, {"text": "it might be that", "speaker": "B"}, {"text": "so the first set of variance weighting vectors would be just one modifying one and leaving the others the same .", "speaker": "E"}, {"text": "and and do that for each one .", "speaker": "E"}, {"text": "because you see , , what is happening here in in in such model is that it 's tells you what has low variance is is more reliable ,", "speaker": "B"}, {"text": "that would be one set of experiment", "speaker": "E"}, {"text": "wh - , when the data matches that , then you get really", "speaker": "E"}, {"text": "how do we know , especially when it comes to noise ?", "speaker": "B"}, {"text": "but there could just naturally be low variance .", "speaker": "E"}, {"text": "because like , 've noticed in the higher cepstral coefficients , the numbers seem to get smaller ,", "speaker": "E"}, {"text": "they have smaller means , also .", "speaker": "C"}, {"text": "and so it seems like they 're already compressed .", "speaker": "E"}, {"text": "the range of values .", "speaker": "E"}, {"text": "that 's why people used these lifters were inverse variance weighting lifters that makes euclidean distance more like mahalanobis distance with diagonal covariance when you knew wh the variances were over the old data .", "speaker": "B"}, {"text": "what they would do is that they would weight each coefficient by inverse of the variance .", "speaker": "B"}, {"text": "turns out that the variance decreases at least at fast , believe , as the index of the cepstral coefficients .", "speaker": "B"}, {"text": "you can show that analytically .", "speaker": "B"}, {"text": "so typically what happens is that you need to weight the weight the higher coefficients more than the lower coefficients .", "speaker": "B"}, {"text": "when we talked about aurora still wanted to make plea encourage for more communication between different parts of the distributed center .", "speaker": "B"}, {"text": "even when there is nothing to to say but the weather is good in ore - in berkeley .", "speaker": "B"}, {"text": "'m that it 's being appreciated in oregon and it will generate similar responses down here ,", "speaker": "B"}, {"text": "we can set up webcam .", "speaker": "C"}, {"text": "what , nowadays ,", "speaker": "B"}, {"text": "it 's actually do - able , almost .", "speaker": "B"}, {"text": "if we mail to \" aurora - inhouse \" , does that go up to you also ?", "speaker": "E"}, {"text": "so we should do that .", "speaker": "B"}, {"text": "so what is it", "speaker": "E"}, {"text": "we should definitely set up", "speaker": "B"}, {"text": "do we have mailing list that includes the ogi people ?", "speaker": "E"}, {"text": "we don't have .", "speaker": "C"}, {"text": "we should set that up .", "speaker": "E"}, {"text": "that would make it much easier .", "speaker": "E"}, {"text": "that would make it easier .", "speaker": "B"}, {"text": "so just call it \" aurora \" that would", "speaker": "E"}, {"text": "and then we also can send the dis to the same address", "speaker": "B"}, {"text": "and it goes to everybody", "speaker": "B"}, {"text": "we can set that up .", "speaker": "E"}, {"text": "because what 's happening naturally in research , know , is that people essentially start working on something and they don't want to be much bothered ,", "speaker": "B"}, {"text": "but what the then the danger is in group like this , is that two people are working on the same thing and both of them come with the very good solution , but it could have been done somehow in half of the effort .", "speaker": "B"}, {"text": "there 's another thing which wanted to report .", "speaker": "B"}, {"text": "lucash , , wrote the software for this aurora - two system .", "speaker": "B"}, {"text": "reasonably good one , because he 's doing it for intel ,", "speaker": "B"}, {"text": "but trust that we have rights to use it or distribute it and everything .", "speaker": "B"}, {"text": "cuz intel 's intentions originally was to distribute it free of charge anyways .", "speaker": "B"}, {"text": "and so we will make that at least you can see the software and if if it is of any use .", "speaker": "B"}, {"text": "it might be reasonable point for perhaps start converging .", "speaker": "B"}, {"text": "because morgan 's point is that he is an experienced guy .", "speaker": "B"}, {"text": "he says \" it 's very difficult to collaborate if you are working with supposedly the same thing , in quotes , except which is not is not the same .", "speaker": "B"}, {"text": "which which one is using that set of hurdles , another one set is using another set of hurdles .", "speaker": "B"}, {"text": "so . and then it 's difficult to compare .", "speaker": "B"}, {"text": "what about harry ?", "speaker": "C"}, {"text": "we received mail last week and you are starting to do some experiments .", "speaker": "C"}, {"text": "he got the he got the software .", "speaker": "B"}, {"text": "they sent the release .", "speaker": "B"}, {"text": "and use this intel version .", "speaker": "C"}, {"text": "because intel paid us", "speaker": "B"}, {"text": "should say on microphone ?", "speaker": "B"}, {"text": "some amount of money , not much .", "speaker": "B"}, {"text": "not much say on microphone .", "speaker": "B"}, {"text": "much less then we should have gotten for this amount of work .", "speaker": "B"}, {"text": "and they wanted to have software so that they can also play with it , which means that it has to be in certain environment", "speaker": "B"}, {"text": "they use actu actually some intel libraries , but in the process , lucash just rewrote the whole thing because he figured rather than trying to make sense of including icsi software not for training on the nets", "speaker": "B"}, {"text": "but he rewrote the or so somehow reused over the parts of the thing so that the whole thing , including mlp , trained mlp is one piece of software .", "speaker": "B"}, {"text": "is it useful ?", "speaker": "B"}, {"text": "remember when we were trying to put together all the icsi software for the submission .", "speaker": "A"}, {"text": "that 's what he was saying ,", "speaker": "B"}, {"text": "he said that it was like it was like just so many libraries and nobody knew what was used when ,", "speaker": "B"}, {"text": "and so that 's where he started and that 's where he realized that it needs to be needs to be at least cleaned up ,", "speaker": "B"}, {"text": "and so it this is available .", "speaker": "B"}, {"text": "the only thing would check is if he does he use intel math libraries ,", "speaker": "C"}, {"text": "because if it 's the case , it 's not so easy to use it on another architecture .", "speaker": "C"}, {"text": "not not in first not in first ap approximation", "speaker": "B"}, {"text": "because he started first just with plain or - plus before", "speaker": "B"}, {"text": "check on that .", "speaker": "B"}, {"text": "and in otherwise the intel libraries , they are available free of freely .", "speaker": "B"}, {"text": "but they may be running only on on windows .", "speaker": "B"}, {"text": "on intel architecture .", "speaker": "C"}, {"text": "on intel architecture , may not run in sun .", "speaker": "B"}, {"text": "that is that is that is possible .", "speaker": "B"}, {"text": "that 's why intel is distributing it ,", "speaker": "B"}, {"text": "there are at least there are optimized version for their architecture .", "speaker": "C"}, {"text": "never checked carefully these sorts of", "speaker": "C"}, {"text": "know there was some issues that initially we do all the development on linux", "speaker": "B"}, {"text": "but we use we don't have we have only three suns", "speaker": "B"}, {"text": "and we have them only because they have spert board in .", "speaker": "B"}, {"text": "otherwise otherwise we almost exclusively are working with pc 's now , with intel .", "speaker": "B"}, {"text": "in that way intel succeeded with us , because they gave us too many good machines for very little money or nothing .", "speaker": "B"}, {"text": "so . so we run everything on intel .", "speaker": "B"}, {"text": "does anybody have anything else ?", "speaker": "E"}, {"text": "shall we read some digits ?", "speaker": "E"}, {"text": "have to take my glasses", "speaker": "B"}, {"text": "hynek , if you 've ever done this .", "speaker": "E"}, {"text": "the way that it works is each person goes around in turn , and you say the transcript number and then you read the digits , the strings of numbers as individual digits .", "speaker": "E"}, {"text": "so you don't say \" eight hundred and fifty \" , you say \" eight five \" , and .", "speaker": "E"}, {"text": "so can can start then ?", "speaker": "B"}], "id": "xxxxx", "relations": [{"y": 1, "x": 0, "type": "Explanation"}]}]