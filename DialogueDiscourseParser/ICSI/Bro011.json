[{"edus": [{"text": "blow into it ,", "speaker": "B"}, {"text": "it works really .", "speaker": "B"}, {"text": "people say the strangest things when their microphones are on .", "speaker": "A"}, {"text": "so everybody 's on ?", "speaker": "A"}, {"text": "so you had meeting with with hynek which unfortunately had to miss .", "speaker": "A"}, {"text": "chuck you weren't there either ,", "speaker": "A"}, {"text": "you were there ?", "speaker": "A"}, {"text": "so everybody knows what happened except me .", "speaker": "A"}, {"text": "somebody should tell me .", "speaker": "A"}, {"text": "first we discussed about some of the points that was addressing in the mail sent last week .", "speaker": "C"}, {"text": "about the , the downsampling problem .", "speaker": "C"}, {"text": "and about the the length of the filters", "speaker": "C"}, {"text": "what was the what was the downsampling problem again ?", "speaker": "A"}, {"text": "so the fact that there is no low - pass filtering before the downsampling .", "speaker": "C"}, {"text": "there is because there is lda filtering but that 's perhaps not the best", "speaker": "C"}, {"text": "depends what it 's frequency characteristic is , .", "speaker": "A"}, {"text": "so you could do you could do stricter one .", "speaker": "A"}, {"text": "so we discussed about this , about the", "speaker": "C"}, {"text": "was there any conclusion about that ?", "speaker": "A"}, {"text": "\" try it \" .", "speaker": "C"}, {"text": "so again this is this is the downsampling of the the feature vector stream", "speaker": "A"}, {"text": "the lda filters they were doing do have", "speaker": "A"}, {"text": "let 's see , so the the feature vectors are calculated every ten milliseconds", "speaker": "A"}, {"text": "the question is how far down they are at fifty hertz .", "speaker": "A"}, {"text": "at twenty - five hertz since they 're downsampling by two .", "speaker": "A"}, {"text": "so . does anybody the frequency characteristic is ?", "speaker": "A"}, {"text": "we don't have yet", "speaker": "C"}, {"text": "we should have look first at , perhaps , the modulation spectrum .", "speaker": "C"}, {"text": "so there is this ,", "speaker": "C"}, {"text": "there is the length of the filters .", "speaker": "C"}, {"text": "so the this idea of trying to find filters with shorter delays .", "speaker": "C"}, {"text": "we started to work with this .", "speaker": "C"}, {"text": "and the third point was the ,", "speaker": "C"}, {"text": "the on - line normalization where ,", "speaker": "C"}, {"text": "the recursion recursion for the mean estimation is filter with some delay", "speaker": "C"}, {"text": "and that 's not taken into account now .", "speaker": "C"}, {"text": "and there again , .", "speaker": "C"}, {"text": "for this , the conclusion of hynek was , , \" we can try it but \"", "speaker": "C"}, {"text": "try try what ?", "speaker": "A"}, {"text": "so try to take into account the delay of the recursion for the mean estimation .", "speaker": "C"}, {"text": "and this we 've not worked on this yet .", "speaker": "C"}, {"text": "and so while discussing about these lda filters , some issues appeared , like", "speaker": "C"}, {"text": "the fact that if we look at the frequency response of these filters it 's", "speaker": "C"}, {"text": ", we really what 's the important part in the frequency response", "speaker": "C"}, {"text": "and there is the fact that in the very low frequency , these filters don't don't really remove lot . compared to the to the standard rasta filter .", "speaker": "C"}, {"text": "and that 's probably reason why , , on - line normalization helps because it ,", "speaker": "C"}, {"text": "it removed this mean .", "speaker": "C"}, {"text": ", but perhaps everything could should be could be in the filter ,", "speaker": "C"}, {"text": "the mean normalization and", "speaker": "C"}, {"text": "so that was that 's all we discussed about .", "speaker": "C"}, {"text": "we discussed about good things to do", "speaker": "C"}, {"text": "also , generally good to do for the research .", "speaker": "C"}, {"text": "and this was this lda tuning perhaps and hynek proposed again to his traps ,", "speaker": "C"}, {"text": "the key thing for me is figuring out how to better coordinate between the two sides", "speaker": "A"}, {"text": "was talking with hynek about it later", "speaker": "A"}, {"text": "and the had the sense that neither group of people wanted to bother the other group too much .", "speaker": "A"}, {"text": "and and don't think anybody is , , closed in their thinking or are unwilling to talk about things", "speaker": "A"}, {"text": "but that you were waiting for them to tell you that they had something for you", "speaker": "A"}, {"text": "and that and expected that they would do certain things", "speaker": "A"}, {"text": "and they were sor they didn't wanna bother you", "speaker": "A"}, {"text": "and they were waiting for you", "speaker": "A"}, {"text": "and and we ended up with this thing where they were filling up all of the possible latency themselves ,", "speaker": "A"}, {"text": "and they just had hadn't thought of that .", "speaker": "A"}, {"text": "it 's true that no one really thought about that this latency thing would be such strict issue", "speaker": "A"}, {"text": "what happened really , but", "speaker": "C"}, {"text": "it 's it 's also so the time constraints .", "speaker": "C"}, {"text": "because , , we discussed about that about this problem", "speaker": "C"}, {"text": "and they told us \" , we will do all that 's possible to have enough space for network \"", "speaker": "C"}, {"text": "but then , , perhaps they were too short with the time and", "speaker": "C"}, {"text": "then they couldn't .", "speaker": "A"}, {"text": "but there was also problem perhaps problem of communication .", "speaker": "C"}, {"text": "now we will try to", "speaker": "C"}, {"text": "just talk more .", "speaker": "A"}, {"text": "slikes and send mails .", "speaker": "C"}, {"text": "you 're you 're bus other than that you folks are busy doing all the all the things that you 're trying that we talked about before", "speaker": "A"}, {"text": "and this machines are busy", "speaker": "A"}, {"text": "and you 're busy", "speaker": "A"}, {"text": "let 's let 's , , that as we said before that one of the things that we 're imagining is that there will be in the system we end up with there 'll be something to explicitly do something about noise", "speaker": "A"}, {"text": "in addition to the other things that we 're talking about", "speaker": "A"}, {"text": "and that 's probably the best thing to do .", "speaker": "A"}, {"text": "and there was that one email that said that it sounded like things looked very promising up there", "speaker": "A"}, {"text": "in terms of they were using ericsson 's approach", "speaker": "A"}, {"text": "and in addition to", "speaker": "A"}, {"text": "they 're doing some noise removal thing ,", "speaker": "A"}, {"text": "so we 're will start to do this also .", "speaker": "C"}, {"text": "so carmen is just looking at the ericsson code .", "speaker": "C"}, {"text": "modifying studied barry 's sim code , more or less .", "speaker": "D"}, {"text": "to take @ @ the first step the spectral subtraction .", "speaker": "D"}, {"text": "and we have some the feature for italian database", "speaker": "D"}, {"text": "and we will try with this feature with the filter to find the result .", "speaker": "D"}, {"text": "but we haven't result until this moment .", "speaker": "D"}, {"text": "but , we are working in this also", "speaker": "D"}, {"text": "and try another type of spectral subtraction , don't", "speaker": "D"}, {"text": "when you say you don't have result yet you mean it 's it 's just that it 's in process", "speaker": "A"}, {"text": "or that you it finished and it didn't get good result ?", "speaker": "A"}, {"text": "no , no we have do the experiment", "speaker": "D"}, {"text": "only have the feature the feature but the experiment have", "speaker": "D"}, {"text": "we have not make the experiment", "speaker": "D"}, {"text": "will be good result or bad result ,", "speaker": "D"}, {"text": "so suggest actually now we we sorta move on and hear what 's what 's happening in other areas", "speaker": "A"}, {"text": "like what 's happening with your investigations about echos and so on .", "speaker": "A"}, {"text": "haven't started writing the test yet , 'm meeting with adam today", "speaker": "F"}, {"text": "and he 's going show me the scripts he has for running recognition on mee meeting recorder digits .", "speaker": "F"}, {"text": "also haven't got the code yet ,", "speaker": "F"}, {"text": "haven't asked hynek for the for his code yet .", "speaker": "F"}, {"text": "cuz looked at avendano 's thesis and don't really understand what he 's doing yet", "speaker": "F"}, {"text": "but it it sounded like the channel normalization part of his thesis was done in bit of what the word is , bit of rough way", "speaker": "F"}, {"text": "it sounded like he", "speaker": "F"}, {"text": "he it wasn't really fleshed out", "speaker": "F"}, {"text": "and he did something that was interesting for the test situation", "speaker": "F"}, {"text": "but 'm not if it 's what 'd wanna use", "speaker": "F"}, {"text": "so have to have to read it more ,", "speaker": "F"}, {"text": "don't really understand what he 's doing yet .", "speaker": "F"}, {"text": "haven't read it in while so 'm not gonna be too much help unless read it again ,", "speaker": "A"}, {"text": "know this is mine here .", "speaker": "D"}, {"text": "so you , and then you 're also gonna be doing this echo cancelling between the close mounted and the and the what we 're calling cheating experiment of sorts", "speaker": "A"}, {"text": "or 'm hoping 'm hoping espen will do it .", "speaker": "F"}, {"text": "that 's good .", "speaker": "A"}, {"text": "it 's good to delegate .", "speaker": "A"}, {"text": "he 's at least planning to do it for the cl close - mike cross - talk", "speaker": "F"}, {"text": "and so just take whatever setup he has and use it .", "speaker": "F"}, {"text": "wonder who else is", "speaker": "A"}, {"text": "it 's dan ellis is going to be doing different cancellation .", "speaker": "A"}, {"text": "one of the things that people working in the meeting task wanna get at is they would like to have cleaner close - miked recordings .", "speaker": "A"}, {"text": "so this is especially true for the lapel", "speaker": "A"}, {"text": "but even for the close - miked cases", "speaker": "A"}, {"text": "we 'd like to be able to have other sounds from other people and removed from", "speaker": "A"}, {"text": "so when someone isn't speaking you 'd like the part where they 're not speaking to actually be", "speaker": "A"}, {"text": "so what they 're talking about doing is using ec echo cancellation - like techniques .", "speaker": "A"}, {"text": "it 's not really echo but just", "speaker": "A"}, {"text": "taking the input from other mikes and using an adaptive filtering approach to remove the effect of that other speech .", "speaker": "A"}, {"text": "what was it ,", "speaker": "A"}, {"text": "there was there was some some point where eric or somebody was speaking and he had lots of silence in his channel", "speaker": "A"}, {"text": "and was saying something to somebody else which was in the background", "speaker": "A"}, {"text": "and it was not", "speaker": "A"}, {"text": "it was recognizing my words , which were the background speech on the close mike .", "speaker": "A"}, {"text": "the what we talked about yesterday ?", "speaker": "B"}, {"text": "that was actually my", "speaker": "B"}, {"text": "was wearing the was wearing the lapel and you were sitting next to me ,", "speaker": "B"}, {"text": "it was you was", "speaker": "A"}, {"text": "and only said one thing but you were talking and it was picking up all your words .", "speaker": "B"}, {"text": "so they would like clean channels .", "speaker": "A"}, {"text": "and for that mmm that purpose they 'd like to pull it out .", "speaker": "A"}, {"text": "so dan ellis or somebody who was working with him was going to work on that .", "speaker": "A"}, {"text": "and if we 've talked lately about the plans you 're developing that we talked about this morning", "speaker": "A"}, {"text": "don't remember if we talked about that last week or not ,", "speaker": "A"}, {"text": "but just quick reprise of what we were saying this morning .", "speaker": "A"}, {"text": "so continuing to extend", "speaker": "E"}, {"text": "what about the that mirjam has been doing ?", "speaker": "B"}, {"text": "and and shawn , .", "speaker": "B"}, {"text": "so they 're training up nets to try to recognize these acoustic features ?", "speaker": "B"}, {"text": "but that 's all that 's is certainly relevant study", "speaker": "A"}, {"text": "and , , what are the features that they 're finding .", "speaker": "A"}, {"text": "we have this problem with the overloading of the term \" feature \"", "speaker": "A"}, {"text": "what are the variables ,", "speaker": "A"}, {"text": "what we 're calling this one ,", "speaker": "A"}, {"text": "what are the variables that they 're found finding useful", "speaker": "A"}, {"text": "and their targets are based on canonical mappings of phones to acoustic features .", "speaker": "B"}, {"text": "and that 's certainly one thing to do and we 're gonna try and do something more more fine than that", "speaker": "A"}, {"text": "so what , was trying to remember some of the things we were saying ,", "speaker": "A"}, {"text": "do you ha still have that ?", "speaker": "A"}, {"text": "there 's those that", "speaker": "A"}, {"text": "some of some of the issues we were talking about was in just getting good handle on what \" good features \" are", "speaker": "A"}, {"text": "what does what did larry saul use for it was the sonorant detector ,", "speaker": "B"}, {"text": "how did he do that ?", "speaker": "B"}, {"text": "wh - what was his detector ?", "speaker": "B"}, {"text": "so how did he combine all these features ?", "speaker": "B"}, {"text": "what what mmm classifier did he", "speaker": "B"}, {"text": "you were talking about that , .", "speaker": "B"}, {"text": "and the other thing you were talking about is is where we get the targets from .", "speaker": "A"}, {"text": "so , there 's these issues of what are the what are the variables that you use", "speaker": "A"}, {"text": "and do you combine them using the soft \" and - or \" or you do something , , more complicated", "speaker": "A"}, {"text": "and then the other thing was so where do you get the targets from ?", "speaker": "A"}, {"text": "the initial thing is just the obvious that we 're discussing is starting up with phone labels from somewhere and then doing the transformation .", "speaker": "A"}, {"text": "but then the other thing is to do something better", "speaker": "A"}, {"text": "and why don't you tell us again about this database ?", "speaker": "A"}, {"text": "and then tell them to talk naturally ?", "speaker": "A"}, {"text": "you could just mount it to that and they wouldn't even notice .", "speaker": "B"}, {"text": "you could go to these parlors and you could , have , , reduced rates if you if you can do the measurements .", "speaker": "A"}, {"text": "you could what you could do is you could sell little rings and with embedded , transmitters in them and things", "speaker": "B"}, {"text": "be and help science .", "speaker": "A"}, {"text": "there 's bunch of data that around ,", "speaker": "B"}, {"text": "that people have done studies like that way back", "speaker": "B"}, {"text": "'t remember where wisconsin or someplace that used to have big database of", "speaker": "B"}, {"text": "remember there was this guy at - andt ,", "speaker": "B"}, {"text": "or what was his name ?", "speaker": "B"}, {"text": "do you remember that guy ?", "speaker": "B"}, {"text": "researcher at - andt while back that was studying , trying to do speech recognition from these kinds of features .", "speaker": "B"}, {"text": "'t remember what his name was .", "speaker": "B"}, {"text": "now 'll think of it .", "speaker": "B"}, {"text": "that 's interesting .", "speaker": "B"}, {"text": "do you mean but you mar", "speaker": "A"}, {"text": "he was the guy the guy that was using", "speaker": "C"}, {"text": "you mean when was mark randolph there , or ?", "speaker": "A"}, {"text": "he 's he 's at motorola now .", "speaker": "A"}, {"text": "is it the guy that was using the pattern of pressure on the tongue", "speaker": "C"}, {"text": "'t remember exactly what he was using , now .", "speaker": "B"}, {"text": "but know remember it had to do with positional parameters", "speaker": "B"}, {"text": "and trying to do speech recognition based on them .", "speaker": "B"}, {"text": "so the only the only hesitation had about it since , haven't see the data is it sounds like it 's continuous variables and bunch of them .", "speaker": "A"}, {"text": "how complicated it is to go from there", "speaker": "A"}, {"text": "what you really want are these binary labels , and just few of them .", "speaker": "A"}, {"text": "and there 's trivial mapping if you wanna do it", "speaker": "A"}, {"text": "and it 's but it", "speaker": "A"}, {"text": "worry little bit that this is research project in itself ,", "speaker": "A"}, {"text": "whereas if you did something instead that like having some manual annotation by , linguistics students ,", "speaker": "A"}, {"text": "this would there 'd be limited set of things that you could do as per our discussions with john before", "speaker": "A"}, {"text": "but the things that you could do , like nasality and voicing and couple other things you probably could do reasonably .", "speaker": "A"}, {"text": "and then there would it would really be this binary variable .", "speaker": "A"}, {"text": "course then , that 's the other question is do you want binary variables .", "speaker": "A"}, {"text": "the other thing you could do is boot trying to get those binary variables", "speaker": "A"}, {"text": "and take the continuous variables from the data itself there ,", "speaker": "A"}, {"text": "could you cluster the just do some clustering ?", "speaker": "B"}, {"text": "you could , .", "speaker": "A"}, {"text": "bin them up into different categories and", "speaker": "B"}, {"text": "so anyway that 's that 's that 's another whole direction that cou could be looked at .", "speaker": "A"}, {"text": "in general it 's gonna be for new data that you look at ,", "speaker": "A"}, {"text": "it 's gonna be hidden variable because we 're not gonna get everybody sitting in these meetings to wear the pellets and", "speaker": "A"}, {"text": "so you 're talking about using that data to get", "speaker": "B"}, {"text": "instead of using canonical mappings of phones .", "speaker": "B"}, {"text": "so you 'd use that data to give you what the true mappings are for each phone ?", "speaker": "B"}, {"text": "so wh , where this fits into the rest in my mind , , is that we 're looking at different ways that we can combine different kinds of rep front - end representations in order to get robustness under difficult or even , , typical conditions .", "speaker": "A"}, {"text": "and part of it , this robustness , seems to come from multi - stream or multi - band sorts of things", "speaker": "A"}, {"text": "and saul seems to have reasonable way of looking at it , at least for one articulatory feature .", "speaker": "A"}, {"text": "the question is can we learn from that to change some of the other methods we have , since", "speaker": "A"}, {"text": "one of the things that 's about what he had was that it", "speaker": "A"}, {"text": "the decision about how strongly to train the different pieces is based on reasonable criterion with hidden variables", "speaker": "A"}, {"text": "rather than just assuming that you should train every detector with equal strength towards it being this phone or that phone .", "speaker": "A"}, {"text": "so it so he 's got these", "speaker": "A"}, {"text": "he \" and 's \" between these different features .", "speaker": "A"}, {"text": "it 's soft \" and \" ,", "speaker": "A"}, {"text": "but in principle you wanna get strong concurrence of all the different things that indicate something", "speaker": "A"}, {"text": "and then he \" or 's \" across the different soft \" or 's \" across the different multi - band channels .", "speaker": "A"}, {"text": "the target for the training of the \" and \" \" and ' ed \" things is something that 's kept as hidden variable ,", "speaker": "A"}, {"text": "and is learned with .", "speaker": "A"}, {"text": "whereas what we were doing is taking the phone target and then just back propagating from that", "speaker": "A"}, {"text": "so he doesn't have", "speaker": "B"}, {"text": "which means that it 's it 's it could be that for particular point in the data you don't want to train particular band train the detectors for particular band .", "speaker": "A"}, {"text": "you you wanna ignore that band , cuz that 's ban - band is noisy measure .", "speaker": "A"}, {"text": "we 're we 're still gonna try to train it up .", "speaker": "A"}, {"text": "in our scheme we 're gonna try to train it up to do as as it can at predicting .", "speaker": "A"}, {"text": "that 's not the thing to do .", "speaker": "A"}, {"text": "so he doesn't have to have truth marks", "speaker": "B"}, {"text": "and he doesn't have to have hard labels .", "speaker": "E"}, {"text": "at the at the tail end , , he has to 's where it 's sonorant .", "speaker": "A"}, {"text": "but he 's but what he 's - but what he 's not training up what he doesn't depend on as truth is", "speaker": "A"}, {"text": "for the full band .", "speaker": "E"}, {"text": "one way of describing would be", "speaker": "A"}, {"text": "if sound is sonorant is it sonorant in this band ?", "speaker": "A"}, {"text": "is it sonorant in that band ?", "speaker": "A"}, {"text": "is it sonorant in that band ?", "speaker": "A"}, {"text": "it 's hard to even answer that", "speaker": "A"}, {"text": "what you really mean is that the whole sound is sonorant .", "speaker": "A"}, {"text": "then it comes down to , , to what extent should you make use of information from particular band towards making your decision .", "speaker": "A"}, {"text": "and we 're making in sense this hard decision that you should you should use everything with equal strength .", "speaker": "A"}, {"text": "and because in the ideal case we would be going for posterior probabilities ,", "speaker": "A"}, {"text": "if we had enough data to really get posterior probabilities", "speaker": "A"}, {"text": "and if the if we also had enough data so that it was representative of the test data", "speaker": "A"}, {"text": "then we would be doing the thing to train everything as hard as we can .", "speaker": "A"}, {"text": "but this is something that 's more built up along an idea of robustness from the beginning", "speaker": "A"}, {"text": "and so you don't necessarily want to train everything up towards the", "speaker": "A"}, {"text": "so where did he get his his tar his high - level targets about what 's sonorant and what 's not ?", "speaker": "B"}, {"text": "from canonical mappings at first", "speaker": "E"}, {"text": "and then it 's unclear", "speaker": "E"}, {"text": "and then he does some fine tuning for special cases .", "speaker": "E"}, {"text": "we ha we have iterative training because we do this embedded viterbi ,", "speaker": "A"}, {"text": "so there is some something that 's suggested , based on the data", "speaker": "A"}, {"text": "but it 's it 's not", "speaker": "A"}, {"text": "it doesn't seem like it 's quite the same , cuz of this", "speaker": "A"}, {"text": "cuz then whatever that alignment is , it 's that for all bands .", "speaker": "A"}, {"text": "no , that 's not quite , we did actually do them separate tried to do them separately", "speaker": "A"}, {"text": "so that would be little more like what he did .", "speaker": "A"}, {"text": "but it 's still not quite the same because then it 's it 's setting targets based on where you would say the sound begins in particular band .", "speaker": "A"}, {"text": "where he 's this is not labeling per se .", "speaker": "A"}, {"text": "might be closer if we did soft target embedded neural net training like we 've done few times", "speaker": "A"}, {"text": "the forward do the forward calculations to get the gammas and train on those .", "speaker": "A"}, {"text": "what 's next ?", "speaker": "A"}, {"text": "could say little bit about 've been playing with .", "speaker": "B"}, {"text": "you 're playing ?", "speaker": "A"}, {"text": "you 're playing ?", "speaker": "A"}, {"text": "yes , 'm playing .", "speaker": "B"}, {"text": "so wanted to do this experiment to see what happens if we try to improve the performance of the back - end recognizer for the aurora task", "speaker": "B"}, {"text": "and see how that affects things .", "speaker": "B"}, {"text": "and so had this sent around last week this plan had for an experiment ,", "speaker": "B"}, {"text": "this matrix where would take the the original the original system .", "speaker": "B"}, {"text": "so there 's the original system trained on the mel cepstral features", "speaker": "B"}, {"text": "and then com and then optimize the htk system and run that again .", "speaker": "B"}, {"text": "so look at the difference there", "speaker": "B"}, {"text": "and then do the same thing for the icsi - ogi front - end .", "speaker": "B"}, {"text": "what which test set was this ?", "speaker": "A"}, {"text": "that looked at ?", "speaker": "B"}, {"text": "'m looking at the italian now .", "speaker": "B"}, {"text": "so as far as 've gotten is 've been able to go through from beginning to end the full htk system for the italian data", "speaker": "B"}, {"text": "and got the same results that that stephane had .", "speaker": "B"}, {"text": "so started looking to and now 'm 'm lookin at the point where wanna should change in the htk back - end in order to try to to improve it .", "speaker": "B"}, {"text": "one of the first things of was the fact that they use the same number of states for all of the models", "speaker": "B"}, {"text": "and so went on - line and found pronunciation dictionary for italian digits", "speaker": "B"}, {"text": "and just looked at , , the number of phones in each one of the digits .", "speaker": "B"}, {"text": "the canonical way of setting up an system is that you use three states per phone", "speaker": "B"}, {"text": "and so then the total number of states for word would just be , , the number of phones times three .", "speaker": "B"}, {"text": "and so when did that for the italian digits , got number of states , ranging on the low end from nine to the high end , eighteen .", "speaker": "B"}, {"text": "now you have to really add two to that because in htk there 's an initial null and final null", "speaker": "B"}, {"text": "so when they use models that have eighteen states , there 're really sixteen states .", "speaker": "B"}, {"text": "they 've got those initial and final null states .", "speaker": "B"}, {"text": "and so their of eighteen states seems to be pretty matched to the two longest words of the italian digits ,", "speaker": "B"}, {"text": "the four and five which , according to my , , off the cuff calculation , should have eighteen states each .", "speaker": "B"}, {"text": "and so they had sixteen .", "speaker": "B"}, {"text": "so that 's pretty close .", "speaker": "B"}, {"text": "but for the most of the words are sh much shorter .", "speaker": "B"}, {"text": "so the majority of them wanna have nine states .", "speaker": "B"}, {"text": "and so theirs are twice as long .", "speaker": "B"}, {"text": "and then if you printed out confusion matrix for the - matched case ,", "speaker": "B"}, {"text": "and it turns out that the longest words are actually the ones that do the best .", "speaker": "B"}, {"text": "so my about what 's happening is that , if you assume fixed the same amount of training data for each of these digits", "speaker": "B"}, {"text": "and fixed length model for all of them", "speaker": "B"}, {"text": "but the actual words for some of them are half as long", "speaker": "B"}, {"text": "you really have , , half as much training data for those models .", "speaker": "B"}, {"text": "because if you have long word and you 're training it to eighteen states , you 've got , you 've got the same number of gaussians , you 've gotta train in each case ,", "speaker": "B"}, {"text": "but for the shorter words , , the total number of frames is actually half as many .", "speaker": "B"}, {"text": "so it could be that , , for the short words there 's because you have so many states , you just don't have enough data to train all those gaussians .", "speaker": "B"}, {"text": "so 'm going to try to create more word - specific prototype ms to start training from .", "speaker": "B"}, {"text": ", it 's not uncommon you do worse on long word on short words than long words anyway just because you 're accumulating more evidence for the for the longer word ,", "speaker": "A"}, {"text": "so 'll 'll , the next experiment 'm gonna try is to just create models that seem to be more matched to my about how long they should be .", "speaker": "B"}, {"text": "and as part of that wanted to see how the", "speaker": "B"}, {"text": "how these models were coming out , , what when we train up , the model for \" one \" , which wants to have nine states , ,", "speaker": "B"}, {"text": "what is the what do the transition probabilities look like in the self - loops , look like in those models ?", "speaker": "B"}, {"text": "and so talked to andreas and he explained to me how you can calculate the expected duration of an just by looking at the transition matrix", "speaker": "B"}, {"text": "and so wrote little matlab script that calculates that", "speaker": "B"}, {"text": "so 'm gonna print those out for each of the words to see what 's happening , , how these models are training up ,", "speaker": "B"}, {"text": "the long ones versus the short ones .", "speaker": "B"}, {"text": "quickly , did the silence model", "speaker": "B"}, {"text": "that 's coming out with about one point two seconds as its average duration", "speaker": "B"}, {"text": "and the silence model 's the one that 's used at the beginning and the end of each of the string of digits .", "speaker": "B"}, {"text": "lots of silence .", "speaker": "A"}, {"text": "and so the model , which is what they put in between digits , haven't calculated that for that one yet ,", "speaker": "B"}, {"text": "so they their model for whole digit string is silence digit , sp , digit , sp blah - blah and then silence at the end .", "speaker": "B"}, {"text": "are the sp 's optional ?", "speaker": "A"}, {"text": "have to look at that , but 'm not that they are .", "speaker": "B"}, {"text": "now the one thing about the model is really it only has single emitting state to it .", "speaker": "B"}, {"text": "so if it 's not optional , , it 's it 's not gonna hurt whole lot", "speaker": "B"}, {"text": "and it 's tied to the center state of the silence model so it 's not its own", "speaker": "B"}, {"text": "it doesn't require its own training data ,", "speaker": "B"}, {"text": "it just shares that state .", "speaker": "B"}, {"text": "so it , , it 's pretty good the way that they have it set up ,", "speaker": "B"}, {"text": "so wanna play with that little bit more .", "speaker": "B"}, {"text": "'m curious about looking at , how these models have trained and looking at the expected durations of the models", "speaker": "B"}, {"text": "and wanna compare that in the - matched case to the unmatched case , and see if you can get an idea of", "speaker": "B"}, {"text": "just from looking at the durations of these models , , what 's happening .", "speaker": "B"}, {"text": ", that , as much as you can , it 's good to not do anything really tricky .", "speaker": "A"}, {"text": "not do anything that 's really finely tuned ,", "speaker": "A"}, {"text": "but just you you", "speaker": "A"}, {"text": "the premise is you have good person look at this for few weeks and what do you come up with ?", "speaker": "A"}, {"text": "and hynek , when wa told him about this , he had an interesting point ,", "speaker": "B"}, {"text": "and that was the final models that they end up training up have probably something on the order of six gaussians per state .", "speaker": "B"}, {"text": "so they 're fairly , , hefty models .", "speaker": "B"}, {"text": "and hynek was saying that , probably in real application , you wouldn't have enough compute to handle models that are very big or complicated .", "speaker": "B"}, {"text": "so what we may want are simpler models .", "speaker": "B"}, {"text": "and compare how they perform to that .", "speaker": "B"}, {"text": "but , it depends on what the actual application is", "speaker": "B"}, {"text": "and it 's really hard to your limits are in terms of how many gaussians you can have .", "speaker": "B"}, {"text": "and that , , at the moment that 's not the limitation ,", "speaker": "A"}, {"text": "what you were gonna say but which was thinking was", "speaker": "A"}, {"text": "where did six come from ?", "speaker": "A"}, {"text": "probably came from the same place eighteen came from .", "speaker": "A"}, {"text": "that 's another parameter ,", "speaker": "A"}, {"text": "that , , you really want three or nine or", "speaker": "A"}, {"text": "one thing , if if start reducing the number of states for some of these shorter models that 's gonna reduce the total number of gaussians .", "speaker": "B"}, {"text": "so in sense it 'll be simpler system .", "speaker": "B"}, {"text": "but now again the idea is doing just very simple things", "speaker": "A"}, {"text": "how much better can you make it ?", "speaker": "A"}, {"text": "and since they 're only simple things there 's nothing that you 're gonna do that is going to blow up the amount of computation", "speaker": "A"}, {"text": "if you found that nine was better than six that would be , , actually .", "speaker": "A"}, {"text": "doesn't have to go down .", "speaker": "A"}, {"text": "really wasn't even gonna play with that part of the system yet ,", "speaker": "B"}, {"text": "was just gonna change the", "speaker": "B"}, {"text": "just work with the models ,", "speaker": "A"}, {"text": "just look at the length of the models and just see what happens .", "speaker": "B"}, {"text": "your plan for you you ' plan for the next week is just continue on these same things we 've been talking about for aurora and", "speaker": "A"}, {"text": "we can try to have some new baseline for next week perhaps .", "speaker": "C"}, {"text": "with all these minor things modified .", "speaker": "C"}, {"text": "and then do other things ,", "speaker": "C"}, {"text": "play with the spectral subtraction ,", "speaker": "C"}, {"text": "and retry the msg and things like that .", "speaker": "C"}, {"text": "we have big list .", "speaker": "A"}, {"text": "you have big list of things to do .", "speaker": "A"}, {"text": "that 's good .", "speaker": "A"}, {"text": "that after all of this confusion settles down in another", "speaker": "A"}, {"text": "some point little later next year there will be some standard and it 'll get out there", "speaker": "A"}, {"text": "and hopefully it 'll have some effect from something that has been done by our group of people", "speaker": "A"}, {"text": "even if it doesn't there 's there 's go there 'll be standards after that .", "speaker": "A"}, {"text": "does anybody know how to run matlab", "speaker": "B"}, {"text": "in batch mode like you send it bunch of commands to run and it gives you the output .", "speaker": "B"}, {"text": "is it possible to do that ?", "speaker": "B"}, {"text": "and he says it 's impossible so he went to octave .", "speaker": "E"}, {"text": "octave is the unix clone of matlab which you can batch .", "speaker": "E"}, {"text": "was going crazy trying to do that .", "speaker": "B"}, {"text": "what is octave so ?", "speaker": "C"}, {"text": "it 's free software ?", "speaker": "C"}, {"text": "what 's that ?", "speaker": "E"}, {"text": "it 's it 's free .", "speaker": "E"}, {"text": "we have it here running somewhere .", "speaker": "E"}, {"text": "and it does the same syntax and everything", "speaker": "C"}, {"text": "like matlab , or ?", "speaker": "C"}, {"text": "it 's little behind ,", "speaker": "E"}, {"text": "it 's the same syntax but it 's little behind in that matlab went to these like", "speaker": "E"}, {"text": "you can have cells and you can implement object - oriented type things with matlab .", "speaker": "E"}, {"text": "octave doesn't do that yet ,", "speaker": "E"}, {"text": "octave is kinda like matlab", "speaker": "E"}, {"text": "four point something or .", "speaker": "E"}, {"text": "if it 'll do like lot of the basic matrix and vector", "speaker": "B"}, {"text": "the basic , .", "speaker": "E"}, {"text": "that 's perfect .", "speaker": "B"}, {"text": "we 're done .", "speaker": "A"}], "id": "xxxxx", "relations": [{"y": 1, "x": 0, "type": "Explanation"}]}]