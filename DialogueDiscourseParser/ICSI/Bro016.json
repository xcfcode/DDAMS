[{"edus": [{"text": "let 's see .", "speaker": "E"}, {"text": "was saying hynek 'll be here next week ,", "speaker": "E"}, {"text": "won't be here thursday and friday .", "speaker": "E"}, {"text": "but my suggestion is that , , at least for this meeting , people should go ahead ,", "speaker": "E"}, {"text": "cuz hynek will be here ,", "speaker": "E"}, {"text": "we don't have any czech accent yet ,", "speaker": "E"}, {"text": "as far as know ,", "speaker": "E"}, {"text": "there we go .", "speaker": "E"}, {"text": "so other than reading digits , what 's our agenda ?", "speaker": "E"}, {"text": "don't really have , , anything new .", "speaker": "F"}, {"text": "been working on meeting recorder .", "speaker": "F"}, {"text": "do you think that would be the case for next week also ?", "speaker": "E"}, {"text": "or is , ?", "speaker": "E"}, {"text": "what 's your projection on ?", "speaker": "E"}, {"text": "cuz the one thing the one thing that seems to me we really should try , if you hadn't tried it before , because it hadn't occurred to me", "speaker": "E"}, {"text": "it was an obvious thing", "speaker": "E"}, {"text": "is , , adjusting the , , sca the scaling and , , insertion penalty sorta .", "speaker": "E"}, {"text": "did play with that , actually , little bit .", "speaker": "F"}, {"text": "what happens is , , when you get to the noisy , you start getting lots of insertions .", "speaker": "F"}, {"text": "so 've tried playing around little bit with , , the insertion penalties and things like that .", "speaker": "F"}, {"text": "it didn't make whole lot of difference .", "speaker": "F"}, {"text": "like for the - matched case , it seemed like it was pretty good .", "speaker": "F"}, {"text": "could do more playing with that , though .", "speaker": "F"}, {"text": "but you were looking at mel cepstrum .", "speaker": "E"}, {"text": "you 're talking about for for our features .", "speaker": "F"}, {"text": "so , , it 's not the direction that you were working with that we were saying what 's the , what 's the best you can do with mel cepstrum .", "speaker": "E"}, {"text": "but , they raised very valid point ,", "speaker": "E"}, {"text": "so , to first order , you have other things you were gonna do ,", "speaker": "E"}, {"text": "but to first order , would say that the conclusion is that if you , , do , , some monkeying around with , , the exact htk training and @ @ with , , , how many states and , that it doesn't particularly improve the performance .", "speaker": "E"}, {"text": "in other words , that even though it sounds pretty dumb , just applying the same number of states to everything , more or less , no matter what language , isn't so bad .", "speaker": "E"}, {"text": "and you hadn't gotten to all the experiments you wanted to do with number of gaussians ,", "speaker": "E"}, {"text": "if we had to if we had to draw conclusion on the information we have so far , we 'd say something like that .", "speaker": "E"}, {"text": "so the next question to ask , which is the one that that andreas was dre addressing himself to in the lunch meeting , is , , we 're not supposed to adjust the back - end ,", "speaker": "E"}, {"text": "but anybody using the system would .", "speaker": "E"}, {"text": "if you were just adjusting the back - end , how much better would you do , , in noise ?", "speaker": "E"}, {"text": "because the language scaling and insertion penalties and are probably set to be about for mel cepstrum .", "speaker": "E"}, {"text": "but , , they 're probably not set for these things ,", "speaker": "E"}, {"text": "particularly these things that look over , , larger time windows , in one way or another with lda and klt and neural nets and all these things .", "speaker": "E"}, {"text": "in the fa past we 've always found that we had to increase the insertion penalty to correspond to such things .", "speaker": "E"}, {"text": "that 's , , @ @ that 's first - order thing that we should try .", "speaker": "E"}, {"text": "so the experiment is to , , run our front - end like normal , with the default , , insertion penalties and ,", "speaker": "F"}, {"text": "and then tweak that little bit", "speaker": "F"}, {"text": "and see how much of difference it makes", "speaker": "F"}, {"text": "so by \" our front - end \" take , , the aurora - two take some version that stephane has that is , , our current best version of something .", "speaker": "E"}, {"text": "don't wanna do this over hundred different things that they 've tried", "speaker": "E"}, {"text": "but , , for some version that you say is good one .", "speaker": "E"}, {"text": "how how much , , does it improve if you actually adjust that ?", "speaker": "E"}, {"text": "but it is interesting .", "speaker": "E"}, {"text": "you say you have for the noisy", "speaker": "E"}, {"text": "how about for the for the mismatched or or the medium mismatched conditions ?", "speaker": "E"}, {"text": "when you adjusted those numbers for mel cepstrum , did it ?", "speaker": "E"}, {"text": "don't remember off the top of my head .", "speaker": "F"}, {"text": "didn't even write them down .", "speaker": "F"}, {"text": "did write down ,", "speaker": "F"}, {"text": "so , when was doing wrote down some numbers for the - matched case .", "speaker": "F"}, {"text": "looking at the wrote down what the deletions , substitutions , and insertions were ,", "speaker": "F"}, {"text": "for different numbers of states per phone .", "speaker": "F"}, {"text": "but , , that 's all wrote down .", "speaker": "F"}, {"text": "would need to do that .", "speaker": "F"}, {"text": "do that for next week .", "speaker": "F"}, {"text": "also , , sometimes if you run behind on some of these things , we can get someone else to do it", "speaker": "E"}, {"text": "and you can supervise .", "speaker": "E"}, {"text": "but it would be it 'd be good to know that .", "speaker": "E"}, {"text": "need to get , , front - end , , from you", "speaker": "F"}, {"text": "or you point me to some files that you 've already calculated .", "speaker": "F"}, {"text": "probably will have time to do that and time to play little bit with the silence model .", "speaker": "F"}, {"text": "so have that for next week when hynek 's here .", "speaker": "F"}, {"text": "cuz , , the other", "speaker": "E"}, {"text": "that , , might have been part of what , , the difference was", "speaker": "E"}, {"text": "at least part of it that we were seeing .", "speaker": "E"}, {"text": "remember we were seeing the sri system was so much better than the tandem system .", "speaker": "E"}, {"text": "part of it might just be that the sri system , they they always adjust these things to be optimized ,", "speaker": "E"}, {"text": "wonder if there 's anything that we could do to the front - end that would affect the insertion", "speaker": "F"}, {"text": "what could you do ?", "speaker": "F"}, {"text": "part of what 's going on , , is the , , the range of values .", "speaker": "E"}, {"text": "so , if you have something that has much smaller range or much larger range , and taking the appropriate root .", "speaker": "E"}, {"text": "if something is like the equivalent of bunch of probabilities multiplied together , you can take root of some sort .", "speaker": "E"}, {"text": "if it 's like seven probabilities together , you can take the seventh root of it ,", "speaker": "E"}, {"text": "or if it 's in the log domain , divide it by seven .", "speaker": "E"}, {"text": "that has similar effect", "speaker": "E"}, {"text": "because it changes the scale of the numbers of the differences between different candidates from the acoustic model", "speaker": "E"}, {"text": "as opposed to what 's coming from the language model .", "speaker": "E"}, {"text": "so , in effect , that 's changing the value of your insertion penalty .", "speaker": "F"}, {"text": "it 's more directly like the language scaling or the , the model scaling or acoustic scaling ,", "speaker": "E"}, {"text": "that 's interesting .", "speaker": "F"}, {"text": "but that those things have similar effect to the insertion penalty", "speaker": "E"}, {"text": "anyway . they 're slightly different way of handling it .", "speaker": "E"}, {"text": "so if we the insertion penalty is , then we can get an idea about what range our number should be in ,", "speaker": "F"}, {"text": "so that they match with that .", "speaker": "F"}, {"text": "so that 's why", "speaker": "E"}, {"text": "that 's another reason other than curiosity as to why it would be kinda neat to find out if we 're way off .", "speaker": "E"}, {"text": "the other thing is , are aren't we seeing ?", "speaker": "E"}, {"text": "'m you 've already looked at this", "speaker": "E"}, {"text": "bu in these noisy cases , are ? we are seeing lots of insertions .", "speaker": "E"}, {"text": "the insertion number is quite high ?", "speaker": "E"}, {"text": "know the vad takes pre care of part of that ,", "speaker": "E"}, {"text": "'ve seen that with the mel cepstrum .", "speaker": "F"}, {"text": "don't about the aurora front - end ,", "speaker": "F"}, {"text": "it 's much more balanced with , when the front - end is more robust .", "speaker": "B"}, {"text": "could look at it at this .", "speaker": "B"}, {"text": "wha - what 's typical number ?", "speaker": "E"}, {"text": "you , you .", "speaker": "E"}, {"text": "don't have this in", "speaker": "B"}, {"text": "'m it 's more balanced ,", "speaker": "E"}, {"text": "but it it wouldn't surprise me if there 's still", "speaker": "E"}, {"text": "in the the old systems we used to do , , remember numbers like insertions being half the number of deletions , as being and both numbers being tend to be on the small side comparing to , , substitutions .", "speaker": "E"}, {"text": "the whole problem with insertions was what , , we talked about when the guy from ogi came down that one time", "speaker": "F"}, {"text": "and that was when people were saying , we should have , , voice activity detector", "speaker": "F"}, {"text": "that , because all that that we 're getting thr the silence that 's getting through is causing insertions .", "speaker": "F"}, {"text": "'ll bet you there 's still lot of insertions .", "speaker": "F"}, {"text": "and it may be less of critical thing .", "speaker": "E"}, {"text": "the fact that some get by may be less of critical thing if you , , get things in the range .", "speaker": "E"}, {"text": "so , , the insertions is symptom .", "speaker": "E"}, {"text": "it 's symptom that there 's something , , wrong with the range .", "speaker": "E"}, {"text": "but there 's , your your substitutions tend to go up as .", "speaker": "E"}, {"text": "so , , that ,", "speaker": "E"}, {"text": "the most obvious thing is just the insertions , @ @ .", "speaker": "E"}, {"text": "if you 're operating in the wrong range , that 's why just in general , if you change what these penalties and scaling factors are , you reach some point that 's that 's minimum .", "speaker": "E"}, {"text": "we do have to do over range of different conditions ,", "speaker": "E"}, {"text": "some of which are noisier than others .", "speaker": "E"}, {"text": "but , , we may get better handle on that if we if we see", "speaker": "E"}, {"text": "it 's if we actually could pick more stable value for the range of these features , it , , , could", "speaker": "E"}, {"text": "even though it 's it 's true that in real situation you can adjust the these scaling factors in the back - end , and it 's ar artificial here that we 're not adjusting those , you certainly don't wanna be adjusting those all the time .", "speaker": "E"}, {"text": "and if you have front - end that 's in roughly the range", "speaker": "E"}, {"text": "remember after we got our more or less together in the previous systems we built , that we tended to set those scaling factors at standard level ,", "speaker": "E"}, {"text": "and we would rarely adjust them again ,", "speaker": "E"}, {"text": "even though you could get", "speaker": "E"}, {"text": "for an evaluation you can get an extra point if you tweaked it little bit .", "speaker": "E"}, {"text": "once we knew what rou roughly the operating range was , it was pretty stable ,", "speaker": "E"}, {"text": "and , we might just not even be in the operating range .", "speaker": "E"}, {"text": "so , would the ?", "speaker": "F"}, {"text": "would good idea be to try to map it into the same range that you get in the - matched case ?", "speaker": "F"}, {"text": "so , if we computed what the range was in - matched , and then when we get our noisy conditions out we try to make it have the same range as ?", "speaker": "F"}, {"text": "no . you don't wanna change it for different conditions .", "speaker": "E"}, {"text": "what what 'm saying", "speaker": "E"}, {"text": "wasn't suggesting change it for different conditions .", "speaker": "F"}, {"text": "was just saying that when we pick range , we wanna pick range that we map our numbers into", "speaker": "F"}, {"text": "we should probably pick it based on the range that we get in the - matched case .", "speaker": "F"}, {"text": "otherwise , , what range are we gonna choose", "speaker": "F"}, {"text": "to map everything into ?", "speaker": "F"}, {"text": "it depends how much we wanna do gamesmanship and how much we wanna do", "speaker": "E"}, {"text": "it to me , actually , even if you wanna be play on the gamesmanship side , it can be kinda tricky .", "speaker": "E"}, {"text": "so , , what you would do is set the set the scaling factors , , so that you got the best number for this point four five times the , and so on .", "speaker": "E"}, {"text": "but they might change that", "speaker": "E"}, {"text": "sorta think we need to explore the space .", "speaker": "E"}, {"text": "just take look at it little bit .", "speaker": "E"}, {"text": "and we we may just find that we 're way off .", "speaker": "E"}, {"text": "we 're not .", "speaker": "E"}, {"text": "as for these other things , it may turn out that , , it 's reasonable .", "speaker": "E"}, {"text": "andreas gave very reasonable response ,", "speaker": "E"}, {"text": "and he 's probably not gonna be the only one who 's gonna say this in the future", "speaker": "E"}, {"text": "people within this tight - knit community who are doing this evaluation are accepting , , more or less , that these are the rules .", "speaker": "E"}, {"text": "but , people outside of it who look in at the broader picture are certainly gonna say \" , minute . you 're doing all this standing on your head , , on the front - end ,", "speaker": "E"}, {"text": "when all you could do is just adjust this in the back - end with one one knob . \"", "speaker": "E"}, {"text": "so we have to at least , , determine that 's not true ,", "speaker": "E"}, {"text": "which would be ,", "speaker": "E"}, {"text": "or determine that it is true ,", "speaker": "E"}, {"text": "in which case we want to adjust that", "speaker": "E"}, {"text": "and then continue with what we 're doing .", "speaker": "E"}, {"text": "and as you say as you point out finding ways to then compensate for that in the front - end also then becomes priority for this particular test ,", "speaker": "E"}, {"text": "and saying you don't have to do that .", "speaker": "E"}, {"text": "what 's new with you ?", "speaker": "E"}, {"text": "so there 's nothing new .", "speaker": "B"}, {"text": "what 's old with you that 's developed ?", "speaker": "E"}, {"text": "what 's old with you that has developed over the last week or two ?", "speaker": "E"}, {"text": "so we 've been mainly working on the report", "speaker": "B"}, {"text": "mainly working on what ?", "speaker": "F"}, {"text": "on the report of the work that was already done .", "speaker": "B"}, {"text": "that 's all .", "speaker": "B"}, {"text": "how about that ?", "speaker": "F"}, {"text": "any - anything new on the thing that , , you were working on with the , ?", "speaker": "F"}, {"text": "don't have results yet .", "speaker": "C"}, {"text": "what was that ?", "speaker": "E"}, {"text": "what 's what 's going on now ?", "speaker": "E"}, {"text": "what are you doing ?", "speaker": "E"}, {"text": "to try to found , nnn , robust feature for detect between voice and unvoice .", "speaker": "C"}, {"text": "and we we try to use the variance of the es difference between the fft spectrum and mel filter bank spectrum .", "speaker": "C"}, {"text": "also the another parameter is relates with the auto - correlation function .", "speaker": "C"}, {"text": "- ze energy and the variance also of the auto - correlation function .", "speaker": "C"}, {"text": "so , that 's", "speaker": "E"}, {"text": "that 's what you were describing , , week or two ago .", "speaker": "E"}, {"text": "but we don't have res we don't have result of the auro for aurora yet .", "speaker": "C"}, {"text": "we need to train the neural network", "speaker": "C"}, {"text": "so you 're training neural networks now ?", "speaker": "E"}, {"text": "so , what wha wh wha what 's going on ?", "speaker": "E"}, {"text": "we work in the report , too ,", "speaker": "C"}, {"text": "because we have lot of result ,", "speaker": "C"}, {"text": "they are very dispersed ,", "speaker": "C"}, {"text": "and was necessary to look in all the directory to to give some more structure .", "speaker": "C"}, {"text": "if summarize , what 's going on is that you 're going over lot of material that you have generated in furious fashion ,", "speaker": "E"}, {"text": "generating many results and doing many experiments", "speaker": "E"}, {"text": "and trying to pull it together into some coherent form to be able to see wha see what happens .", "speaker": "E"}, {"text": "we 've stopped , , experimenting ,", "speaker": "B"}, {"text": "we 're just writing some technical report .", "speaker": "B"}, {"text": "is this report that 's for aurora ?", "speaker": "F"}, {"text": "or is it just like tech report for icsi ,", "speaker": "F"}, {"text": "just summary of the experiment and the conclusion", "speaker": "C"}, {"text": "something like that .", "speaker": "C"}, {"text": "so , my suggestion , though , is that you not necessarily finish that .", "speaker": "E"}, {"text": "but that you put it all together so that it 's you 've got clearer structure to it .", "speaker": "E"}, {"text": "what things are ,", "speaker": "E"}, {"text": "you have things documented ,", "speaker": "E"}, {"text": "you 've looked things up that you needed to look up .", "speaker": "E"}, {"text": "so that , so that such thing can be written .", "speaker": "E"}, {"text": "when when do you leave again ?", "speaker": "E"}, {"text": "first of july .", "speaker": "C"}, {"text": "first of july ?", "speaker": "E"}, {"text": "and that you figure on actually finishing it in june .", "speaker": "E"}, {"text": "because , , you 're gonna have another bunch of results to fit in there anyway .", "speaker": "E"}, {"text": "and now it 's important that we actually go forward with experiments .", "speaker": "E"}, {"text": "it 's not .", "speaker": "C"}, {"text": "so so , it 's good to pause , and to gather everything together and make it 's in good shape ,", "speaker": "E"}, {"text": "so that other people can get access to it", "speaker": "E"}, {"text": "and so that it can go into report in june .", "speaker": "E"}, {"text": "but to really work on fine - tuning the report at this point is probably bad timing , .", "speaker": "E"}, {"text": "we just planned to work on it one week on this report ,", "speaker": "B"}, {"text": "not no more , anyway .", "speaker": "B"}, {"text": "but you ma you may really wanna add other things later anyway", "speaker": "E"}, {"text": "there 's more to go ?", "speaker": "E"}, {"text": "so . there are small things that we started to do .", "speaker": "B"}, {"text": "are you discovering anything , , that makes you scratch your head as you write this report ,", "speaker": "F"}, {"text": "like why did we do that ,", "speaker": "F"}, {"text": "or why didn't we do this ,", "speaker": "F"}, {"text": "actually , there were some tables that were also with partial results .", "speaker": "B"}, {"text": "we just noticed that ,", "speaker": "B"}, {"text": "wh while gathering the result that for some conditions we didn't have everything .", "speaker": "B"}, {"text": "we have , , extracted actually the noises from the speechdat - car .", "speaker": "B"}, {"text": "we can train neural network with speech and these noises .", "speaker": "B"}, {"text": "it 's difficult to say what it will give ,", "speaker": "B"}, {"text": "because when we look at the aurora the ti - digits experiments , , they have these three conditions that have different noises ,", "speaker": "B"}, {"text": "and this system perform as on the seen noises on the unseen noises and on the seen noises .", "speaker": "B"}, {"text": "this is something we have to try anyway .", "speaker": "B"}, {"text": "adding the noises from the speechdat - car .", "speaker": "B"}, {"text": "that 's permitted ?", "speaker": "E"}, {"text": "ogi does did that .", "speaker": "B"}, {"text": "at some point they did that for the voice activity detector .", "speaker": "B"}, {"text": "could you say it again ?", "speaker": "F"}, {"text": "what what exactly did they do ?", "speaker": "F"}, {"text": "they used some parts of the , , italian database to train the voice activity detector , .", "speaker": "B"}, {"text": "that 's matter of interpretation .", "speaker": "E"}, {"text": "the rules as understand it , is that in principle the italian and the spanish and the english", "speaker": "E"}, {"text": "italian and the finnish and the english ? were development data", "speaker": "E"}, {"text": "and spanish , .", "speaker": "B"}, {"text": "on which you could adjust things .", "speaker": "E"}, {"text": "and the and the german and danish were the evaluation data .", "speaker": "E"}, {"text": "and then when they finally actually evaluated things they used everything .", "speaker": "E"}, {"text": "and it is true that the performance , , on the german was", "speaker": "E"}, {"text": "even though the improvement wasn't so good , the pre the raw performance was really pretty good .", "speaker": "E"}, {"text": "it doesn't appear that there 's strong evidence that even though things were somewhat tuned on those three or four languages , that going to different language really hurt you .", "speaker": "E"}, {"text": "and the noises were not exactly the same .", "speaker": "E"}, {"text": "because it was taken from different ,", "speaker": "E"}, {"text": "they were different drives .", "speaker": "E"}, {"text": "it was it was actual different cars and so on .", "speaker": "E"}, {"text": "it 's somewhat tuned .", "speaker": "E"}, {"text": "it 's tuned more than , ,", "speaker": "E"}, {"text": "you 'd really like to have something that needed no particular noise ,", "speaker": "E"}, {"text": "just some white noise like that at most .", "speaker": "E"}, {"text": "but that 's not really what this contest is .", "speaker": "E"}, {"text": "that 's something 'd like to understand before we actually use something from it ,", "speaker": "E"}, {"text": "it 's probably something that , mmm , the , the , , experiment designers didn't really think about ,", "speaker": "F"}, {"text": "because most people aren't doing trained systems , or , , , systems that are like ours , where you actually use the data to build models .", "speaker": "F"}, {"text": "they just doing signal - processing .", "speaker": "F"}, {"text": "it 's true ,", "speaker": "E"}, {"text": "except that , , that 's what we used in aurora one ,", "speaker": "E"}, {"text": "and then they designed the things for aurora - two knowing that we were doing that .", "speaker": "E"}, {"text": "that 's true .", "speaker": "F"}, {"text": "and they didn't forbid us", "speaker": "F"}, {"text": "to build models on the data ?", "speaker": "F"}, {"text": "but , that it", "speaker": "E"}, {"text": "it probably would be the case that if , say , we trained on italian , , data and then , , we tested on danish data and it did terribly , , that it would look bad .", "speaker": "E"}, {"text": "and someone would notice", "speaker": "E"}, {"text": "and would say \" , look . this is not generalizing . \"", "speaker": "E"}, {"text": "would hope tha would hope they would .", "speaker": "E"}, {"text": "it 's true .", "speaker": "E"}, {"text": "there 's parameters that other people have used", "speaker": "E"}, {"text": "that they have tuned in some way for other things .", "speaker": "E"}, {"text": "so it 's it 's ,", "speaker": "E"}, {"text": "we should we should", "speaker": "E"}, {"text": "especially if you talk with him when 'm not here ,", "speaker": "E"}, {"text": "that 's topic you should discuss with hynek", "speaker": "E"}, {"text": "to , , double check it 's .", "speaker": "E"}, {"text": "do we know anything about the speakers for each of the , , training utterances ?", "speaker": "F"}, {"text": "what do you mean ?", "speaker": "B"}, {"text": "do you have speaker information ?", "speaker": "F"}, {"text": "that would be good .", "speaker": "F"}, {"text": "like , we have male , female ,", "speaker": "B"}, {"text": "just male female ?", "speaker": "F"}, {"text": "what information do you mean ?", "speaker": "E"}, {"text": "was thinking about things like , , gender , , gender - specific nets and , , vocal tract length normalization .", "speaker": "F"}, {"text": "things like that .", "speaker": "F"}, {"text": "don't didn't information we have about the speakers that we could try to take advantage of .", "speaker": "F"}, {"text": "again , if you had the whole system you were optimizing , that would be easy to see .", "speaker": "E"}, {"text": "but if you 're supposedly just using fixed back - end and you 're just coming up with feature vector , 'm not", "speaker": "E"}, {"text": "having the two nets suppose you detected that it was male , it was female you come up with different", "speaker": "E"}, {"text": "you could put them both in as separate streams .", "speaker": "F"}, {"text": "was just wondering if there was other information we could exploit .", "speaker": "F"}, {"text": "it 's an interesting thought .", "speaker": "E"}, {"text": "having something along the", "speaker": "E"}, {"text": "you can't really do vocal tract normalization .", "speaker": "E"}, {"text": "but something that had some of that effect", "speaker": "E"}, {"text": "being applied to the data in some way .", "speaker": "E"}, {"text": "do you have something simple in mind for , vocal tract length normalization ?", "speaker": "B"}, {"text": "no . hadn't hadn't thought it was thought too much about it , really .", "speaker": "F"}, {"text": "it just something that popped into my head just now .", "speaker": "F"}, {"text": "you could use the ideas similar idea to what they do in vocal tract length normalization .", "speaker": "F"}, {"text": "you have some , , general speech model ,", "speaker": "F"}, {"text": "just mixture of gaussians that you evaluate every utterance against ,", "speaker": "F"}, {"text": "and then you see where each , , utterance like , the likelihood of each utterance . you divide the range of the likelihoods up into discrete bins", "speaker": "F"}, {"text": "and then each bin 's got some knob , setting .", "speaker": "F"}, {"text": "but just listen to yourself .", "speaker": "E"}, {"text": "that really doesn't sound like real - time thing with less than two hundred milliseconds , , latency that and where you 're not adjusting the statistical engine .", "speaker": "E"}, {"text": "that 's true .", "speaker": "F"}, {"text": "could be expensive .", "speaker": "F"}, {"text": "not just expensive .", "speaker": "E"}, {"text": "don't see how you could possibly do it .", "speaker": "E"}, {"text": "you can't look at the whole utterance and do anything . , you can only", "speaker": "E"}, {"text": "each frame comes in and it 's gotta go out the other end .", "speaker": "E"}, {"text": "so whatever it was , it would have to be on per frame basis .", "speaker": "F"}, {"text": "you can do ,", "speaker": "E"}, {"text": "fairly quickly you can do male female male female .", "speaker": "E"}, {"text": "but as far as ,", "speaker": "E"}, {"text": "like bbn did thing with , , vocal tract normalization ways back .", "speaker": "E"}, {"text": "other people did too .", "speaker": "E"}, {"text": "with with , , trying to identify third formant average third formant using that as an indicator of", "speaker": "E"}, {"text": "if you imagine that to first order what happens with , , changing vocal tract is that , , the formants get moved out by some proportion", "speaker": "E"}, {"text": "so , if you had first formant that was one hundred hertz before , if the fifty if the vocal tract is fifty percent shorter , then it would be out at seven fifty hertz ,", "speaker": "E"}, {"text": "and so on .", "speaker": "E"}, {"text": "so , that 's move of two hundred fifty hertz .", "speaker": "E"}, {"text": "whereas the third formant which might have started off at twenty - five hundred hertz , , might be out to thirty - seven fifty ,", "speaker": "E"}, {"text": "so it 's at", "speaker": "E"}, {"text": "although , you frequently get less distinct higher formants , it 's still third formant 's reasonable compromise ,", "speaker": "E"}, {"text": "so , , , if recall correctly , they did something like that .", "speaker": "E"}, {"text": "but , that doesn't work for just having one frame .", "speaker": "E"}, {"text": "? that 's more like looking at third formant over turn like that ,", "speaker": "E"}, {"text": "but on the other hand , male female is is much simpler categorization than figuring out factor to , , squish or expand the spectrum .", "speaker": "E"}, {"text": "you could imagine that", "speaker": "E"}, {"text": "just like we 're saying voiced - unvoiced is good to know", "speaker": "E"}, {"text": "male female is good to know also .", "speaker": "E"}, {"text": "but , you 'd have to figure out way to to , , incorporate it on the fly .", "speaker": "E"}, {"text": ", , as you say , one thing you could do is simply , , have the male and female output vectors , tr nets trained only on males and trained only on females", "speaker": "E"}, {"text": "if that would really help ,", "speaker": "E"}, {"text": "because you already have males and females", "speaker": "E"}, {"text": "and it 's - putting into one net .", "speaker": "E"}, {"text": "is it balanced ,", "speaker": "F"}, {"text": "in terms of gender", "speaker": "F"}, {"text": "you 're you were saying before ?", "speaker": "E"}, {"text": "so , this noise ,", "speaker": "B"}, {"text": "there is something perhaps , could spend some days to look at this thing ,", "speaker": "B"}, {"text": "cuz it seems that when we train networks on let 's say , on timit with msg features , they look as good as networks trained on plp .", "speaker": "B"}, {"text": "when they are used on the speechdat - car data , it 's not the case", "speaker": "B"}, {"text": "the msg features are much worse ,", "speaker": "B"}, {"text": "and so they 're , , less more sensitive to different recording conditions ,", "speaker": "B"}, {"text": "they should be less so .", "speaker": "E"}, {"text": "but let me ask you this .", "speaker": "E"}, {"text": "what what 's the , ?", "speaker": "E"}, {"text": "do you kno recall if the insertions were higher with msg ?", "speaker": "E"}, {"text": "the error rate is higher .", "speaker": "B"}, {"text": "but you should always look at insertions , deletions , and substitutions .", "speaker": "E"}, {"text": "msg is very , very dif", "speaker": "E"}, {"text": "plp is very much like mel cepstrum .", "speaker": "E"}, {"text": "msg is very different from both of them .", "speaker": "E"}, {"text": "so , if it 's very different , then this is the thing", "speaker": "E"}, {"text": "'m really glad andreas brought this point up .", "speaker": "E"}, {"text": "had forgotten to discuss it .", "speaker": "E"}, {"text": "you always have to look at how this , these adjustments , , affect things .", "speaker": "E"}, {"text": "and even though we 're not allowed to do that , again we could reflect that back to our use of the features .", "speaker": "E"}, {"text": "so if it if ,", "speaker": "E"}, {"text": "the problem might be that the range of the msg features is quite different than the range of the plp or mel cepstrum .", "speaker": "E"}, {"text": "and you might wanna change that .", "speaker": "E"}, {"text": "but , it 's it 's after", "speaker": "B"}, {"text": "it 's tandem features ,", "speaker": "B"}, {"text": "we we have estimation of post posteriors with plp and with msg as input ,", "speaker": "B"}, {"text": "that means they 're between zero and one .", "speaker": "E"}, {"text": "but it it doesn't necessarily", "speaker": "E"}, {"text": "they could be ,", "speaker": "E"}, {"text": "do - doesn't tell you what the variance of the things is .", "speaker": "E"}, {"text": "cuz if you 're taking the log of these things , it could be ,", "speaker": "E"}, {"text": "knowing what the sum of the probabilities are , doesn't tell you what the sum of the logs are .", "speaker": "E"}, {"text": "so we should look at the likelihood ,", "speaker": "B"}, {"text": "at the log , perhaps ,", "speaker": "B"}, {"text": "or what , what you 're the thing you 're actually looking at .", "speaker": "E"}, {"text": "the values that are actually being fed into htk .", "speaker": "E"}, {"text": "what do they look like ?", "speaker": "E"}, {"text": "and so the , for the tandem system , the values that come out of the net don't go through the sigmoid .", "speaker": "F"}, {"text": "they 're the pre - nonlinearity values ?", "speaker": "F"}, {"text": "so they 're kinda like log probabilities is what was saying .", "speaker": "E"}, {"text": "and tho that 's what goes into htk ?", "speaker": "F"}, {"text": "but then you actually do klt on them .", "speaker": "E"}, {"text": "they aren't normalized after that ,", "speaker": "E"}, {"text": "mmm . no ,", "speaker": "B"}, {"text": "so the question is . whatever they are at that point , , are they something for which taking square root or cube root or fourth root like that is gonna be good or bad thing ?", "speaker": "E"}, {"text": "and that 's something that", "speaker": "E"}, {"text": "nothing else after that is gonna", "speaker": "E"}, {"text": "things are gonna scale it", "speaker": "E"}, {"text": ", subtract things from it ,", "speaker": "E"}, {"text": "scale it from it ,", "speaker": "E"}, {"text": "but nothing will have that same effect .", "speaker": "E"}, {"text": "cuz if the log probs that are coming out of the msg are really big , the standard insertion penalty is gonna have very little effect", "speaker": "F"}, {"text": "compared to , , smaller set of log probs .", "speaker": "F"}, {"text": "no . again you don't really look at that .", "speaker": "E"}, {"text": "it 's something that ,", "speaker": "E"}, {"text": "and then it 's going through this transformation that 's probably pretty close to", "speaker": "E"}, {"text": "it 's , , whatever the klt is doing .", "speaker": "E"}, {"text": "but it 's probably pretty close to what discrete cosine transformation is doing .", "speaker": "E"}, {"text": "but still it 's it 's not gonna probably radically change the scale of things .", "speaker": "E"}, {"text": "it may be entirely off", "speaker": "E"}, {"text": "and it may be at the very least it may be quite different for msg than it is for mel cepstrum or plp .", "speaker": "E"}, {"text": "so that would be", "speaker": "E"}, {"text": "so the first thing 'd look at without adjusting anything would just be to go back to the experiment and look at the , , substitutions , insertions , and deletions .", "speaker": "E"}, {"text": "and if the if", "speaker": "E"}, {"text": "if there 's fairly large effect of the difference , say , , the ratio between insertions and deletions for the two cases then that would be , , an indicator that it might be in that direction .", "speaker": "E"}, {"text": "my point was more that it works sometimes", "speaker": "B"}, {"text": "but sometimes it doesn't work .", "speaker": "B"}, {"text": "and it works on ti - digits", "speaker": "B"}, {"text": "and on speechdat - car it doesn't work ,", "speaker": "B"}, {"text": "but , , some problems are harder than others ,", "speaker": "E"}, {"text": "and , , sometimes , , there 's enough evidence to work", "speaker": "E"}, {"text": "and then it 's harder ,", "speaker": "E"}, {"text": "but it but , , it could be that when you say it works we could be doing much better ,", "speaker": "E"}, {"text": "even in ti - digits .", "speaker": "E"}, {"text": "there is also the spectral subtraction ,", "speaker": "B"}, {"text": "we should , , try to integrate it in our system .", "speaker": "B"}, {"text": "that would involve to mmm use big al already big bunch of the system of ericsson .", "speaker": "B"}, {"text": "because he has spectral subtraction ,", "speaker": "B"}, {"text": "then it 's followed by , , other processing that 's are dependent on the , if it 's speech or noi or silence .", "speaker": "B"}, {"text": "and there is this spectral flattening after if it 's silence ,", "speaker": "B"}, {"text": "and it 's important , , to reduce this musical noise and this increase of variance during silence portions .", "speaker": "B"}, {"text": "this was in this would involve to take almost everything from the this proposal", "speaker": "B"}, {"text": "and then just add some on - line normalization in the neural network .", "speaker": "B"}, {"text": "this 'll be , , something for discussion with hynek next week .", "speaker": "E"}, {"text": "how are , how are things going with what you 're doing ?", "speaker": "E"}, {"text": "took lot of time just getting my taxes out of the way", "speaker": "D"}, {"text": "multi - national taxes .", "speaker": "D"}, {"text": "so , 'm 'm starting to write code now for my work", "speaker": "D"}, {"text": "but don't have any results yet .", "speaker": "D"}, {"text": "it would be good for me to talk to hynek , , when he 's here .", "speaker": "D"}, {"text": "do what his schedule will be like ?", "speaker": "D"}, {"text": "he 'll be around for three days .", "speaker": "E"}, {"text": "we 'll have lot of time .", "speaker": "E"}, {"text": "he 'll be talking with everybody in this room", "speaker": "E"}, {"text": "but you said you won't you won't be here next thursday ?", "speaker": "F"}, {"text": "not thursday and friday .", "speaker": "E"}, {"text": "cuz will be at faculty retreat .", "speaker": "E"}, {"text": "'ll try to connect with him and people as on wednesday .", "speaker": "E"}, {"text": "how 'd taxes go ?", "speaker": "E"}, {"text": ", good . .", "speaker": "E"}, {"text": "that 's just that 's one of the big advantages of not making much money is the taxes are easier .", "speaker": "E"}, {"text": "unless you 're getting money in two countries .", "speaker": "F"}, {"text": "they both want their cut .", "speaker": "F"}, {"text": "canada canada wants cut ?", "speaker": "E"}, {"text": "have to do so you have to do two returns ?", "speaker": "E"}, {"text": "mmm . , for two thousand did .", "speaker": "D"}, {"text": "but not for this next year ?", "speaker": "F"}, {"text": "probably not this next year , .", "speaker": "E"}, {"text": "'ll 'll still have bit of canadian income", "speaker": "D"}, {"text": "but it 'll be less complicated", "speaker": "D"}, {"text": "because will not be considered resident of canada anymore ,", "speaker": "D"}, {"text": "so won't have to declare my american income on my canadian return .", "speaker": "D"}, {"text": "do you wanna say something about your here ?", "speaker": "E"}, {"text": ", continuing looking at , , ph , phonetic events ,", "speaker": "A"}, {"text": "and , , this tuesday gonna be , , meeting with john ohala with chuck to talk some more about these , , ph , phonetic events .", "speaker": "A"}, {"text": "came up with , , plan of attack ,", "speaker": "A"}, {"text": "it 's that 's it .", "speaker": "A"}, {"text": "why don't you say something about what it is ?", "speaker": "E"}, {"text": "you , you want you want details .", "speaker": "A"}, {"text": "we 're all gathered here together .", "speaker": "E"}, {"text": "was hoping could wave my hands .", "speaker": "A"}, {"text": "so , once wa", "speaker": "A"}, {"text": "was thinking getting us set of acoustic events to , to be able to distinguish between , , phones and words and .", "speaker": "A"}, {"text": "we would figure out set of these events that can be , , , hand - labeled or derived , , from the hand - labeled phone targets .", "speaker": "A"}, {"text": "we could take these events and , , do some cheating experiments ,", "speaker": "A"}, {"text": "where we feed , , these events into an sri system , , , and evaluate its performance on switchboard task .", "speaker": "A"}, {"text": "can you give an example of an event ?", "speaker": "D"}, {"text": "give you an example of twenty - odd events .", "speaker": "A"}, {"text": "so , he in this paper , , it 's talking about phoneme recognition using acoustic events .", "speaker": "A"}, {"text": "so , things like frication or , , nasality .", "speaker": "A"}, {"text": "whose paper is it ?", "speaker": "E"}, {"text": "this is paper by hubener and cardson benson bernds - berndsen .", "speaker": "A"}, {"text": "from , , university of hamburg and bielefeld .", "speaker": "E"}, {"text": "just to expand little bit on the idea of acoustic event .", "speaker": "F"}, {"text": "there 's , in my mind , anyways , there 's difference between , , acoustic features and acoustic events .", "speaker": "F"}, {"text": "and of acoustic features as being , , things that linguists talk about ,", "speaker": "F"}, {"text": "so , that 's not based on data .", "speaker": "E"}, {"text": "that 's not based on data , necessarily .", "speaker": "F"}, {"text": "that 's not based on , , acoustic data .", "speaker": "F"}, {"text": "so they talk about features for phones ,", "speaker": "F"}, {"text": "like , , its height ,", "speaker": "F"}, {"text": "things like that ,", "speaker": "F"}, {"text": "which may or may not be all that easy to measure in the acoustic signal .", "speaker": "F"}, {"text": "versus an acoustic event , which is just {nonvocalsound} some {nonvocalsound} something in the acoustic signal {nonvocalsound} that is fairly easy to measure .", "speaker": "F"}, {"text": "so it 's , it 's little different ,", "speaker": "F"}, {"text": "in at least in my mind .", "speaker": "F"}, {"text": "when we did the spam work , there we had we had this notion of an , , auditory @ @ auditory event .", "speaker": "E"}, {"text": "good . that 's .", "speaker": "A"}, {"text": "called them \" avents \" ,", "speaker": "E"}, {"text": ", with an at the front .", "speaker": "E"}, {"text": "and the the idea was something that occurred that is important to bunch of neurons somewhere .", "speaker": "E"}, {"text": "sudden change or relatively rapid change in some spectral characteristic will do this .", "speaker": "E"}, {"text": "there 's certainly bunch of bunch of places where that neurons are gonna fire because something novel has happened .", "speaker": "E"}, {"text": "that was that was the main thing that we were focusing on there .", "speaker": "E"}, {"text": "but there 's certainly other things beyond what we talked about there that aren't just rapid changes ,", "speaker": "E"}, {"text": "it 's kinda like the difference between top - down and bottom - up .", "speaker": "F"}, {"text": "of the acoustic , phonetic features as being top - down .", "speaker": "F"}, {"text": "you look at the phone", "speaker": "F"}, {"text": "and you say this phone is supposed to be , have this feature , and this feature .", "speaker": "F"}, {"text": "whether tha those features show up in the acoustic signal is irrelevant .", "speaker": "F"}, {"text": "whereas , an acoustic event goes the other way .", "speaker": "F"}, {"text": "here 's the signal .", "speaker": "F"}, {"text": "here 's some event .", "speaker": "F"}, {"text": "and then that , that may map to this phone sometimes ,", "speaker": "F"}, {"text": "and sometimes it may not .", "speaker": "F"}, {"text": "it just depen depends on the context ,", "speaker": "F"}, {"text": "things like that .", "speaker": "F"}, {"text": "and so it 's different way of looking .", "speaker": "F"}, {"text": "using these events , , , we can we can perform these , , cheating experiments .", "speaker": "A"}, {"text": "see how how good they are , , in , in terms of phoneme recognition or word recognition .", "speaker": "A"}, {"text": "and then from that point on , would , , design robust event detectors , , in similar , , wa spirit that saul has done , with his graphical models , and this probabilistic and - or model that he uses .", "speaker": "A"}, {"text": "try to extend it to , to account for other phenomena like , , cmr co - modulation release .", "speaker": "A"}, {"text": "and also investigate ways to modify the structure of these models , , in data - driven way ,", "speaker": "A"}, {"text": "similar to the way that , , jeff , , bilmes did his work .", "speaker": "A"}, {"text": "and while 'm 'm doing these , , event detectors , , ma mea measure my progress by comparing , , the error rates in clean and noisy conditions to something like , , neural nets .", "speaker": "A"}, {"text": "so , once we have these , , event detectors , , we could put them together and feed the outputs of the event detectors into the sri , , system ,", "speaker": "A"}, {"text": "and test it on switchboard or , , even aurora .", "speaker": "A"}, {"text": "that 's the big picture of , the plan .", "speaker": "A"}, {"text": "there 's , , couple people who are gonna be here", "speaker": "E"}, {"text": "forget if already told you this ,", "speaker": "E"}, {"text": "but , couple people who are gonna be here for six months .", "speaker": "E"}, {"text": "there 's professor kollmeier , , from germany", "speaker": "E"}, {"text": "who 's , , quite big in the , , hearing - aid signal - processing area", "speaker": "E"}, {"text": "and , , michael kleinschmidt , who 's worked with him ,", "speaker": "E"}, {"text": "who also looks at auditory properties inspired by various , , brain function things .", "speaker": "E"}, {"text": "they 'll be interesting to talk to , in this issue", "speaker": "E"}, {"text": "as these detectors are , , developing .", "speaker": "E"}, {"text": "so , he looks at interesting things in the different ways of looking at spectra in order to get various speech properties out .", "speaker": "E"}, {"text": "but that 's .", "speaker": "E"}, {"text": "we might as do our digits .", "speaker": "E"}, {"text": "and like say , encourage you to go ahead and meet , , next week with , , hynek .", "speaker": "E"}, {"text": "'ll 'll start .", "speaker": "E"}, {"text": "it 's , , one thirty - five .", "speaker": "E"}], "id": "xxxxx", "relations": [{"y": 1, "x": 0, "type": "Explanation"}]}]