[{"edus": [{"text": "somebody else should run this .", "speaker": "B"}, {"text": "'m sick of being the one to go through and say , \" , what do you think about this ? \"", "speaker": "B"}, {"text": "should we take turns ?", "speaker": "F"}, {"text": "you want me to run it today ?", "speaker": "F"}, {"text": "why don't you run it today ?", "speaker": "B"}, {"text": "let 's see , we should just get list of items", "speaker": "F"}, {"text": "things that we should talk about .", "speaker": "F"}, {"text": "there 's the usual updates ,", "speaker": "F"}, {"text": "everybody going around and saying , , , what they 're working on ,", "speaker": "F"}, {"text": "the things that happened the last week .", "speaker": "F"}, {"text": "but aside from that is there anything in particular that anybody wants to bring up", "speaker": "F"}, {"text": "so why don't we just around and people can give updates .", "speaker": "F"}, {"text": "do you want to start , stephane ?", "speaker": "F"}, {"text": "the first thing is that the eurospeech paper is , , accepted .", "speaker": "C"}, {"text": "this is what do you , what 's in the paper there ?", "speaker": "F"}, {"text": "so it 's the paper that describe the , , system that were proposed for the aurora .", "speaker": "C"}, {"text": "the one that we we submitted the last round ?", "speaker": "F"}, {"text": "so and the , fff comments seems from the reviewer are good .", "speaker": "C"}, {"text": "where where 's it gonna be this year ?", "speaker": "F"}, {"text": "it 's , , aalborg in denmark .", "speaker": "C"}, {"text": "and it 's ,", "speaker": "C"}, {"text": "then , , whhh", "speaker": "C"}, {"text": "'ve been working on mainly on - line normalization this week .", "speaker": "C"}, {"text": "'ve been trying different slightly different approaches .", "speaker": "C"}, {"text": "the first thing is trying to play little bit again with the , , time constant .", "speaker": "C"}, {"text": "second thing is , , the training of , , on - line normalization with two different means ,", "speaker": "C"}, {"text": "one mean for the silence and one for the speech .", "speaker": "C"}, {"text": "and so have two recursions which are controlled by the , , probability of the voice activity detector .", "speaker": "C"}, {"text": "this actually don't doesn't seem to help ,", "speaker": "C"}, {"text": "although it doesn't hurt .", "speaker": "C"}, {"text": "but , both on - line normalization approach seems equivalent .", "speaker": "C"}, {"text": "are the means pretty different for the two ?", "speaker": "F"}, {"text": "they can be very different .", "speaker": "C"}, {"text": "so do you make errors in different places ?", "speaker": "B"}, {"text": "different kinds of errors ?", "speaker": "B"}, {"text": "didn't look , , more closely .", "speaker": "C"}, {"text": "it might be , .", "speaker": "C"}, {"text": ", there is one thing that we can observe , is that the mean are more different for - zero and - one than for the other coefficients .", "speaker": "C"}, {"text": "and , it the - one is", "speaker": "C"}, {"text": "there are strange thing happening with - one , is that when you have different noises , the mean for the silence portion is can be different .", "speaker": "C"}, {"text": "so when you look at the trajectory of - one , it 's has strange shape", "speaker": "C"}, {"text": "was expecting the that these two mean helps ,", "speaker": "C"}, {"text": "especially because of the strange - ze - one shape ,", "speaker": "C"}, {"text": "which can like , yo you can have , , trajectory for the speech", "speaker": "C"}, {"text": "and then when you are in the silence it goes somewhere ,", "speaker": "C"}, {"text": "but if the noise is different it goes somewhere else .", "speaker": "C"}, {"text": "so which would mean that if we estimate the mean based on all the signal , even though we have frame dropping , but we don't frame ev , drop everything ,", "speaker": "C"}, {"text": "but , this can hurts the estimation of the mean for speech ,", "speaker": "C"}, {"text": "mmm . but still have to investigate further , .", "speaker": "C"}, {"text": "third thing is , , that instead of having fixed time constant , try to have time constant that 's smaller at the beginning of the utterances", "speaker": "C"}, {"text": "to adapt more quickly to the something that 's closer to the mean .", "speaker": "C"}, {"text": "and then this time constant increases", "speaker": "C"}, {"text": "and have threshold that", "speaker": "C"}, {"text": "if it 's higher than certain threshold , keep it to this threshold to still , , adapt , , the mean when if the utterance is , , long enough to continue to adapt after , like , one second", "speaker": "C"}, {"text": ", this doesn't help neither ,", "speaker": "C"}, {"text": "but this doesn't hurt .", "speaker": "C"}, {"text": "wasn't there some experiment you were gonna try", "speaker": "F"}, {"text": "where you did something differently for each , , whether it was each mel band or each , , , fft bin or someth", "speaker": "F"}, {"text": "there was something you were gonna , some parameter you were gonna vary depending on the frequency .", "speaker": "F"}, {"text": "it 's this idea of having different on - line normalization , , tunings for the different mfcc 's .", "speaker": "C"}, {"text": "morgan , you brought it up couple meetings ago .", "speaker": "F"}, {"text": "and then it was something about , , some", "speaker": "F"}, {"text": "and then somebody said \" , it does seem like , , - zero is the one that 's , , the major one \" or , ,", "speaker": "F"}, {"text": "'t remember exactly what it was now .", "speaker": "F"}, {"text": "it 's very important to normalize - zero", "speaker": "C"}, {"text": "and much less to normalize the other coefficients .", "speaker": "C"}, {"text": ", at least with the current on - line normalization scheme .", "speaker": "C"}, {"text": "we , we know that normalizing - one doesn't help with the current scheme .", "speaker": "C"}, {"text": "in my idea , was thinking that the the reason is because of these funny things that happen between speech and silence which have different means .", "speaker": "C"}, {"text": "but it 's not so easy to", "speaker": "C"}, {"text": "really would like to suggest looking , , little bit at the kinds of errors .", "speaker": "B"}, {"text": "know you can get lost in that and go forever and not see too much , but sometimes ,", "speaker": "B"}, {"text": "just seeing that each of these things didn't make things better may not be enough .", "speaker": "B"}, {"text": "it may be that they 're making them better in some ways and worse in others ,", "speaker": "B"}, {"text": "or increasing insertions and decreasing deletions ,", "speaker": "B"}, {"text": "helping with noisy case", "speaker": "B"}, {"text": "but hurting in quiet case .", "speaker": "B"}, {"text": "and if you saw that then you it would something would occur to you of how to deal with that .", "speaker": "B"}, {"text": "so that 's it , , for the on - line normalization .", "speaker": "C"}, {"text": "'ve been playing little bit with some thresholding ,", "speaker": "C"}, {"text": "as first experiment ,", "speaker": "C"}, {"text": "what did is is to take , to measure the average", "speaker": "C"}, {"text": "no , the maximum energy of each utterance", "speaker": "C"}, {"text": "and then put threshold", "speaker": "C"}, {"text": "this for each mel band .", "speaker": "C"}, {"text": "then put threshold that 's fifteen db below", "speaker": "C"}, {"text": ", couple of db below this maximum ,", "speaker": "C"}, {"text": "actually it was not threshold ,", "speaker": "C"}, {"text": "it was just adding noise .", "speaker": "C"}, {"text": "so was adding white noise energy ,", "speaker": "C"}, {"text": "that 's fifteen db below the maximum energy of the utterance .", "speaker": "C"}, {"text": "when we look at the , , mfcc that result from this , they are lot more smoother .", "speaker": "C"}, {"text": "when we compare , like , channel zero and channel one utterance", "speaker": "C"}, {"text": "so clean and , , the same noisy utterance", "speaker": "C"}, {"text": "there is almost no difference between the cepstral coefficients of the two .", "speaker": "C"}, {"text": "and the result that we have in term of speech recognition , actually it 's not it 's not worse ,", "speaker": "C"}, {"text": "it 's not better neither ,", "speaker": "C"}, {"text": "but it 's , , surprising that it 's not worse", "speaker": "C"}, {"text": "because you add noise that 's fifteen db just fifteen db below the maximum energy .", "speaker": "C"}, {"text": "so why does that smooth things out ?", "speaker": "F"}, {"text": "don't don't understand that .", "speaker": "F"}, {"text": "there 's less difference . ?", "speaker": "B"}, {"text": "it 's , it 's whitening this the portion that are more silent ,", "speaker": "C"}, {"text": "as you add white noise that are has very high energy , it whitens everything", "speaker": "C"}, {"text": "and the high - energy portion of the speech don't get much affected anyway by the other noise .", "speaker": "C"}, {"text": "and as the noise you add is the same is the shape , it 's also the same .", "speaker": "C"}, {"text": "so they have the trajectory are very , very similar .", "speaker": "C"}, {"text": "so , , again , if you trained in one noise and tested in the same noise , you 'd , given enough training data you don't do do badly .", "speaker": "B"}, {"text": "the reason that we that we have the problems we have is because it 's different in training and test .", "speaker": "B"}, {"text": "even if the general kind is the same , the exact instances are different .", "speaker": "B"}, {"text": "so when you whiten it , then it 's like you the only noise to first order , the only noise that you have is white noise", "speaker": "B"}, {"text": "and you 've added the same thing to training and test .", "speaker": "B"}, {"text": "so it 's ,", "speaker": "B"}, {"text": "so would that be similar to , like , doing the smoothing , then , over time", "speaker": "F"}, {"text": "it 's smoothing ,", "speaker": "B"}, {"text": "it 's it 's different .", "speaker": "C"}, {"text": "it 's it 's something that , that affects more or less the silence portions", "speaker": "C"}, {"text": "anyway , the sp the portion of speech that ha have high energy are not ch lot affected by the noises in the aurora database .", "speaker": "C"}, {"text": "if if you compare the two shut channels of speechdat - car during speech portion , it 's the mfcc are not very different .", "speaker": "C"}, {"text": "they are very different when energy 's lower ,", "speaker": "C"}, {"text": "like during fricatives or during speech pauses .", "speaker": "C"}, {"text": "but you 're still getting more recognition errors ,", "speaker": "B"}, {"text": "which means that the differences , even though they look like they 're not so big , are hurting your recognition .", "speaker": "B"}, {"text": "so it distort the speech .", "speaker": "C"}, {"text": "so performance went down ?", "speaker": "F"}, {"text": "so , but in this case really expect that the two these two stream of features , they are very different .", "speaker": "C"}, {"text": "and we could gain something by combining them", "speaker": "C"}, {"text": "the other thing is that you just picked one particular way of doing it .", "speaker": "B"}, {"text": ", first place it 's fifteen db , , down across the utterance .", "speaker": "B"}, {"text": "and you 'd want to have something that was little more adaptive .", "speaker": "B"}, {"text": "secondly , you happened to pick fifteen db", "speaker": "B"}, {"text": "and twenty 'd be better ,", "speaker": "B"}, {"text": "so what was the what was the threshold part of it ?", "speaker": "F"}, {"text": "was the threshold , , how far down ?", "speaker": "F"}, {"text": "he , he had to figure out how much to add .", "speaker": "B"}, {"text": "so he was looking he was looking at the peak value .", "speaker": "B"}, {"text": "and and so what 's", "speaker": "F"}, {"text": "ho don't understand .", "speaker": "F"}, {"text": "how does it go ?", "speaker": "F"}, {"text": "if it if the peak value 's above some threshold , then you add the noise ?", "speaker": "F"}, {"text": "or if it 's below", "speaker": "F"}, {"text": "systematically add the noise ,", "speaker": "C"}, {"text": "but the , , noise level is just some threshold below the peak .", "speaker": "C"}, {"text": "which is not really noise , actually .", "speaker": "C"}, {"text": "it 's just adding constant to each of the mel , , energy .", "speaker": "C"}, {"text": "to each of the mel filter bank .", "speaker": "C"}, {"text": "so , , it 's really , , white noise .", "speaker": "C"}, {"text": "so then afterwards log is taken ,", "speaker": "B"}, {"text": "and that 's so why the little variation tends to go away .", "speaker": "B"}, {"text": "the this threshold is still factor that we have to look at .", "speaker": "C"}, {"text": "and , constant noise addition would be fine also ,", "speaker": "C"}, {"text": "or or not constant but , , varying over time is another way to go .", "speaker": "B"}, {"text": "were you using the normalization in addition to this ?", "speaker": "B"}, {"text": "what was the rest of the system ?", "speaker": "B"}, {"text": "it was it was , , the same system .", "speaker": "C"}, {"text": "it was the same system .", "speaker": "C"}, {"text": "third thing is that , , play little bit with the , finding what was different between , ,", "speaker": "C"}, {"text": "and there were couple of differences ,", "speaker": "C"}, {"text": "like the lda filters were not the same .", "speaker": "C"}, {"text": "he had the france telecom blind equalization in the system .", "speaker": "C"}, {"text": "the number of mfcc that was were used was different .", "speaker": "C"}, {"text": "and we used fifteen .", "speaker": "C"}, {"text": "bunch of differences .", "speaker": "C"}, {"text": "and , , actually the result that he got were much better on ti - digits especially .", "speaker": "C"}, {"text": "so 'm investigated to see what was the maor for this difference .", "speaker": "C"}, {"text": "and it seems that the lda filter is was hurting .", "speaker": "C"}, {"text": "so when we put some noise compensation the , , lda filter that 's derived from noisy speech is not more anymore optimal .", "speaker": "C"}, {"text": "and it makes big difference , , on ti - digits", "speaker": "C"}, {"text": "trained on clean .", "speaker": "C"}, {"text": "if we use the old lda filter , the lda filter that was in the proposal , we have , like , eighty - two point seven percent recognition rate ,", "speaker": "C"}, {"text": "on noisy speech when the system is trained on clean speech .", "speaker": "C"}, {"text": "and when we use the filter that 's derived from clean speech we jumped", "speaker": "C"}, {"text": "so from eighty - two point seven to eighty - five point one ,", "speaker": "C"}, {"text": "which is huge leap .", "speaker": "C"}, {"text": "so now the results are more similar ,", "speaker": "C"}, {"text": "don't will not , , investigate on the other differences ,", "speaker": "C"}, {"text": "which is like the number of mfcc that we keep and other small things", "speaker": "C"}, {"text": "that we can optimize later on anyway .", "speaker": "C"}, {"text": "but on the other hand if everybody is trying different kinds of noise suppression things and , it might be good to standardize on the piece that we 're not changing .", "speaker": "B"}, {"text": "so if there 's any particular reason to ha pick one or the other ,", "speaker": "B"}, {"text": "which which one is closer to what the proposal was that was submitted to aurora ?", "speaker": "B"}, {"text": ", the new system that tested is , , closer", "speaker": "C"}, {"text": "because it doesn't have it have less of france telecom ,", "speaker": "C"}, {"text": "the whatever you , , tested with recently . ?", "speaker": "D"}, {"text": "you 're trying to add in france telecom .", "speaker": "B"}, {"text": "tell them about the rest of it .", "speaker": "B"}, {"text": "like you said the number of filters might be different .", "speaker": "B"}, {"text": "the number of cepstral coefficients is what ?", "speaker": "D"}, {"text": "so , , we 'd wanna standardize there ,", "speaker": "B"}, {"text": "so , sh you should pick something", "speaker": "B"}, {"text": "all all three of you .", "speaker": "B"}, {"text": "we were gonna work with this or this new system ,", "speaker": "C"}, {"text": "so the now , the system that is there in the what we have in the repositories , with uses fifteen .", "speaker": "D"}, {"text": "but we will use the lda filters derived from clean speech .", "speaker": "C"}, {"text": ", actually it 's it 's not the lda filter .", "speaker": "C"}, {"text": "it 's something that 's also short enough in latency .", "speaker": "C"}, {"text": "so , we haven't we have been always using , , fifteen coefficients ,", "speaker": "D"}, {"text": ", that 's something 's", "speaker": "D"}, {"text": "as long as you agree on it , it doesn't matter .", "speaker": "B"}, {"text": "we have maximum of sixty , , features that we 're allowed .", "speaker": "B"}, {"text": "ma - we can , at least ,", "speaker": "D"}, {"text": "'ll run some experiments to see whether once have this noise compensation to see whether thirteen and fifteen really matters or not .", "speaker": "D"}, {"text": "never tested it with the compensation ,", "speaker": "D"}, {"text": "but without , , compensation it was like fifteen was slightly better than thirteen ,", "speaker": "D"}, {"text": "so that 's why we stuck to thirteen .", "speaker": "D"}, {"text": "and there is there is also this log energy versus - zero .", "speaker": "C"}, {"text": "the log energy versus - zero .", "speaker": "D"}, {"text": "that 's that 's the other thing .", "speaker": "D"}, {"text": "without noise compensation certainly - zero is better than log energy .", "speaker": "D"}, {"text": "be - , because the there are more , , mismatched conditions than the matching conditions for testing .", "speaker": "D"}, {"text": "always for the matched condition , you always get slightly better performance for log energy than - zero .", "speaker": "D"}, {"text": "for matched and the clean condition both , you get log energy", "speaker": "D"}, {"text": "you get better performance with log energy .", "speaker": "D"}, {"text": ", once we have this noise compensation , , we have to try that also , whether we want to go for - zero or log energy .", "speaker": "D"}, {"text": "we can see that .", "speaker": "D"}, {"text": "so do you have more , stephane ,", "speaker": "F"}, {"text": "that 's it , .", "speaker": "C"}, {"text": "do you have anything , morgan ,", "speaker": "F"}, {"text": "no . 'm just , , being manager this week .", "speaker": "B"}, {"text": "how about you , barry ?", "speaker": "F"}, {"text": "still working on my quals preparation .", "speaker": "A"}, {"text": "so 'm 'm thinking about , , starting some , , cheating experiments to , , determine the , the relative effectiveness of , , some intermediate categories that want to classify .", "speaker": "A"}, {"text": "so , , , if know where voicing occurs and everything , , would do phone , phone recognition experiment ,", "speaker": "A"}, {"text": "somehow putting in the , the perfect knowledge that have about voicing .", "speaker": "A"}, {"text": "so , , in particular was thinking , , in the hybrid framework , just taking those lna files , and , , setting to zero those probabilities that , that these phones are not voicing .", "speaker": "A"}, {"text": "so say , like , know this particular segment is voicing ,", "speaker": "A"}, {"text": "would say , , go into the corresponding lna file and zonk out the posteriors for , , those phonemes that , , are not voiced ,", "speaker": "A"}, {"text": "and then see what kinds of improvements get .", "speaker": "A"}, {"text": "and so this would be useful thing , , to terms of , like , which , which of these categories are good for , , speech recognition .", "speaker": "A"}, {"text": "so , that 's", "speaker": "A"}, {"text": "hope to get those , those experiments done by the time quals come around in july .", "speaker": "A"}, {"text": "so do you just take the probabilities of the other ones and spread them out evenly among the remaining ones ?", "speaker": "F"}, {"text": "so just set to set to some really low number , the non - voiced , , phones .", "speaker": "A"}, {"text": "and then renormalize .", "speaker": "A"}, {"text": "that will be really interesting to see ,", "speaker": "F"}, {"text": "so then you 're gonna feed the those into some standard recognizer .", "speaker": "F"}, {"text": "wh are you gonna do digits", "speaker": "F"}, {"text": ", 'm gonna work with timit", "speaker": "A"}, {"text": "with timit . .", "speaker": "F"}, {"text": "timit , phone recognition with timit .", "speaker": "A"}, {"text": "so then you 'll feed those", "speaker": "F"}, {"text": "so where do the outputs of the net go into if you 're doing phone recognition ?", "speaker": "F"}, {"text": "the outputs of the net go into the standard , , icsi hybrid , , recognizer .", "speaker": "A"}, {"text": "so , , chronos", "speaker": "A"}, {"text": "an - and you 're gonna the you 're gonna do phone recognition with that ?", "speaker": "F"}, {"text": "and , , another thing would be to extend this to , , digits where look at whole words .", "speaker": "A"}, {"text": "and would be able to see , , not just , like , phoneme events , but , , inter - phoneme events .", "speaker": "A"}, {"text": "so , like , this is from stop to vo vocalic", "speaker": "A"}, {"text": "so something that is transitional in nature .", "speaker": "A"}, {"text": "so that 's that 's it .", "speaker": "A"}, {"text": "let 's see , haven't done whole lot on anything related to this week .", "speaker": "F"}, {"text": "'ve been focusing mainly on meeting recorder .", "speaker": "F"}, {"text": "so , , 'll just pass it on to dave .", "speaker": "F"}, {"text": "in my lunch talk last week said 'd tried phase normalization and gotten garbage results using that , long - term mean subtraction approach .", "speaker": "G"}, {"text": "it turned out there was bug in my matlab code .", "speaker": "G"}, {"text": "so tried it again ,", "speaker": "G"}, {"text": "and , , the results were better .", "speaker": "G"}, {"text": "got intelligible speech back .", "speaker": "G"}, {"text": "but they still weren't as good as just subtracting the magnitude the log magnitude means .", "speaker": "G"}, {"text": "and also 've been talking to , , andreas and thilo about the , , smartkom language model", "speaker": "G"}, {"text": "and about coming up with good model for , , far mike use of the smartkom system .", "speaker": "G"}, {"text": "'m gonna be working on , , implementing this mean subtraction approach in the far - mike system", "speaker": "G"}, {"text": "for the smartkom system , .", "speaker": "G"}, {"text": "one of the experiments we 're gonna do is , , we 're gonna , , train the broadcast news net ,", "speaker": "G"}, {"text": "which is because that 's what we 've been using so far ,", "speaker": "G"}, {"text": "and , , adapt it on some other data . , an - andreas wants to use ,", "speaker": "G"}, {"text": "data that resembles read speech ,", "speaker": "G"}, {"text": "like these digit readings ,", "speaker": "G"}, {"text": "because he feels that the smartkom system interaction is not gonna be exactly conversational .", "speaker": "G"}, {"text": "so actually was wondering , how long does it take to train that broadcast news net ?", "speaker": "G"}, {"text": "the big one takes while .", "speaker": "B"}, {"text": "that takes two , three weeks .", "speaker": "B"}, {"text": "two , three weeks .", "speaker": "G"}, {"text": "so but , , , you can get", "speaker": "B"}, {"text": "if you even want to run the big one , , , in the in the final system ,", "speaker": "B"}, {"text": "cuz , , it takes little while to run it .", "speaker": "B"}, {"text": "so , , you can scale it down by", "speaker": "B"}, {"text": "it was two , three weeks for training up for the large broadcast news test set training set .", "speaker": "B"}, {"text": "how much you 'd be training on .", "speaker": "B"}, {"text": "so if you trained on half as much and made the net , , half as big , then it would be one fourth the amount of time", "speaker": "B"}, {"text": "and it 'd be nearly as good .", "speaker": "B"}, {"text": "also , we had we 've had these , , little di discussions", "speaker": "B"}, {"text": "you ha haven't had chance to work with it too much", "speaker": "B"}, {"text": "about , other ways of taking care of the phase .", "speaker": "B"}, {"text": "so , , that was something could say would be that we 've talked little bit about", "speaker": "B"}, {"text": "you just doing it all with complex arithmetic", "speaker": "B"}, {"text": "and not , , doing the polar representation with magnitude and phase .", "speaker": "B"}, {"text": "but it looks like there 's ways that one could potentially just work with the complex numbers and and in principle get rid of the effects of the average complex spectrum .", "speaker": "B"}, {"text": "actually , regarding the phase normalization", "speaker": "G"}, {"text": "so did two experiments ,", "speaker": "G"}, {"text": "so , phases get added , modulo two pi ,", "speaker": "G"}, {"text": "and because you only know the phase of the complex number to value modulo two pi .", "speaker": "G"}, {"text": "and so at first , , that , , what should do is unwrap the phase", "speaker": "G"}, {"text": "because that will undo that .", "speaker": "G"}, {"text": "but actually got worse results doing that unwrapping using the simple phase unwrapper that 's in matlab than did not unwrapping .", "speaker": "G"}, {"text": "and that 's all have to say .", "speaker": "G"}, {"text": "so 'm 'm still hopeful that", "speaker": "B"}, {"text": "we don't even the phase is something the average phase is something that we do want to remove .", "speaker": "B"}, {"text": "there 's some deeper reason why it isn't the thing to do .", "speaker": "B"}, {"text": "at least in principle it looks like there 's there 's , , couple potential ways to do it .", "speaker": "B"}, {"text": "one one being to just work with the complex numbers ,", "speaker": "B"}, {"text": "and , in rectangular coordinates .", "speaker": "B"}, {"text": "and the other is to , , do taylor series", "speaker": "B"}, {"text": "so you work with the complex numbers", "speaker": "B"}, {"text": "and then when you get the spectrum the average complex spectrum , actually divide it out ,", "speaker": "B"}, {"text": "as opposed to taking the log and subtracting .", "speaker": "B"}, {"text": "there might be some numerical issues .", "speaker": "B"}, {"text": "we don't really know that .", "speaker": "B"}, {"text": "the other thing we talked little bit about was taylor series expansion .", "speaker": "B"}, {"text": "actually was talking to dick karp about it little bit ,", "speaker": "B"}, {"text": "and and , since got thinking about it ,", "speaker": "B"}, {"text": "so one thing is that you 'd have to do , ,", "speaker": "B"}, {"text": "we may have to do this on whiteboard ,", "speaker": "B"}, {"text": "but you have to be little careful about scaling the numbers that you 're taking the complex numbers that you 're taking the log of", "speaker": "B"}, {"text": "because the taylor expansion for it has , , square and cube , and .", "speaker": "B"}, {"text": "and and so if you have number that is modulus , , , very different from one it should be around one ,", "speaker": "B"}, {"text": "cuz it 's expansion of log one", "speaker": "B"}, {"text": "or is one plus epsilon ,", "speaker": "B"}, {"text": "or is it one plus ?", "speaker": "B"}, {"text": "there 's an epsilon squared over two", "speaker": "B"}, {"text": "and an epsilon cubed over three ,", "speaker": "B"}, {"text": "so if epsilon is bigger than one , then it diverges .", "speaker": "B"}, {"text": "so you have to do some scaling .", "speaker": "B"}, {"text": "but that 's not big deal", "speaker": "B"}, {"text": "cuz it 's the log of times complex number ,", "speaker": "B"}, {"text": "then you can just that 's the same as log of plus log of the complex number .", "speaker": "B"}, {"text": "how about you , sunil ?", "speaker": "F"}, {"text": "so , , 've been , , implementing this , , wiener filtering for this aurora task .", "speaker": "D"}, {"text": "actually thought it was it was doing fine when tested it once .", "speaker": "D"}, {"text": "it 's , like , using small section of the code .", "speaker": "D"}, {"text": "and then ran the whole recognition experiment with italian", "speaker": "D"}, {"text": "and got , like , worse results than not using it .", "speaker": "D"}, {"text": "so , 've been trying to find where the problem came from .", "speaker": "D"}, {"text": "and then it looks like have some problem in the way", "speaker": "D"}, {"text": "there is some very silly bug somewhere .", "speaker": "D"}, {"text": "and , ugh !", "speaker": "D"}, {"text": ", it actually it actually made the whole thing worse .", "speaker": "D"}, {"text": "was looking at the spectrograms that got", "speaker": "D"}, {"text": "and it 's , like it 's it 's very horrible .", "speaker": "D"}, {"text": "was was distracted .", "speaker": "B"}, {"text": "missed the very first sentence .", "speaker": "B"}, {"text": "so then , 'm little lost on the rest .", "speaker": "B"}, {"text": "actually implemented the wiener fil filtering as module and then tested it out separately .", "speaker": "D"}, {"text": "and it it gave , like got the signal out", "speaker": "D"}, {"text": "and it was .", "speaker": "D"}, {"text": "so , plugged it in somewhere", "speaker": "D"}, {"text": "and then , it 's like had to remove some part", "speaker": "D"}, {"text": "and then plugging it in somewhere .", "speaker": "D"}, {"text": "and then in that process messed it up somewhere .", "speaker": "D"}, {"text": "so , it was real", "speaker": "D"}, {"text": "it was all fine", "speaker": "D"}, {"text": "and then ran it , and got something worse than not using it .", "speaker": "D"}, {"text": "was like 'm trying to find where the problem came ,", "speaker": "D"}, {"text": "and it seems to be , like , somewhere", "speaker": "D"}, {"text": "and , , the other thing , , was ,", "speaker": "D"}, {"text": "hynek showed up one suddenly on one day", "speaker": "D"}, {"text": "and then was talking wi", "speaker": "D"}, {"text": "as as he is wont to do .", "speaker": "B"}, {"text": "so was actually that day was thinking about doing something about the wiener filtering , and then carlos matter of .", "speaker": "D"}, {"text": "and then he showed up", "speaker": "D"}, {"text": "and then told him .", "speaker": "D"}, {"text": "and then he gave me whole bunch of filters", "speaker": "D"}, {"text": "what carlos used for his , , thesis", "speaker": "D"}, {"text": "and then that was something which came up .", "speaker": "D"}, {"text": "so , , 'm actually , , thinking of using that also in this , , wiener filtering", "speaker": "D"}, {"text": "because that is modified wiener filtering approach ,", "speaker": "D"}, {"text": "where instead of using the current frame , it uses adjacent frames also in designing the wiener filter .", "speaker": "D"}, {"text": "so instead of designing our own new wiener filters , may just use one of those carlos filters in this implementation", "speaker": "D"}, {"text": "and see whether it actually gives me something better", "speaker": "D"}, {"text": "than using just the current current frame ,", "speaker": "D"}, {"text": "which is in way , , something like the smoothing the wiener filter", "speaker": "D"}, {"text": "'m 'm , like", "speaker": "D"}, {"text": "that so that is the next thing . once this once sort this pro , problem out 'll just go into that also .", "speaker": "D"}, {"text": "the other thing was about the subspace approach .", "speaker": "D"}, {"text": "like , plugged some groupings for computing this eigen , , values and eigenvectors .", "speaker": "D"}, {"text": "so just @ @ some small block of things which needed to put together for the subspace approach .", "speaker": "D"}, {"text": "and 'm in the process of , like , building up that .", "speaker": "D"}, {"text": "that 's it .", "speaker": "D"}, {"text": "and , , that 's where am now .", "speaker": "D"}, {"text": "how about you , carmen ?", "speaker": "F"}, {"text": "mmm . 'm working with vts .", "speaker": "E"}, {"text": "do several experiment with the spanish database first ,", "speaker": "E"}, {"text": "only with vts and nothing more .", "speaker": "E"}, {"text": "what what is vts again ?", "speaker": "F"}, {"text": "vectorial taylor series .", "speaker": "E"}, {"text": "to remove the noise too .", "speaker": "E"}, {"text": "ask you that every single meeting ,", "speaker": "F"}, {"text": "ask you that question every meeting .", "speaker": "F"}, {"text": "so , that 'd be good from for analysis .", "speaker": "B"}, {"text": "it 's good to have some , , cases of the same utterance at different times .", "speaker": "B"}, {"text": "\" what is vts ? \"", "speaker": "F"}, {"text": ", the question is that", "speaker": "E"}, {"text": "remove some noise but not too much .", "speaker": "E"}, {"text": "and when we put the the , , vad , the result is better .", "speaker": "E"}, {"text": "and we put everything , the result is better ,", "speaker": "E"}, {"text": "but it 's not better than the result that we have without vts .", "speaker": "E"}, {"text": "no , no .", "speaker": "E"}, {"text": "so that @ @ given that you 're using the vad also , the effect of the vts is not so far", "speaker": "B"}, {"text": "do you how much of that do you due to just the particular implementation and how much you 're adjusting it ?", "speaker": "B"}, {"text": "or how much do you intrinsic to ?", "speaker": "B"}, {"text": "are you still using only the ten first frame for noise estimation", "speaker": "C"}, {"text": "do the experiment using only the onl , to use on only one fair estimation of the noise .", "speaker": "E"}, {"text": "and also did some experiment , , doing , , lying estimation of the noise .", "speaker": "E"}, {"text": "and , , it 's little bit better but not", "speaker": "E"}, {"text": "you have to standardize this thing also ,", "speaker": "C"}, {"text": "because all the thing that you are testing use different", "speaker": "C"}, {"text": "they all need some noise spectra", "speaker": "C"}, {"text": "no , do that two did two time .", "speaker": "E"}, {"text": "but they use every all use different one .", "speaker": "C"}, {"text": "have an idea .", "speaker": "B"}, {"text": "if if , ,", "speaker": "B"}, {"text": "each of these require this .", "speaker": "B"}, {"text": "given that we 're going to have for this test at least of , boundaries , what if initially we start off by using known sections of nonspeech for the estimation ?", "speaker": "B"}, {"text": "first place , even if ultimately we wouldn't be given the boundaries , , this would be good initial experiment to separate out the effects of things .", "speaker": "B"}, {"text": "how much is the poor , relatively , , unhelpful result that you 're getting in this or this", "speaker": "B"}, {"text": "is due to some inherent limitation to the method for these tasks", "speaker": "B"}, {"text": "and how much of it is just due to the fact that you 're not accurately finding enough regions that are really noise ?", "speaker": "B"}, {"text": "so if you tested it using that , you 'd have more reliable stretches of nonspeech to do the estimation from", "speaker": "B"}, {"text": "and see if that helps .", "speaker": "B"}, {"text": "another thing is the , the codebook ,", "speaker": "E"}, {"text": "the initial codebook .", "speaker": "E"}, {"text": "it 's too clean", "speaker": "E"}, {"text": "if you want , you say something about the method .", "speaker": "E"}, {"text": "because it 's little bit different of the other method .", "speaker": "E"}, {"text": "if this if this is the noise signal , {nonvocalsound} , in the log domain , we have something like this .", "speaker": "E"}, {"text": "now , we have something like this .", "speaker": "E"}, {"text": "and the idea of these methods is to given ,", "speaker": "E"}, {"text": "how do you say ?", "speaker": "E"}, {"text": "will read because it 's better for my english .", "speaker": "E"}, {"text": "is the estimate of the pdf of the noise signal", "speaker": "E"}, {"text": "when we have , , statistic of the clean speech and an statistic of the noisy speech .", "speaker": "E"}, {"text": "and the clean speech the statistic of the clean speech is from codebook .", "speaker": "E"}, {"text": "mmm ? this is the idea .", "speaker": "E"}, {"text": "like , this relation is not linear .", "speaker": "E"}, {"text": "the methods propose to develop this in vectorial taylor series approximation .", "speaker": "E"}, {"text": "'m actually just confused about the equations you have up there .", "speaker": "B"}, {"text": "the top equation is is", "speaker": "B"}, {"text": "no , this in the it 's this is the log domain .", "speaker": "E"}, {"text": "must to say that .", "speaker": "E"}, {"text": "which is which is the log domain ?", "speaker": "B"}, {"text": "is the is egual is equal to , , log of", "speaker": "E"}, {"text": "but is what ?", "speaker": "B"}, {"text": "and this is this .", "speaker": "E"}, {"text": "no , no .", "speaker": "B"}, {"text": "the top is what ?", "speaker": "B"}, {"text": "is that power spectrum ?", "speaker": "B"}, {"text": "this is the noisy speech .", "speaker": "E"}, {"text": "no , is that power spectrum ?", "speaker": "B"}, {"text": "it 's the power spectrum of noisy speech .", "speaker": "C"}, {"text": "it 's the power spectrum .", "speaker": "E"}, {"text": "this is the noisy", "speaker": "E"}, {"text": "so this it 's the magnitude squared .", "speaker": "B"}, {"text": "so you have power spectrum added there", "speaker": "B"}, {"text": "and down here you have you put the", "speaker": "B"}, {"text": "but all of this is just you just mean", "speaker": "B"}, {"text": "it 's the same .", "speaker": "E"}, {"text": "you just mean the log of the of the one up above .", "speaker": "B"}, {"text": "and , , so that is times ,", "speaker": "B"}, {"text": "one one plus by .", "speaker": "D"}, {"text": "we can expre we can put this expression", "speaker": "E"}, {"text": "times one plus , , minus ?", "speaker": "B"}, {"text": "so that 's log of plus log of one plus ,", "speaker": "B"}, {"text": "and the noise signal .", "speaker": "E"}, {"text": "one plus by .", "speaker": "D"}, {"text": "actually don't see how you get that .", "speaker": "B"}, {"text": "if we apply the log , we have is", "speaker": "E"}, {"text": "log {nonvocalsound} is equal , , to log of plus .", "speaker": "E"}, {"text": "and , log of", "speaker": "D"}, {"text": "we can say that {nonvocalsound} is equal to log of , {nonvocalsound} {nonvocalsound} , exponential of plus exponential of .", "speaker": "E"}, {"text": "that doesn't follow .", "speaker": "B"}, {"text": "this is this is in the ti the time domain .", "speaker": "E"}, {"text": "we have that ,", "speaker": "E"}, {"text": "we have first that , , is equal ,", "speaker": "E"}, {"text": "this is the frequency domain", "speaker": "E"}, {"text": "and we can put that the log domain", "speaker": "E"}, {"text": "log of omega ,", "speaker": "E"}, {"text": "but , , in the time domain we have an exponential .", "speaker": "E"}, {"text": "just never mind what they are .", "speaker": "B"}, {"text": "it 's just if and are variables", "speaker": "B"}, {"text": "what is , ?", "speaker": "D"}, {"text": "the the log of plus is not the same as the log of to the plus to the .", "speaker": "B"}, {"text": "we can take it off - line ,", "speaker": "B"}, {"text": "do this incorrectly .", "speaker": "E"}, {"text": "the expression that appear in the in the paper , {nonvocalsound} is ,", "speaker": "E"}, {"text": "the taylor series expansion for log one plus by is", "speaker": "D"}, {"text": "is it the first - order expansion ?", "speaker": "C"}, {"text": "the first one .", "speaker": "D"}, {"text": "cuz it doesn't just follow what 's there .", "speaker": "B"}, {"text": "it has to be some , , taylor series", "speaker": "B"}, {"text": "if if you take log into log one plus by , and then expand the log one plus by into taylor series", "speaker": "D"}, {"text": "now , this is the", "speaker": "E"}, {"text": "but the second expression that you put is the first - order expansion of the nonlinear relation between", "speaker": "C"}, {"text": "no , no .", "speaker": "E"}, {"text": "it 's not the first space .", "speaker": "E"}, {"text": "we have pfft , ,", "speaker": "E"}, {"text": "we can put that is equal is equal to log of , ,", "speaker": "E"}, {"text": "that doesn't follow .", "speaker": "B"}, {"text": "we can put , , this ?", "speaker": "E"}, {"text": "that , that the top one does not imply the second one .", "speaker": "B"}, {"text": "because cuz the log of sum is not the same as", "speaker": "B"}, {"text": "we know that , , the log of plus is equal to log of plus log to .", "speaker": "E"}, {"text": "and we can say here , it", "speaker": "E"}, {"text": "what is that ?", "speaker": "C"}, {"text": "and we can , , put this inside .", "speaker": "E"}, {"text": "and then we can ,", "speaker": "E"}, {"text": "don't see how you get the second expression from the top one .", "speaker": "B"}, {"text": "the , just more generally here , if you say \" log of , , plus \" ,", "speaker": "B"}, {"text": "the log of log of plus is not", "speaker": "B"}, {"text": "or plus is not the , , log of to the plus to the .", "speaker": "B"}, {"text": "no , no , no , no .", "speaker": "E"}, {"text": "and that 's what you seem to be saying .", "speaker": "B"}, {"text": "it 's not . but this is the same", "speaker": "E"}, {"text": "cuz you cuz you up here you have the plus", "speaker": "B"}, {"text": "say if apply log , have , , log of is equal to log of , in this side , is equal to log of", "speaker": "E"}, {"text": "and then how do you go from there to the ?", "speaker": "B"}, {"text": "and then if apply exponential , to have here", "speaker": "E"}, {"text": "it 's log of capital .", "speaker": "C"}, {"text": "this is , inside .", "speaker": "D"}, {"text": "we have this ,", "speaker": "E"}, {"text": "that one 's .", "speaker": "B"}, {"text": "we can put here the set transformation .", "speaker": "E"}, {"text": "in this case , , we can put here {nonvocalsound} .", "speaker": "E"}, {"text": "it 's just by definition that the individual that the ,", "speaker": "B"}, {"text": "so , capital is by definition the same as to the little", "speaker": "B"}, {"text": "because she 's saying that the little is the , is the log .", "speaker": "B"}, {"text": "now we can put this .", "speaker": "E"}, {"text": "and here we can multiply by .", "speaker": "E"}, {"text": "these things are lot clearer when you can use fonts different fonts there", "speaker": "B"}, {"text": "so which is which .", "speaker": "B"}, {"text": "but under understand what you mean now .", "speaker": "B"}, {"text": "that 's true .", "speaker": "E"}, {"text": "that 's true .", "speaker": "E"}, {"text": "but this is correct ?", "speaker": "E"}, {"text": "and now do it ,", "speaker": "E"}, {"text": "put log {nonvocalsound} of ex plus log", "speaker": "E"}, {"text": "yes . understand now .", "speaker": "B"}, {"text": "and that 's where it comes from .", "speaker": "B"}, {"text": "now it 's correct .", "speaker": "E"}, {"text": "we have fixed this equa", "speaker": "E"}, {"text": "so now once you get that one , then you then you do first or second - order , , taylor series expansion of this .", "speaker": "B"}, {"text": "this is another linear relation that this to develop this in vector taylor series .", "speaker": "E"}, {"text": "and for that , , the goal is to obtain , est estimate pdf for the noisy speech", "speaker": "E"}, {"text": "when we have statistic for clean speech and for the noisy speech .", "speaker": "E"}, {"text": "the way to obtain the pdf for the noisy speech is", "speaker": "E"}, {"text": "we know this statistic", "speaker": "E"}, {"text": "and we know the noisy st", "speaker": "E"}, {"text": "we can apply first order of the vector st taylor series of the of , the order that we want , increase the complexity of the problem .", "speaker": "E"}, {"text": "and then when we have expression , , for the mean and variance of the noisy speech , we apply technique of minimum mean - square estimation", "speaker": "E"}, {"text": "to obtain the expected value of the clean speech given the this statistic for the noisy speech", "speaker": "E"}, {"text": "the statistic for clean speech and the statistic of the noisy speech .", "speaker": "E"}, {"text": "this only that .", "speaker": "E"}, {"text": "but the idea is that", "speaker": "E"}, {"text": "and the model of clean speech is codebook . ?", "speaker": "C"}, {"text": "we have our codebook with different density gaussian .", "speaker": "E"}, {"text": "we can expre we can put that the pdf for the clean test , probability of the clean speech is equal to", "speaker": "E"}, {"text": "how much in the work they reported , how much noisy speech did you need to get , , good enough statistics", "speaker": "B"}, {"text": "for the to get this mapping ?", "speaker": "B"}, {"text": "cuz what 's certainly characteristic of lot of the data in this test is that , , you don't have the", "speaker": "B"}, {"text": "the training set may not be estimator for the noise in the test set .", "speaker": "B"}, {"text": "and sometimes it 's not .", "speaker": "B"}, {"text": "the clean speech the codebook for clean speech , am using timit .", "speaker": "E"}, {"text": "and have now , , sixty - four {nonvocalsound} gaus - gaussian .", "speaker": "E"}, {"text": "and what are you using for the noisy ?", "speaker": "B"}, {"text": "estimate the noises wi", "speaker": "E"}, {"text": "for the noises only use one gaussian .", "speaker": "E"}, {"text": "and and you train it up entirely from , , nonspeech sections in the test ?", "speaker": "B"}, {"text": "the first experiment that do it is solely to calculate the , mmm , this value", "speaker": "E"}, {"text": "the compensation of the dictionary one time", "speaker": "E"}, {"text": "using the noise at the beginning of the sentence .", "speaker": "E"}, {"text": "this is the first experiment .", "speaker": "E"}, {"text": "and fix this for all the all the sentences .", "speaker": "E"}, {"text": "the first thing that do is to obtain , , an expression for", "speaker": "E"}, {"text": "probability expression of .", "speaker": "E"}, {"text": "that mean that the vts mmm , with the vts we obtain ,", "speaker": "E"}, {"text": "we obtain the means for each gaussian and the variance .", "speaker": "E"}, {"text": "this is one .", "speaker": "E"}, {"text": "this is the composition of the dictionary .", "speaker": "E"}, {"text": "this one thing .", "speaker": "E"}, {"text": "and the other thing that this with these methods is to , , obtain to calculate this value .", "speaker": "E"}, {"text": "because we can write", "speaker": "E"}, {"text": "we can write that the estimation of the clean speech is equal at an expected value of the clean speech conditional to , , the noise signal the probability of the statistic of the clean speech and the statistic of the noise .", "speaker": "E"}, {"text": "this is the methods that say that we 're going obtain this .", "speaker": "E"}, {"text": "and we can put that this is equal to the estimated value of minus function that conditional to to the to the noise signal .", "speaker": "E"}, {"text": "this is this function is the term after develop this , the term that we take .", "speaker": "E"}, {"text": "give px and , , the noise .", "speaker": "E"}, {"text": "and put that this is equal to the noise signal minus", "speaker": "E"}, {"text": "put before this name ,", "speaker": "E"}, {"text": "and calculate this .", "speaker": "E"}, {"text": "what is the first variable in that probability ?", "speaker": "B"}, {"text": "this is the gaussian .", "speaker": "E"}, {"text": "no , no . 'm .", "speaker": "B"}, {"text": "in in the one you pointed at .", "speaker": "B"}, {"text": "what 's that variable ?", "speaker": "B"}, {"text": "so probably it would do that .", "speaker": "D"}, {"text": "it 's one mixture of the model . ?", "speaker": "C"}, {"text": "no , it 's condition", "speaker": "E"}, {"text": "it 's not exactly this .", "speaker": "E"}, {"text": "it 's modify .", "speaker": "E"}, {"text": "if we have clean speech we have the dictionary for the clean speech , we have probability of our weight for each gaussian .", "speaker": "E"}, {"text": "and now , this weight is different now", "speaker": "E"}, {"text": "because it 's conditional .", "speaker": "E"}, {"text": "and this need to calcu", "speaker": "E"}, {"text": "because this is from the dictionary that you have .", "speaker": "E"}, {"text": "need to calculate this .", "speaker": "E"}, {"text": "and for calculate this , have an develop an expression that is", "speaker": "E"}, {"text": "it 's overlapping .", "speaker": "D"}, {"text": "calculate calculated this value , , with the statistic of the noisy speech that calculated before with the vts approximation .", "speaker": "E"}, {"text": "and , normalizing .", "speaker": "E"}, {"text": "and know everything .", "speaker": "E"}, {"text": "when develop this in taylor series , 't , , calculate the mean and the variance of the for each of the gaussian of the dictionary for the noisy speech .", "speaker": "E"}, {"text": "and this is fixed .", "speaker": "E"}, {"text": "if never do an estimat newer estimation of the noise , this mean as mean and the variance are fixed .", "speaker": "E"}, {"text": "and for each , frame of the speech the only thing that need to do is to calculate this", "speaker": "E"}, {"text": "in order to calculate the estimation of the clean speech given our noisy speech .", "speaker": "E"}, {"text": "so , 'm 'm not following this perfectly", "speaker": "B"}, {"text": "are you saying of these estimates are done using , , estimates of the probability density for the noise that are calculated only from the first ten frames ?", "speaker": "B"}, {"text": "and never change throughout anything else ?", "speaker": "B"}, {"text": "this is one of the approximations that am doing .", "speaker": "E"}, {"text": "per per utterance ,", "speaker": "B"}, {"text": "per utterance . yes .", "speaker": "E"}, {"text": "per utterance . yes .", "speaker": "E"}, {"text": "so it 's done it 's done new for each new utterance .", "speaker": "B"}, {"text": "so this changes the whole mapping for every utterance .", "speaker": "B"}, {"text": "it 's fixed , the dictionary .", "speaker": "E"}, {"text": "and the other estimation is when do the on - line estimation , change the means and variance of for the noisy speech", "speaker": "E"}, {"text": "each time that detect noise .", "speaker": "E"}, {"text": "do it again this", "speaker": "E"}, {"text": "estimate the new mean and the variance of the noisy speech .", "speaker": "E"}, {"text": "and with with this new new mean and variance estimate again this .", "speaker": "E"}, {"text": "so you estimated , , completely forgetting what you had before ?", "speaker": "B"}, {"text": "or is there some adaptation ?", "speaker": "B"}, {"text": "no , no . it 's not completely", "speaker": "E"}, {"text": "no , it 's am doing something like an adaptation of the noise .", "speaker": "E"}, {"text": "now do we know , either from their experience or from yours , that , , just having , , two parameters , the mean and variance , is enough ?", "speaker": "B"}, {"text": "know you don't have lot of data to estimate with ,", "speaker": "B"}, {"text": "estimate mean and variance for each one of the gaussian of the codebook .", "speaker": "E"}, {"text": "no , 'm talking about the noise .", "speaker": "B"}, {"text": "there 's only one gaussian .", "speaker": "B"}, {"text": "am only using only one .", "speaker": "E"}, {"text": "and you and it 's ,", "speaker": "B"}, {"text": "it 's only one", "speaker": "B"}, {"text": "what 's the dimensionality of the gaussian ?", "speaker": "B"}, {"text": "it 's in after the mel filter bank .", "speaker": "E"}, {"text": "so this is twenty ?", "speaker": "B"}, {"text": "twenty - three .", "speaker": "E"}, {"text": "so it 's actually forty numbers that you 're getting .", "speaker": "B"}, {"text": "the original paper say that only one gaussian for the noise .", "speaker": "E"}, {"text": "but , , no paper is bible ,", "speaker": "B"}, {"text": "isn't the thing .", "speaker": "E"}, {"text": "this is this is ,", "speaker": "B"}, {"text": "the question is , , whether it would be helpful , particularly if you used if you had more", "speaker": "B"}, {"text": "so , suppose you did", "speaker": "B"}, {"text": "this is almost cheating .", "speaker": "B"}, {"text": "it certainly isn't real - time .", "speaker": "B"}, {"text": "but if suppose you use the real boundaries that you were were given by the vad and", "speaker": "B"}, {"text": "or we 're gonna be given even better boundaries than that .", "speaker": "B"}, {"text": "and you look you take all all of the nonspeech components in an utterance ,", "speaker": "B"}, {"text": "so you have fair amount .", "speaker": "B"}, {"text": "do you benefit from having better model for the noise ?", "speaker": "B"}, {"text": "that would be another question .", "speaker": "B"}, {"text": "so first question would be to what extent are the errors that you 're still seeing based on the fact that you have poor boundaries for the , , nonspeech ?", "speaker": "B"}, {"text": "and the second question might be , given that you have good boundaries , could you do better if you used more parameters to characterize the noise ?", "speaker": "B"}, {"text": "also another question might be", "speaker": "B"}, {"text": "they are doing they 're using first term only of the vector taylor series ?", "speaker": "B"}, {"text": "if you do second term does it get too complicated cuz of the nonlinearity ?", "speaker": "B"}, {"text": "it 's quite complicated .", "speaker": "E"}, {"text": "no , won't ask the next question then .", "speaker": "B"}, {"text": "it 's it 's the for me it 's the first time that am working with vts .", "speaker": "E"}, {"text": "no , it 's interesting .", "speaker": "B"}, {"text": "we haven't had anybody work with it before ,", "speaker": "B"}, {"text": "so it 's interesting to get your get your feedback about it .", "speaker": "B"}, {"text": "it 's another type of approximation because because it 's statistic approximation to remove the noise .", "speaker": "E"}, {"text": "we 're about done .", "speaker": "F"}, {"text": "so some of the digit forms don't have digits .", "speaker": "F"}, {"text": "there were some blanks in there ,", "speaker": "F"}, {"text": "so not everybody will be reading digits .", "speaker": "F"}, {"text": "you 've got some . , morgan ?", "speaker": "F"}, {"text": "why don't you go ahead and start .", "speaker": "F"}, {"text": "and it 's just us down here at this end that have them .", "speaker": "F"}, {"text": "so , we switch off with this", "speaker": "D"}, {"text": "whenever you 're ready .", "speaker": "F"}, {"text": "leave it on ,", "speaker": "F"}, {"text": "they prefer to have them on", "speaker": "B"}, {"text": "just so that they 're continuing to get the distant , , information .", "speaker": "B"}], "id": "xxxxx", "relations": [{"y": 1, "x": 0, "type": "Explanation"}]}]